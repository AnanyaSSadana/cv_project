{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb70403-2740-4e1d-ac77-f1fae4079b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:51.695665Z",
     "iopub.status.busy": "2024-05-12T08:20:51.695552Z",
     "iopub.status.idle": "2024-05-12T08:20:53.649103Z",
     "shell.execute_reply": "2024-05-12T08:20:53.648547Z",
     "shell.execute_reply.started": "2024-05-12T08:20:51.695655Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from util import misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5775166-b433-45d7-9b29-2e043d56f3ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.650678Z",
     "iopub.status.busy": "2024-05-12T08:20:53.650155Z",
     "iopub.status.idle": "2024-05-12T08:20:53.655763Z",
     "shell.execute_reply": "2024-05-12T08:20:53.654931Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.650664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.12.0\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current CUDA device index: 0\n",
      "Current CUDA device name: NVIDIA GeForce RTX 3080\n",
      "CUDA device properties:\n",
      "   Name: NVIDIA GeForce RTX 3080\n",
      "   CUDA capability: 8 . 6\n",
      "   Total memory: 10.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch version\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda:0\")\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available:\", cuda_available)\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the CUDA device count\n",
    "    cuda_device_count = torch.cuda.device_count()\n",
    "    print(\"CUDA device count:\", cuda_device_count)\n",
    "\n",
    "    # Get the current CUDA device index\n",
    "    current_cuda_device = torch.cuda.current_device()\n",
    "    print(\"Current CUDA device index:\", current_cuda_device)\n",
    "\n",
    "    # Get the name of the current CUDA device\n",
    "    current_cuda_device_name = torch.cuda.get_device_name(current_cuda_device)\n",
    "    print(\"Current CUDA device name:\", current_cuda_device_name)\n",
    "\n",
    "    # Get the CUDA device properties\n",
    "    cuda_device_properties = torch.cuda.get_device_properties(current_cuda_device)\n",
    "    print(\"CUDA device properties:\")\n",
    "    print(\"   Name:\", cuda_device_properties.name)\n",
    "    print(\"   CUDA capability:\", cuda_device_properties.major, \".\", cuda_device_properties.minor)\n",
    "    print(\"   Total memory:\", round(cuda_device_properties.total_memory / (1024 ** 3), 1), \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2163f0-9e7a-4b2e-98ca-7a573929b574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.656632Z",
     "iopub.status.busy": "2024-05-12T08:20:53.656468Z",
     "iopub.status.idle": "2024-05-12T08:20:53.660256Z",
     "shell.execute_reply": "2024-05-12T08:20:53.659612Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.656617Z"
    }
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data': './SSL_embeddings/Real/',\n",
    "    'output_dir': './SSL_CRC_outputs/',\n",
    "    'log_dir': './logs/',\n",
    "    'model': 'base',\n",
    "    'workers': 12,\n",
    "    'epochs': 30,\n",
    "    'start_epoch': 0,\n",
    "    'batch_size': 64,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 0.,\n",
    "    'print_freq': 100,\n",
    "    'eval_freq': 1,\n",
    "    # 'world_size': 1,\n",
    "    # 'rank': 0,\n",
    "    # 'local_rank': 0,\n",
    "    # 'dist_url': 'env://',\n",
    "    # 'dist_backend': 'nccl',\n",
    "    'seed': None,\n",
    "    'gpu': 0,\n",
    "    'pretrained': './model_saved/full_classes/epoch_last.pth',\n",
    "    'use_bn': False,\n",
    "    'num_classes': 9,\n",
    "    'base_lrs': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "    # 'base_lrs': [0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af09efb-222f-4290-99bf-6353e66284b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.661580Z",
     "iopub.status.busy": "2024-05-12T08:20:53.660962Z",
     "iopub.status.idle": "2024-05-12T08:20:53.664502Z",
     "shell.execute_reply": "2024-05-12T08:20:53.663916Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.661566Z"
    }
   },
   "outputs": [],
   "source": [
    "class DictToObject:\n",
    "    def __init__(self, d):\n",
    "        for key, value in d.items():\n",
    "            setattr(self, key, value)\n",
    "args = DictToObject(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af81f65f-8edd-4a38-a541-e7431c51c657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.665466Z",
     "iopub.status.busy": "2024-05-12T08:20:53.665171Z",
     "iopub.status.idle": "2024-05-12T08:20:53.671047Z",
     "shell.execute_reply": "2024-05-12T08:20:53.670427Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.665452Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_and_optimizer(args):\n",
    "    # load pre-trained model\n",
    "    if os.path.isfile(args.pretrained):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.pretrained))\n",
    "        checkpoint = torch.load(args.pretrained, map_location=f\"cuda:{args.gpu}\")\n",
    "        state_dict = checkpoint['model']\n",
    "\n",
    "        prefix = 'visual.'\n",
    "        for k in list(state_dict.keys()):\n",
    "            if k.startswith(prefix) and not k.startswith(prefix + 'head'):\n",
    "                state_dict[k[len('visual.'):]] = state_dict[k]\n",
    "            del state_dict[k]\n",
    "    else:\n",
    "        raise Exception(f\"No pre-trained model specified: {args.pretrained}\")\n",
    "\n",
    "    # create model\n",
    "    model = timm.create_model(f\"vit_{args.model}_patch16_224\", num_classes=args.num_classes)\n",
    "    msg = model.load_state_dict(state_dict, strict=False)\n",
    "    assert set(msg.missing_keys) == {\"head.weight\", \"head.bias\"}\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if name not in ['head.weight', 'head.bias']:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # delete the last fc layer, and instead add a bunch of classifiers\n",
    "    del model.head\n",
    "    feat_dim = model.cls_token.shape[-1]\n",
    "    linear_classifiers, optim_param_groups = add_linear_classifier(\n",
    "        feat_dim, args.num_classes, args.base_lrs, args.batch_size, args.use_bn)\n",
    "\n",
    "    model.cuda(args.gpu)\n",
    "    # if args.distributed:\n",
    "    #     linear_classifiers = torch.nn.parallel.DistributedDataParallel(\n",
    "    #         linear_classifiers, device_ids=[args.gpu])\n",
    "\n",
    "    optimizer = torch.optim.SGD(optim_param_groups,\n",
    "                                lr=0.0,  # fake lr\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    return model, linear_classifiers, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "907b8c23-6783-4176-b146-bf865f442e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.672027Z",
     "iopub.status.busy": "2024-05-12T08:20:53.671792Z",
     "iopub.status.idle": "2024-05-12T08:20:53.676327Z",
     "shell.execute_reply": "2024-05-12T08:20:53.675697Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.672013Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(args):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        os.path.join(args.data, 'train'), train_transform)\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        os.path.join(args.data, 'val'), val_transform)\n",
    "\n",
    "    # if args.distributed:\n",
    "    #     train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    # else:\n",
    "    train_sampler = None\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler, drop_last=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, len(train_dataset), train_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23201f3b-f010-4e00-ae32-88b675040aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.678145Z",
     "iopub.status.busy": "2024-05-12T08:20:53.677822Z",
     "iopub.status.idle": "2024-05-12T08:20:53.681349Z",
     "shell.execute_reply": "2024-05-12T08:20:53.680803Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.678129Z"
    }
   },
   "outputs": [],
   "source": [
    "class AllClassifiers(nn.Module):\n",
    "    def __init__(self, classifiers_dict):\n",
    "        super().__init__()\n",
    "        self.classifiers_dict = nn.ModuleDict()\n",
    "        self.classifiers_dict.update(classifiers_dict)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return {k: v.forward(inputs) for k, v in self.classifiers_dict.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.classifiers_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6530fae1-c16a-4a7d-ad9a-a0226c6aca31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.682071Z",
     "iopub.status.busy": "2024-05-12T08:20:53.681937Z",
     "iopub.status.idle": "2024-05-12T08:20:53.686311Z",
     "shell.execute_reply": "2024-05-12T08:20:53.685667Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.682060Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_linear_classifier(feat_dim, num_classes, learning_rates, batch_size, use_bn=False):\n",
    "    linear_classifier_dict = nn.ModuleDict()\n",
    "    optim_param_groups = []\n",
    "    for blr in learning_rates:\n",
    "        lr = blr * batch_size * misc.get_world_size() / 256\n",
    "\n",
    "        linear_classifier = nn.Linear(feat_dim, num_classes)\n",
    "        linear_classifier.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        linear_classifier.bias.data.zero_()\n",
    "        if use_bn:\n",
    "            linear_classifier = nn.Sequential(\n",
    "                torch.nn.SyncBatchNorm(feat_dim, affine=False, eps=1e-6),\n",
    "                linear_classifier\n",
    "            )\n",
    "        linear_classifier.cuda()\n",
    "\n",
    "        name = f\"{blr:.4f}\".replace('.', '_')\n",
    "        linear_classifier_dict[f\"classifier_lr_{name}\"] = linear_classifier\n",
    "        optim_param_groups.append({\"params\": linear_classifier.parameters(), \"lr\": lr})\n",
    "\n",
    "    # add to ddp mode\n",
    "    linear_classifiers = AllClassifiers(linear_classifier_dict)\n",
    "    print('number of classifiers in totall (with different lr): ', len(linear_classifiers))\n",
    "    return linear_classifiers, optim_param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fd5f7a-4daa-4c86-b715-59070374baa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.687577Z",
     "iopub.status.busy": "2024-05-12T08:20:53.686960Z",
     "iopub.status.idle": "2024-05-12T08:20:53.691305Z",
     "shell.execute_reply": "2024-05-12T08:20:53.690665Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.687561Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "        # print(output)\n",
    "        # print(maxk)\n",
    "        # print(target)\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be0fb25a-d3f9-48ac-a698-0a1a55d6ca5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.692476Z",
     "iopub.status.busy": "2024-05-12T08:20:53.691961Z",
     "iopub.status.idle": "2024-05-12T08:20:53.700917Z",
     "shell.execute_reply": "2024-05-12T08:20:53.699838Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.692460Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, linear_classifiers, optimizer, scheduler, epoch, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        # [batch_time, data_time, losses, top1, top5],\n",
    "        [batch_time, data_time, losses, top1],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    model.eval()\n",
    "    linear_classifiers.train(True)\n",
    "\n",
    "    all_top1 = {k: AverageMeter('Acc@1', ':6.2f') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "    # all_top5 = {k: AverageMeter('Acc@5', ':6.2f') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "    all_losses = {k: AverageMeter('Loss', ':.4e') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        images = images.cuda(args.gpu, non_blocking=True)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            features = model.forward_features(images)\n",
    "        outputs = linear_classifiers(features)\n",
    "\n",
    "        cls_losses = {f\"loss_{k}\": nn.CrossEntropyLoss()(v, target) for k, v in outputs.items()}\n",
    "        loss = sum(cls_losses.values())\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        min_loss = 1e5\n",
    "        max_acc1 = -1\n",
    "        # max_acc5 = -1\n",
    "        for k, v in outputs.items():\n",
    "            # acc1, acc5 = accuracy(v, target, topk=(1, 5))\n",
    "            acc1, _ = accuracy(v, target, topk=(1, 2))\n",
    "            # print(acc1)\n",
    "            all_top1[k].update(acc1.item(), images.size(0))\n",
    "            # all_top5[k].update(acc5.item(), images.size(0))\n",
    "            all_losses[k].update(cls_losses[f\"loss_{k}\"].item(), images.size(0))\n",
    "            min_loss = min(min_loss, cls_losses[f\"loss_{k}\"].item())\n",
    "            max_acc1 = max(max_acc1, acc1.item())\n",
    "            # max_acc5 = max(max_acc5, acc5.item())\n",
    "\n",
    "        # logging the best loss/accuracy across all classifiers\n",
    "        losses.update(min_loss, images.size(0))\n",
    "        top1.update(max_acc1, images.size(0))\n",
    "        # top5.update(max_acc5, images.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "    # return {'acc1': top1.avg, 'acc5': top5.avg, 'loss': losses.avg}, all_top1, all_top5, all_losses\n",
    "    return {'acc1': top1.avg, 'loss': losses.avg}, all_top1, all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba13d88-50e5-4089-9ada-bf6c7e1d7eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.702758Z",
     "iopub.status.busy": "2024-05-12T08:20:53.702248Z",
     "iopub.status.idle": "2024-05-12T08:20:53.711754Z",
     "shell.execute_reply": "2024-05-12T08:20:53.710890Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.702732Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, linear_classifiers, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        # [batch_time, losses, top1, top5],\n",
    "        [batch_time, losses, top1],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    linear_classifiers.eval()\n",
    "\n",
    "    all_top1 = {k: AverageMeter('Acc@1', ':6.2f') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "    # all_top5 = {k: AverageMeter('Acc@5', ':6.2f') for k in linear_classifiers.module.classifiers_dict.keys()}\n",
    "    all_losses = {k: AverageMeter('Loss', ':.4e') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            images = images.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            features = model.forward_features(images)\n",
    "            outputs = linear_classifiers(features)\n",
    "\n",
    "            my_losses = {f\"loss_{k}\": nn.CrossEntropyLoss()(v, target) for k, v in outputs.items()}\n",
    "            min_loss = 1e6\n",
    "            max_acc1 = -1\n",
    "            # max_acc5 = -1\n",
    "            for k, v in outputs.items():\n",
    "                # acc1, acc5 = accuracy(v, target, topk=(1, 5))\n",
    "                acc1, _ = accuracy(v, target, topk=(1, 2))\n",
    "                all_top1[k].update(acc1.item(), images.size(0))\n",
    "                # all_top5[k].update(acc5.item(), images.size(0))\n",
    "                all_losses[k].update(my_losses[f\"loss_{k}\"].item(), images.size(0))\n",
    "                min_loss = min(min_loss, my_losses[f\"loss_{k}\"].item())\n",
    "                max_acc1 = max(max_acc1, acc1.item())\n",
    "                # max_acc5 = max(max_acc5, acc5.item())\n",
    "\n",
    "            # logging the best loss/accuracy across all classifiers\n",
    "            losses.update(min_loss, images.size(0))\n",
    "            top1.update(max_acc1, images.size(0))\n",
    "            # top5.update(max_acc5, images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # print('Monitored (fake) accuracy * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "        #       .format(top1=top1, top5=top5))\n",
    "        print('Monitored (fake) accuracy * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "    # print('acc1', top1.avg)\n",
    "    # print('loss', losses.avg)\n",
    "    # return {'acc1': top1.avg, 'acc5': top5.avg, 'loss': losses.avg}, all_top1, all_top5, all_losses\n",
    "    return {'acc1': top1.avg, 'loss': losses.avg}, all_top1, all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a7ec2fc-b64f-442f-ac2d-32cb8914f0a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.712985Z",
     "iopub.status.busy": "2024-05-12T08:20:53.712726Z",
     "iopub.status.idle": "2024-05-12T08:20:53.718199Z",
     "shell.execute_reply": "2024-05-12T08:20:53.717002Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.712962Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, output_dir):\n",
    "    ckpt_path = f'{output_dir}/linear_checkpoint.pt'\n",
    "    best_path = f'{output_dir}/linear_best.pt'\n",
    "    torch.save(state, ckpt_path)\n",
    "    if is_best:\n",
    "        shutil.copyfile(ckpt_path, best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91954208-4ccf-417e-8687-91027bf0fce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.719491Z",
     "iopub.status.busy": "2024-05-12T08:20:53.719193Z",
     "iopub.status.idle": "2024-05-12T08:20:53.725834Z",
     "shell.execute_reply": "2024-05-12T08:20:53.724481Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.719468Z"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbed858d-c64d-4445-9888-ae032913b862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.727548Z",
     "iopub.status.busy": "2024-05-12T08:20:53.727234Z",
     "iopub.status.idle": "2024-05-12T08:20:53.733257Z",
     "shell.execute_reply": "2024-05-12T08:20:53.732088Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.727510Z"
    }
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a8f644d-c044-47c5-b581-2f874a455ef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:20:53.734597Z",
     "iopub.status.busy": "2024-05-12T08:20:53.734319Z",
     "iopub.status.idle": "2024-05-12T08:21:00.882070Z",
     "shell.execute_reply": "2024-05-12T08:21:00.881511Z",
     "shell.execute_reply.started": "2024-05-12T08:20:53.734580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './model_saved/full_classes/epoch_last.pth'\n",
      "number of classifiers in totall (with different lr):  10\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "model, linear_classifiers, optimizer = get_model_and_optimizer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d44d2257-04c4-4385-8193-3c50304d0070",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:21:00.883160Z",
     "iopub.status.busy": "2024-05-12T08:21:00.882993Z",
     "iopub.status.idle": "2024-05-12T09:28:02.022141Z",
     "shell.execute_reply": "2024-05-12T09:28:02.013738Z",
     "shell.execute_reply.started": "2024-05-12T08:21:00.883148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/562]\tTime  8.967 ( 8.967)\tData  2.097 ( 2.097)\tLoss 2.1480e+00 (2.1480e+00)\tAcc@1  25.00 ( 25.00)\n",
      "Epoch: [0][100/562]\tTime  0.177 ( 0.264)\tData  0.000 ( 0.021)\tLoss 5.4086e-01 (6.9018e-01)\tAcc@1  79.69 ( 76.42)\n",
      "Epoch: [0][200/562]\tTime  0.177 ( 0.221)\tData  0.000 ( 0.011)\tLoss 8.9901e-01 (6.4071e-01)\tAcc@1  68.75 ( 78.09)\n",
      "Epoch: [0][300/562]\tTime  0.183 ( 0.207)\tData  0.000 ( 0.007)\tLoss 5.3206e-01 (6.2193e-01)\tAcc@1  85.94 ( 78.89)\n",
      "Epoch: [0][400/562]\tTime  0.185 ( 0.201)\tData  0.000 ( 0.005)\tLoss 7.3840e-01 (6.1230e-01)\tAcc@1  68.75 ( 79.28)\n",
      "Epoch: [0][500/562]\tTime  0.183 ( 0.197)\tData  0.000 ( 0.004)\tLoss 5.9966e-01 (6.0299e-01)\tAcc@1  76.56 ( 79.65)\n",
      "Test: [  0/141]\tTime  1.071 ( 1.071)\tLoss 3.0546e-06 (3.0546e-06)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.193)\tLoss 4.3567e-01 (3.0531e-01)\tAcc@1  85.94 ( 90.62)\n",
      "Monitored (fake) accuracy * Acc@1 89.189\n",
      "Epoch: [1][  0/562]\tTime  1.547 ( 1.547)\tData  1.147 ( 1.147)\tLoss 5.2745e-01 (5.2745e-01)\tAcc@1  81.25 ( 81.25)\n",
      "Epoch: [1][100/562]\tTime  0.186 ( 0.200)\tData  0.000 ( 0.012)\tLoss 5.6893e-01 (5.5707e-01)\tAcc@1  85.94 ( 81.08)\n",
      "Epoch: [1][200/562]\tTime  0.185 ( 0.194)\tData  0.000 ( 0.006)\tLoss 3.3166e-01 (5.6210e-01)\tAcc@1  85.94 ( 81.06)\n",
      "Epoch: [1][300/562]\tTime  0.186 ( 0.192)\tData  0.000 ( 0.004)\tLoss 5.0236e-01 (5.6670e-01)\tAcc@1  82.81 ( 80.78)\n",
      "Epoch: [1][400/562]\tTime  0.185 ( 0.190)\tData  0.000 ( 0.003)\tLoss 5.1166e-01 (5.6501e-01)\tAcc@1  82.81 ( 80.88)\n",
      "Epoch: [1][500/562]\tTime  0.184 ( 0.190)\tData  0.000 ( 0.002)\tLoss 4.9533e-01 (5.6488e-01)\tAcc@1  81.25 ( 80.90)\n",
      "Test: [  0/141]\tTime  1.015 ( 1.015)\tLoss 3.4101e-06 (3.4101e-06)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.193)\tLoss 3.7145e-01 (3.1275e-01)\tAcc@1  89.06 ( 89.96)\n",
      "Monitored (fake) accuracy * Acc@1 89.767\n",
      "Epoch: [2][  0/562]\tTime  1.337 ( 1.337)\tData  0.989 ( 0.989)\tLoss 7.3419e-01 (7.3419e-01)\tAcc@1  76.56 ( 76.56)\n",
      "Epoch: [2][100/562]\tTime  0.185 ( 0.197)\tData  0.000 ( 0.010)\tLoss 3.9214e-01 (5.5460e-01)\tAcc@1  87.50 ( 81.42)\n",
      "Epoch: [2][200/562]\tTime  0.184 ( 0.191)\tData  0.000 ( 0.005)\tLoss 6.9107e-01 (5.4617e-01)\tAcc@1  76.56 ( 81.61)\n",
      "Epoch: [2][300/562]\tTime  0.185 ( 0.190)\tData  0.000 ( 0.003)\tLoss 4.8487e-01 (5.4562e-01)\tAcc@1  81.25 ( 81.49)\n",
      "Epoch: [2][400/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.003)\tLoss 5.6309e-01 (5.5496e-01)\tAcc@1  81.25 ( 81.14)\n",
      "Epoch: [2][500/562]\tTime  0.185 ( 0.189)\tData  0.000 ( 0.002)\tLoss 5.7154e-01 (5.5167e-01)\tAcc@1  81.25 ( 81.30)\n",
      "Test: [  0/141]\tTime  0.785 ( 0.785)\tLoss 4.6938e-07 (4.6938e-07)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.192)\tLoss 1.3389e-01 (3.1751e-01)\tAcc@1  95.31 ( 90.39)\n",
      "Monitored (fake) accuracy * Acc@1 88.389\n",
      "Epoch: [3][  0/562]\tTime  1.170 ( 1.170)\tData  0.866 ( 0.866)\tLoss 5.2428e-01 (5.2428e-01)\tAcc@1  82.81 ( 82.81)\n",
      "Epoch: [3][100/562]\tTime  0.186 ( 0.196)\tData  0.000 ( 0.009)\tLoss 5.4003e-01 (5.2814e-01)\tAcc@1  76.56 ( 82.30)\n",
      "Epoch: [3][200/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.005)\tLoss 6.2500e-01 (5.4305e-01)\tAcc@1  79.69 ( 81.87)\n",
      "Epoch: [3][300/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.003)\tLoss 5.7056e-01 (5.4239e-01)\tAcc@1  76.56 ( 81.95)\n",
      "Epoch: [3][400/562]\tTime  0.189 ( 0.189)\tData  0.000 ( 0.002)\tLoss 5.0833e-01 (5.4531e-01)\tAcc@1  84.38 ( 81.74)\n",
      "Epoch: [3][500/562]\tTime  0.187 ( 0.188)\tData  0.000 ( 0.002)\tLoss 5.7326e-01 (5.4626e-01)\tAcc@1  84.38 ( 81.74)\n",
      "Test: [  0/141]\tTime  0.929 ( 0.929)\tLoss 5.3072e-03 (5.3072e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.192)\tLoss 3.1046e-01 (3.3213e-01)\tAcc@1  89.06 ( 91.55)\n",
      "Monitored (fake) accuracy * Acc@1 90.811\n",
      "Epoch: [4][  0/562]\tTime  1.481 ( 1.481)\tData  1.114 ( 1.114)\tLoss 4.1257e-01 (4.1257e-01)\tAcc@1  90.62 ( 90.62)\n",
      "Epoch: [4][100/562]\tTime  0.186 ( 0.199)\tData  0.000 ( 0.011)\tLoss 4.4566e-01 (5.5329e-01)\tAcc@1  84.38 ( 81.20)\n",
      "Epoch: [4][200/562]\tTime  0.185 ( 0.193)\tData  0.000 ( 0.006)\tLoss 5.6437e-01 (5.5341e-01)\tAcc@1  78.12 ( 81.28)\n",
      "Epoch: [4][300/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.004)\tLoss 7.4535e-01 (5.5455e-01)\tAcc@1  73.44 ( 81.24)\n",
      "Epoch: [4][400/562]\tTime  0.185 ( 0.190)\tData  0.000 ( 0.003)\tLoss 5.3505e-01 (5.5111e-01)\tAcc@1  82.81 ( 81.39)\n",
      "Epoch: [4][500/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.002)\tLoss 5.1069e-01 (5.4658e-01)\tAcc@1  84.38 ( 81.47)\n",
      "Test: [  0/141]\tTime  1.125 ( 1.125)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.195)\tLoss 4.6284e-01 (3.1797e-01)\tAcc@1  79.69 ( 89.74)\n",
      "Monitored (fake) accuracy * Acc@1 87.789\n",
      "Epoch: [5][  0/562]\tTime  1.468 ( 1.468)\tData  1.126 ( 1.126)\tLoss 4.4298e-01 (4.4298e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [5][100/562]\tTime  0.188 ( 0.200)\tData  0.000 ( 0.011)\tLoss 5.5905e-01 (5.4232e-01)\tAcc@1  81.25 ( 81.87)\n",
      "Epoch: [5][200/562]\tTime  0.185 ( 0.194)\tData  0.000 ( 0.006)\tLoss 7.0479e-01 (5.4971e-01)\tAcc@1  73.44 ( 81.19)\n",
      "Epoch: [5][300/562]\tTime  0.189 ( 0.191)\tData  0.000 ( 0.004)\tLoss 6.1670e-01 (5.4549e-01)\tAcc@1  76.56 ( 81.58)\n",
      "Epoch: [5][400/562]\tTime  0.185 ( 0.190)\tData  0.000 ( 0.003)\tLoss 4.5325e-01 (5.4196e-01)\tAcc@1  85.94 ( 81.75)\n",
      "Epoch: [5][500/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.002)\tLoss 6.6418e-01 (5.4033e-01)\tAcc@1  73.44 ( 81.83)\n",
      "Test: [  0/141]\tTime  0.995 ( 0.995)\tLoss 6.3213e-04 (6.3213e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.193)\tLoss 3.0849e-01 (3.8278e-01)\tAcc@1  92.19 ( 89.62)\n",
      "Monitored (fake) accuracy * Acc@1 90.522\n",
      "Epoch: [6][  0/562]\tTime  1.178 ( 1.178)\tData  0.878 ( 0.878)\tLoss 4.6557e-01 (4.6557e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [6][100/562]\tTime  0.185 ( 0.196)\tData  0.000 ( 0.009)\tLoss 3.9206e-01 (5.3478e-01)\tAcc@1  87.50 ( 82.13)\n",
      "Epoch: [6][200/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.005)\tLoss 4.0102e-01 (5.4116e-01)\tAcc@1  85.94 ( 81.74)\n",
      "Epoch: [6][300/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 5.1028e-01 (5.3732e-01)\tAcc@1  82.81 ( 81.88)\n",
      "Epoch: [6][400/562]\tTime  0.185 ( 0.189)\tData  0.000 ( 0.002)\tLoss 3.8183e-01 (5.3579e-01)\tAcc@1  89.06 ( 82.03)\n",
      "Epoch: [6][500/562]\tTime  0.187 ( 0.188)\tData  0.000 ( 0.002)\tLoss 6.5272e-01 (5.3655e-01)\tAcc@1  75.00 ( 82.03)\n",
      "Test: [  0/141]\tTime  0.866 ( 0.866)\tLoss 1.3393e-02 (1.3393e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.195 ( 0.192)\tLoss 1.4735e-01 (2.3283e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Monitored (fake) accuracy * Acc@1 92.267\n",
      "Epoch: [7][  0/562]\tTime  1.178 ( 1.178)\tData  0.983 ( 0.983)\tLoss 4.6403e-01 (4.6403e-01)\tAcc@1  81.25 ( 81.25)\n",
      "Epoch: [7][100/562]\tTime  0.184 ( 0.197)\tData  0.000 ( 0.010)\tLoss 4.6951e-01 (5.3578e-01)\tAcc@1  78.12 ( 81.87)\n",
      "Epoch: [7][200/562]\tTime  0.185 ( 0.191)\tData  0.000 ( 0.005)\tLoss 2.6907e-01 (5.2777e-01)\tAcc@1  92.19 ( 82.17)\n",
      "Epoch: [7][300/562]\tTime  0.185 ( 0.190)\tData  0.000 ( 0.003)\tLoss 5.0198e-01 (5.2969e-01)\tAcc@1  85.94 ( 82.18)\n",
      "Epoch: [7][400/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.003)\tLoss 5.2688e-01 (5.2827e-01)\tAcc@1  82.81 ( 82.15)\n",
      "Epoch: [7][500/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.002)\tLoss 3.1608e-01 (5.2785e-01)\tAcc@1  87.50 ( 82.08)\n",
      "Test: [  0/141]\tTime  0.912 ( 0.912)\tLoss 3.2246e-03 (3.2246e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.193)\tLoss 3.5210e-01 (2.7103e-01)\tAcc@1  81.25 ( 91.48)\n",
      "Monitored (fake) accuracy * Acc@1 89.200\n",
      "Epoch: [8][  0/562]\tTime  1.031 ( 1.031)\tData  0.831 ( 0.831)\tLoss 4.9861e-01 (4.9861e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [8][100/562]\tTime  0.185 ( 0.195)\tData  0.000 ( 0.008)\tLoss 6.8982e-01 (5.4839e-01)\tAcc@1  75.00 ( 81.85)\n",
      "Epoch: [8][200/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.004)\tLoss 3.7056e-01 (5.3315e-01)\tAcc@1  87.50 ( 82.21)\n",
      "Epoch: [8][300/562]\tTime  0.189 ( 0.189)\tData  0.000 ( 0.003)\tLoss 5.1495e-01 (5.3105e-01)\tAcc@1  82.81 ( 82.29)\n",
      "Epoch: [8][400/562]\tTime  0.185 ( 0.188)\tData  0.000 ( 0.002)\tLoss 6.8846e-01 (5.3131e-01)\tAcc@1  73.44 ( 82.16)\n",
      "Epoch: [8][500/562]\tTime  0.185 ( 0.188)\tData  0.000 ( 0.002)\tLoss 6.1670e-01 (5.2642e-01)\tAcc@1  79.69 ( 82.33)\n",
      "Test: [  0/141]\tTime  1.035 ( 1.035)\tLoss 1.6576e-04 (1.6576e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.194)\tLoss 1.9999e-01 (2.7023e-01)\tAcc@1  92.19 ( 92.61)\n",
      "Monitored (fake) accuracy * Acc@1 91.244\n",
      "Epoch: [9][  0/562]\tTime  1.458 ( 1.458)\tData  1.068 ( 1.068)\tLoss 4.5944e-01 (4.5944e-01)\tAcc@1  90.62 ( 90.62)\n",
      "Epoch: [9][100/562]\tTime  0.185 ( 0.199)\tData  0.000 ( 0.011)\tLoss 3.7225e-01 (5.3166e-01)\tAcc@1  92.19 ( 82.04)\n",
      "Epoch: [9][200/562]\tTime  0.185 ( 0.193)\tData  0.000 ( 0.005)\tLoss 4.8256e-01 (5.2991e-01)\tAcc@1  82.81 ( 82.21)\n",
      "Epoch: [9][300/562]\tTime  0.188 ( 0.191)\tData  0.000 ( 0.004)\tLoss 6.6719e-01 (5.2228e-01)\tAcc@1  76.56 ( 82.55)\n",
      "Epoch: [9][400/562]\tTime  0.185 ( 0.190)\tData  0.000 ( 0.003)\tLoss 4.5481e-01 (5.1949e-01)\tAcc@1  82.81 ( 82.63)\n",
      "Epoch: [9][500/562]\tTime  0.189 ( 0.189)\tData  0.000 ( 0.002)\tLoss 5.1163e-01 (5.2219e-01)\tAcc@1  85.94 ( 82.57)\n",
      "Test: [  0/141]\tTime  1.054 ( 1.054)\tLoss 5.4575e-07 (5.4575e-07)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.194)\tLoss 4.0625e-01 (2.7966e-01)\tAcc@1  87.50 ( 91.62)\n",
      "Monitored (fake) accuracy * Acc@1 90.222\n",
      "Epoch: [10][  0/562]\tTime  1.102 ( 1.102)\tData  0.790 ( 0.790)\tLoss 4.0724e-01 (4.0724e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [10][100/562]\tTime  0.185 ( 0.196)\tData  0.000 ( 0.008)\tLoss 4.2448e-01 (5.0888e-01)\tAcc@1  84.38 ( 82.84)\n",
      "Epoch: [10][200/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.004)\tLoss 5.7507e-01 (5.1092e-01)\tAcc@1  79.69 ( 82.84)\n",
      "Epoch: [10][300/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.003)\tLoss 2.8606e-01 (5.1303e-01)\tAcc@1  90.62 ( 82.71)\n",
      "Epoch: [10][400/562]\tTime  0.185 ( 0.189)\tData  0.000 ( 0.002)\tLoss 5.6319e-01 (5.1288e-01)\tAcc@1  81.25 ( 82.79)\n",
      "Epoch: [10][500/562]\tTime  0.185 ( 0.188)\tData  0.000 ( 0.002)\tLoss 5.7367e-01 (5.1513e-01)\tAcc@1  81.25 ( 82.76)\n",
      "Test: [  0/141]\tTime  0.756 ( 0.756)\tLoss 5.0371e-04 (5.0371e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.192)\tLoss 2.2724e-01 (2.9369e-01)\tAcc@1  92.19 ( 90.95)\n",
      "Monitored (fake) accuracy * Acc@1 90.378\n",
      "Epoch: [11][  0/562]\tTime  1.270 ( 1.270)\tData  1.088 ( 1.088)\tLoss 3.8343e-01 (3.8343e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [11][100/562]\tTime  0.186 ( 0.197)\tData  0.000 ( 0.011)\tLoss 3.9596e-01 (5.0224e-01)\tAcc@1  87.50 ( 83.56)\n",
      "Epoch: [11][200/562]\tTime  0.186 ( 0.192)\tData  0.000 ( 0.006)\tLoss 4.8465e-01 (5.0216e-01)\tAcc@1  87.50 ( 83.46)\n",
      "Epoch: [11][300/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.004)\tLoss 7.9877e-01 (5.1002e-01)\tAcc@1  75.00 ( 83.01)\n",
      "Epoch: [11][400/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.003)\tLoss 3.7601e-01 (5.1213e-01)\tAcc@1  87.50 ( 83.02)\n",
      "Epoch: [11][500/562]\tTime  0.185 ( 0.188)\tData  0.000 ( 0.002)\tLoss 7.6379e-01 (5.1157e-01)\tAcc@1  78.12 ( 83.01)\n",
      "Test: [  0/141]\tTime  1.009 ( 1.009)\tLoss 1.7780e-04 (1.7780e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.194)\tLoss 4.0995e-01 (2.8250e-01)\tAcc@1  85.94 ( 90.93)\n",
      "Monitored (fake) accuracy * Acc@1 90.433\n",
      "Epoch: [12][  0/562]\tTime  1.480 ( 1.480)\tData  1.086 ( 1.086)\tLoss 4.8536e-01 (4.8536e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [12][100/562]\tTime  0.187 ( 0.199)\tData  0.000 ( 0.011)\tLoss 3.7120e-01 (5.0757e-01)\tAcc@1  87.50 ( 83.34)\n",
      "Epoch: [12][200/562]\tTime  0.188 ( 0.193)\tData  0.000 ( 0.006)\tLoss 5.7651e-01 (5.0470e-01)\tAcc@1  75.00 ( 83.45)\n",
      "Epoch: [12][300/562]\tTime  0.185 ( 0.191)\tData  0.000 ( 0.004)\tLoss 4.5438e-01 (5.0654e-01)\tAcc@1  85.94 ( 83.27)\n",
      "Epoch: [12][400/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.003)\tLoss 5.0347e-01 (5.1095e-01)\tAcc@1  82.81 ( 83.16)\n",
      "Epoch: [12][500/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.002)\tLoss 5.8625e-01 (5.0881e-01)\tAcc@1  78.12 ( 83.13)\n",
      "Test: [  0/141]\tTime  0.964 ( 0.964)\tLoss 4.0886e-03 (4.0886e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.193)\tLoss 6.0781e-02 (2.5707e-01)\tAcc@1  98.44 ( 91.75)\n",
      "Monitored (fake) accuracy * Acc@1 90.933\n",
      "Epoch: [13][  0/562]\tTime  1.372 ( 1.372)\tData  0.984 ( 0.984)\tLoss 5.0620e-01 (5.0620e-01)\tAcc@1  82.81 ( 82.81)\n",
      "Epoch: [13][100/562]\tTime  0.185 ( 0.198)\tData  0.000 ( 0.010)\tLoss 6.4401e-01 (4.9869e-01)\tAcc@1  82.81 ( 83.59)\n",
      "Epoch: [13][200/562]\tTime  0.185 ( 0.192)\tData  0.000 ( 0.005)\tLoss 3.5126e-01 (4.9744e-01)\tAcc@1  85.94 ( 83.48)\n",
      "Epoch: [13][300/562]\tTime  0.184 ( 0.190)\tData  0.000 ( 0.003)\tLoss 6.4049e-01 (5.0117e-01)\tAcc@1  81.25 ( 83.37)\n",
      "Epoch: [13][400/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.003)\tLoss 5.6278e-01 (4.9922e-01)\tAcc@1  82.81 ( 83.56)\n",
      "Epoch: [13][500/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.002)\tLoss 4.9648e-01 (5.0052e-01)\tAcc@1  82.81 ( 83.47)\n",
      "Test: [  0/141]\tTime  0.806 ( 0.806)\tLoss 5.5843e-03 (5.5843e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.191)\tLoss 5.3904e-01 (2.2826e-01)\tAcc@1  76.56 ( 92.82)\n",
      "Monitored (fake) accuracy * Acc@1 89.889\n",
      "Epoch: [14][  0/562]\tTime  1.242 ( 1.242)\tData  0.918 ( 0.918)\tLoss 5.0453e-01 (5.0453e-01)\tAcc@1  82.81 ( 82.81)\n",
      "Epoch: [14][100/562]\tTime  0.185 ( 0.196)\tData  0.000 ( 0.009)\tLoss 5.0178e-01 (5.1564e-01)\tAcc@1  84.38 ( 83.11)\n",
      "Epoch: [14][200/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.005)\tLoss 5.2807e-01 (5.0803e-01)\tAcc@1  84.38 ( 83.25)\n",
      "Epoch: [14][300/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 4.4352e-01 (5.0832e-01)\tAcc@1  82.81 ( 83.32)\n",
      "Epoch: [14][400/562]\tTime  0.185 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.4364e-01 (5.0211e-01)\tAcc@1  96.88 ( 83.54)\n",
      "Epoch: [14][500/562]\tTime  0.187 ( 0.188)\tData  0.000 ( 0.002)\tLoss 7.5493e-01 (4.9998e-01)\tAcc@1  76.56 ( 83.67)\n",
      "Test: [  0/141]\tTime  0.960 ( 0.960)\tLoss 7.1029e-03 (7.1029e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.193)\tLoss 2.2526e-01 (3.1014e-01)\tAcc@1  93.75 ( 90.39)\n",
      "Monitored (fake) accuracy * Acc@1 89.600\n",
      "Epoch: [15][  0/562]\tTime  0.999 ( 0.999)\tData  0.790 ( 0.790)\tLoss 6.2003e-01 (6.2003e-01)\tAcc@1  79.69 ( 79.69)\n",
      "Epoch: [15][100/562]\tTime  0.185 ( 0.195)\tData  0.000 ( 0.008)\tLoss 4.8280e-01 (4.9763e-01)\tAcc@1  85.94 ( 83.82)\n",
      "Epoch: [15][200/562]\tTime  0.185 ( 0.191)\tData  0.000 ( 0.004)\tLoss 5.6680e-01 (4.9106e-01)\tAcc@1  84.38 ( 83.99)\n",
      "Epoch: [15][300/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.003)\tLoss 3.6631e-01 (4.9247e-01)\tAcc@1  89.06 ( 83.73)\n",
      "Epoch: [15][400/562]\tTime  0.190 ( 0.189)\tData  0.000 ( 0.002)\tLoss 6.5712e-01 (4.9386e-01)\tAcc@1  78.12 ( 83.89)\n",
      "Epoch: [15][500/562]\tTime  0.186 ( 0.188)\tData  0.000 ( 0.002)\tLoss 5.3326e-01 (4.9380e-01)\tAcc@1  78.12 ( 83.84)\n",
      "Test: [  0/141]\tTime  0.892 ( 0.892)\tLoss 2.1406e-02 (2.1406e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.192)\tLoss 3.4109e-01 (2.4618e-01)\tAcc@1  89.06 ( 92.65)\n",
      "Monitored (fake) accuracy * Acc@1 91.889\n",
      "Epoch: [16][  0/562]\tTime  1.287 ( 1.287)\tData  0.912 ( 0.912)\tLoss 4.3671e-01 (4.3671e-01)\tAcc@1  89.06 ( 89.06)\n",
      "Epoch: [16][100/562]\tTime  0.185 ( 0.197)\tData  0.000 ( 0.009)\tLoss 4.6940e-01 (4.8918e-01)\tAcc@1  81.25 ( 84.45)\n",
      "Epoch: [16][200/562]\tTime  0.185 ( 0.192)\tData  0.000 ( 0.005)\tLoss 3.7684e-01 (4.8744e-01)\tAcc@1  87.50 ( 84.37)\n",
      "Epoch: [16][300/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 5.6540e-01 (4.9297e-01)\tAcc@1  81.25 ( 84.04)\n",
      "Epoch: [16][400/562]\tTime  0.185 ( 0.189)\tData  0.000 ( 0.002)\tLoss 6.0363e-01 (4.9145e-01)\tAcc@1  78.12 ( 84.05)\n",
      "Epoch: [16][500/562]\tTime  0.185 ( 0.188)\tData  0.000 ( 0.002)\tLoss 6.6774e-01 (4.9099e-01)\tAcc@1  79.69 ( 83.98)\n",
      "Test: [  0/141]\tTime  0.994 ( 0.994)\tLoss 4.8047e-03 (4.8047e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.193)\tLoss 2.4849e-01 (2.5887e-01)\tAcc@1  92.19 ( 92.26)\n",
      "Monitored (fake) accuracy * Acc@1 89.978\n",
      "Epoch: [17][  0/562]\tTime  0.959 ( 0.959)\tData  0.760 ( 0.760)\tLoss 5.1025e-01 (5.1025e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [17][100/562]\tTime  0.185 ( 0.194)\tData  0.000 ( 0.008)\tLoss 3.6504e-01 (4.8474e-01)\tAcc@1  85.94 ( 83.60)\n",
      "Epoch: [17][200/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.004)\tLoss 5.7284e-01 (4.9255e-01)\tAcc@1  82.81 ( 83.40)\n",
      "Epoch: [17][300/562]\tTime  0.185 ( 0.189)\tData  0.000 ( 0.003)\tLoss 5.1465e-01 (4.9731e-01)\tAcc@1  81.25 ( 83.37)\n",
      "Epoch: [17][400/562]\tTime  0.186 ( 0.188)\tData  0.000 ( 0.002)\tLoss 5.1942e-01 (4.9393e-01)\tAcc@1  85.94 ( 83.61)\n",
      "Epoch: [17][500/562]\tTime  0.188 ( 0.188)\tData  0.000 ( 0.002)\tLoss 4.6338e-01 (4.9370e-01)\tAcc@1  84.38 ( 83.64)\n",
      "Test: [  0/141]\tTime  1.101 ( 1.101)\tLoss 1.4597e-02 (1.4597e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.195)\tLoss 1.5605e-01 (2.4091e-01)\tAcc@1  93.75 ( 92.88)\n",
      "Monitored (fake) accuracy * Acc@1 90.878\n",
      "Epoch: [18][  0/562]\tTime  1.340 ( 1.340)\tData  0.945 ( 0.945)\tLoss 4.2116e-01 (4.2116e-01)\tAcc@1  84.38 ( 84.38)\n",
      "Epoch: [18][100/562]\tTime  0.187 ( 0.198)\tData  0.000 ( 0.010)\tLoss 4.5356e-01 (4.8425e-01)\tAcc@1  85.94 ( 84.20)\n",
      "Epoch: [18][200/562]\tTime  0.185 ( 0.192)\tData  0.000 ( 0.005)\tLoss 5.3167e-01 (4.6983e-01)\tAcc@1  79.69 ( 84.41)\n",
      "Epoch: [18][300/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 3.8738e-01 (4.7282e-01)\tAcc@1  89.06 ( 84.55)\n",
      "Epoch: [18][400/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.003)\tLoss 7.7834e-01 (4.7909e-01)\tAcc@1  75.00 ( 84.29)\n",
      "Epoch: [18][500/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.002)\tLoss 3.6085e-01 (4.8296e-01)\tAcc@1  85.94 ( 84.18)\n",
      "Test: [  0/141]\tTime  1.069 ( 1.069)\tLoss 3.1682e-06 (3.1682e-06)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.194)\tLoss 2.4717e-02 (2.5443e-01)\tAcc@1 100.00 ( 92.28)\n",
      "Monitored (fake) accuracy * Acc@1 91.733\n",
      "Epoch: [19][  0/562]\tTime  1.498 ( 1.498)\tData  1.120 ( 1.120)\tLoss 5.7552e-01 (5.7552e-01)\tAcc@1  81.25 ( 81.25)\n",
      "Epoch: [19][100/562]\tTime  0.187 ( 0.199)\tData  0.000 ( 0.011)\tLoss 3.9828e-01 (4.8808e-01)\tAcc@1  82.81 ( 83.83)\n",
      "Epoch: [19][200/562]\tTime  0.191 ( 0.193)\tData  0.000 ( 0.006)\tLoss 5.0736e-01 (4.8071e-01)\tAcc@1  82.81 ( 84.17)\n",
      "Epoch: [19][300/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.004)\tLoss 4.4268e-01 (4.7994e-01)\tAcc@1  84.38 ( 84.16)\n",
      "Epoch: [19][400/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 6.4944e-01 (4.7773e-01)\tAcc@1  76.56 ( 84.27)\n",
      "Epoch: [19][500/562]\tTime  0.189 ( 0.189)\tData  0.000 ( 0.002)\tLoss 3.6617e-01 (4.7115e-01)\tAcc@1  89.06 ( 84.54)\n",
      "Test: [  0/141]\tTime  0.919 ( 0.919)\tLoss 1.9543e-04 (1.9543e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.193)\tLoss 1.7314e-01 (2.2344e-01)\tAcc@1  93.75 ( 93.04)\n",
      "Monitored (fake) accuracy * Acc@1 90.744\n",
      "Epoch: [20][  0/562]\tTime  1.182 ( 1.182)\tData  0.974 ( 0.974)\tLoss 3.0629e-01 (3.0629e-01)\tAcc@1  90.62 ( 90.62)\n",
      "Epoch: [20][100/562]\tTime  0.189 ( 0.196)\tData  0.000 ( 0.010)\tLoss 5.2555e-01 (4.5368e-01)\tAcc@1  82.81 ( 85.02)\n",
      "Epoch: [20][200/562]\tTime  0.184 ( 0.192)\tData  0.000 ( 0.005)\tLoss 3.4033e-01 (4.5942e-01)\tAcc@1  85.94 ( 84.60)\n",
      "Epoch: [20][300/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.003)\tLoss 4.7859e-01 (4.5861e-01)\tAcc@1  82.81 ( 84.73)\n",
      "Epoch: [20][400/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.003)\tLoss 6.9802e-01 (4.5883e-01)\tAcc@1  71.88 ( 84.82)\n",
      "Epoch: [20][500/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.8408e-01 (4.5986e-01)\tAcc@1  89.06 ( 84.83)\n",
      "Test: [  0/141]\tTime  0.817 ( 0.817)\tLoss 1.2340e-04 (1.2340e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.192)\tLoss 1.1422e-01 (2.3998e-01)\tAcc@1  95.31 ( 92.36)\n",
      "Monitored (fake) accuracy * Acc@1 91.644\n",
      "Epoch: [21][  0/562]\tTime  1.283 ( 1.283)\tData  1.101 ( 1.101)\tLoss 3.6194e-01 (3.6194e-01)\tAcc@1  87.50 ( 87.50)\n",
      "Epoch: [21][100/562]\tTime  0.186 ( 0.197)\tData  0.000 ( 0.011)\tLoss 4.8337e-01 (4.6488e-01)\tAcc@1  85.94 ( 84.98)\n",
      "Epoch: [21][200/562]\tTime  0.185 ( 0.192)\tData  0.000 ( 0.006)\tLoss 4.3989e-01 (4.6540e-01)\tAcc@1  85.94 ( 84.86)\n",
      "Epoch: [21][300/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.004)\tLoss 5.2872e-01 (4.5469e-01)\tAcc@1  79.69 ( 85.11)\n",
      "Epoch: [21][400/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.003)\tLoss 4.7264e-01 (4.5281e-01)\tAcc@1  84.38 ( 85.21)\n",
      "Epoch: [21][500/562]\tTime  0.185 ( 0.189)\tData  0.000 ( 0.002)\tLoss 4.4628e-01 (4.5121e-01)\tAcc@1  82.81 ( 85.21)\n",
      "Test: [  0/141]\tTime  1.063 ( 1.063)\tLoss 5.4980e-04 (5.4980e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.194)\tLoss 9.5245e-02 (2.6373e-01)\tAcc@1  98.44 ( 91.77)\n",
      "Monitored (fake) accuracy * Acc@1 90.278\n",
      "Epoch: [22][  0/562]\tTime  0.928 ( 0.928)\tData  0.740 ( 0.740)\tLoss 4.5054e-01 (4.5054e-01)\tAcc@1  84.38 ( 84.38)\n",
      "Epoch: [22][100/562]\tTime  0.187 ( 0.194)\tData  0.000 ( 0.008)\tLoss 3.3183e-01 (4.6271e-01)\tAcc@1  90.62 ( 85.18)\n",
      "Epoch: [22][200/562]\tTime  0.185 ( 0.190)\tData  0.000 ( 0.004)\tLoss 4.9239e-01 (4.5644e-01)\tAcc@1  79.69 ( 85.14)\n",
      "Epoch: [22][300/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.003)\tLoss 2.7614e-01 (4.5387e-01)\tAcc@1  90.62 ( 85.16)\n",
      "Epoch: [22][400/562]\tTime  0.187 ( 0.188)\tData  0.000 ( 0.002)\tLoss 4.6610e-01 (4.5476e-01)\tAcc@1  85.94 ( 85.10)\n",
      "Epoch: [22][500/562]\tTime  0.185 ( 0.188)\tData  0.000 ( 0.002)\tLoss 6.3905e-01 (4.5092e-01)\tAcc@1  78.12 ( 85.25)\n",
      "Test: [  0/141]\tTime  1.047 ( 1.047)\tLoss 9.4592e-03 (9.4592e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.194)\tLoss 3.9152e-01 (2.8531e-01)\tAcc@1  85.94 ( 91.20)\n",
      "Monitored (fake) accuracy * Acc@1 90.233\n",
      "Epoch: [23][  0/562]\tTime  1.308 ( 1.308)\tData  0.962 ( 0.962)\tLoss 3.8860e-01 (3.8860e-01)\tAcc@1  87.50 ( 87.50)\n",
      "Epoch: [23][100/562]\tTime  0.186 ( 0.197)\tData  0.000 ( 0.010)\tLoss 3.8858e-01 (4.6242e-01)\tAcc@1  90.62 ( 85.12)\n",
      "Epoch: [23][200/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.005)\tLoss 3.8669e-01 (4.5241e-01)\tAcc@1  84.38 ( 85.51)\n",
      "Epoch: [23][300/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 4.3497e-01 (4.5017e-01)\tAcc@1  89.06 ( 85.65)\n",
      "Epoch: [23][400/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.003)\tLoss 5.3587e-01 (4.4604e-01)\tAcc@1  84.38 ( 85.65)\n",
      "Epoch: [23][500/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.002)\tLoss 5.3350e-01 (4.4200e-01)\tAcc@1  82.81 ( 85.76)\n",
      "Test: [  0/141]\tTime  0.918 ( 0.918)\tLoss 2.7457e-03 (2.7457e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.193)\tLoss 3.9913e-01 (2.7176e-01)\tAcc@1  85.94 ( 91.01)\n",
      "Monitored (fake) accuracy * Acc@1 89.878\n",
      "Epoch: [24][  0/562]\tTime  1.083 ( 1.083)\tData  0.893 ( 0.893)\tLoss 3.5672e-01 (3.5672e-01)\tAcc@1  89.06 ( 89.06)\n",
      "Epoch: [24][100/562]\tTime  0.189 ( 0.195)\tData  0.000 ( 0.009)\tLoss 4.7406e-01 (4.4050e-01)\tAcc@1  84.38 ( 85.40)\n",
      "Epoch: [24][200/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.005)\tLoss 7.4440e-01 (4.3487e-01)\tAcc@1  76.56 ( 85.76)\n",
      "Epoch: [24][300/562]\tTime  0.185 ( 0.190)\tData  0.000 ( 0.003)\tLoss 4.2241e-01 (4.3324e-01)\tAcc@1  87.50 ( 85.84)\n",
      "Epoch: [24][400/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.002)\tLoss 4.4717e-01 (4.3502e-01)\tAcc@1  87.50 ( 85.86)\n",
      "Epoch: [24][500/562]\tTime  0.185 ( 0.188)\tData  0.000 ( 0.002)\tLoss 5.1582e-01 (4.3626e-01)\tAcc@1  87.50 ( 85.88)\n",
      "Test: [  0/141]\tTime  0.896 ( 0.896)\tLoss 5.7667e-03 (5.7667e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.192)\tLoss 1.9581e-01 (2.5481e-01)\tAcc@1  92.19 ( 92.09)\n",
      "Monitored (fake) accuracy * Acc@1 90.056\n",
      "Epoch: [25][  0/562]\tTime  1.024 ( 1.024)\tData  0.823 ( 0.823)\tLoss 3.5698e-01 (3.5698e-01)\tAcc@1  92.19 ( 92.19)\n",
      "Epoch: [25][100/562]\tTime  0.185 ( 0.195)\tData  0.000 ( 0.008)\tLoss 6.1224e-01 (4.3474e-01)\tAcc@1  78.12 ( 85.63)\n",
      "Epoch: [25][200/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.004)\tLoss 5.8843e-01 (4.3532e-01)\tAcc@1  81.25 ( 85.95)\n",
      "Epoch: [25][300/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.003)\tLoss 5.3613e-01 (4.3292e-01)\tAcc@1  81.25 ( 85.89)\n",
      "Epoch: [25][400/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.002)\tLoss 4.5153e-01 (4.2378e-01)\tAcc@1  82.81 ( 86.23)\n",
      "Epoch: [25][500/562]\tTime  0.186 ( 0.188)\tData  0.000 ( 0.002)\tLoss 6.1722e-01 (4.2168e-01)\tAcc@1  78.12 ( 86.30)\n",
      "Test: [  0/141]\tTime  0.968 ( 0.968)\tLoss 6.9060e-03 (6.9060e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.194)\tLoss 2.6154e-01 (3.1824e-01)\tAcc@1  92.19 ( 89.59)\n",
      "Monitored (fake) accuracy * Acc@1 89.444\n",
      "Epoch: [26][  0/562]\tTime  1.276 ( 1.276)\tData  0.961 ( 0.961)\tLoss 4.0172e-01 (4.0172e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [26][100/562]\tTime  0.184 ( 0.197)\tData  0.000 ( 0.010)\tLoss 4.7224e-01 (4.1855e-01)\tAcc@1  85.94 ( 86.01)\n",
      "Epoch: [26][200/562]\tTime  0.186 ( 0.192)\tData  0.000 ( 0.005)\tLoss 4.2137e-01 (4.2169e-01)\tAcc@1  87.50 ( 86.23)\n",
      "Epoch: [26][300/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 4.0033e-01 (4.2433e-01)\tAcc@1  89.06 ( 86.15)\n",
      "Epoch: [26][400/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.003)\tLoss 4.5455e-01 (4.1862e-01)\tAcc@1  82.81 ( 86.35)\n",
      "Epoch: [26][500/562]\tTime  0.189 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.6665e-01 (4.1792e-01)\tAcc@1  92.19 ( 86.36)\n",
      "Test: [  0/141]\tTime  0.964 ( 0.964)\tLoss 7.0712e-03 (7.0712e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.193)\tLoss 4.0924e-01 (3.0398e-01)\tAcc@1  87.50 ( 90.21)\n",
      "Monitored (fake) accuracy * Acc@1 88.811\n",
      "Epoch: [27][  0/562]\tTime  1.327 ( 1.327)\tData  0.965 ( 0.965)\tLoss 1.7572e-01 (1.7572e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Epoch: [27][100/562]\tTime  0.187 ( 0.198)\tData  0.000 ( 0.010)\tLoss 3.8108e-01 (4.2579e-01)\tAcc@1  90.62 ( 86.22)\n",
      "Epoch: [27][200/562]\tTime  0.185 ( 0.192)\tData  0.000 ( 0.005)\tLoss 2.6196e-01 (4.1849e-01)\tAcc@1  93.75 ( 86.47)\n",
      "Epoch: [27][300/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 5.5457e-01 (4.1905e-01)\tAcc@1  81.25 ( 86.52)\n",
      "Epoch: [27][400/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.003)\tLoss 4.2468e-01 (4.1739e-01)\tAcc@1  84.38 ( 86.53)\n",
      "Epoch: [27][500/562]\tTime  0.184 ( 0.189)\tData  0.000 ( 0.002)\tLoss 5.2309e-01 (4.1615e-01)\tAcc@1  82.81 ( 86.56)\n",
      "Test: [  0/141]\tTime  0.775 ( 0.775)\tLoss 3.9775e-03 (3.9775e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.191)\tLoss 2.3565e-01 (3.0629e-01)\tAcc@1  92.19 ( 90.35)\n",
      "Monitored (fake) accuracy * Acc@1 89.233\n",
      "Epoch: [28][  0/562]\tTime  1.196 ( 1.196)\tData  1.004 ( 1.004)\tLoss 3.0811e-01 (3.0811e-01)\tAcc@1  84.38 ( 84.38)\n",
      "Epoch: [28][100/562]\tTime  0.187 ( 0.197)\tData  0.000 ( 0.010)\tLoss 4.0094e-01 (4.1387e-01)\tAcc@1  90.62 ( 86.51)\n",
      "Epoch: [28][200/562]\tTime  0.185 ( 0.192)\tData  0.000 ( 0.005)\tLoss 3.2128e-01 (4.2097e-01)\tAcc@1  87.50 ( 86.31)\n",
      "Epoch: [28][300/562]\tTime  0.190 ( 0.190)\tData  0.000 ( 0.004)\tLoss 5.4636e-01 (4.1785e-01)\tAcc@1  82.81 ( 86.32)\n",
      "Epoch: [28][400/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.003)\tLoss 3.9630e-01 (4.1364e-01)\tAcc@1  89.06 ( 86.55)\n",
      "Epoch: [28][500/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.002)\tLoss 1.6965e-01 (4.1464e-01)\tAcc@1  96.88 ( 86.56)\n",
      "Test: [  0/141]\tTime  0.872 ( 0.872)\tLoss 5.2815e-03 (5.2815e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.193)\tLoss 3.1067e-01 (2.9491e-01)\tAcc@1  89.06 ( 90.53)\n",
      "Monitored (fake) accuracy * Acc@1 88.867\n",
      "Epoch: [29][  0/562]\tTime  1.080 ( 1.080)\tData  0.896 ( 0.896)\tLoss 4.4797e-01 (4.4797e-01)\tAcc@1  84.38 ( 84.38)\n",
      "Epoch: [29][100/562]\tTime  0.186 ( 0.195)\tData  0.000 ( 0.009)\tLoss 4.0886e-01 (4.0209e-01)\tAcc@1  89.06 ( 87.14)\n",
      "Epoch: [29][200/562]\tTime  0.187 ( 0.191)\tData  0.001 ( 0.005)\tLoss 4.2816e-01 (3.9610e-01)\tAcc@1  85.94 ( 87.15)\n",
      "Epoch: [29][300/562]\tTime  0.185 ( 0.189)\tData  0.000 ( 0.003)\tLoss 2.8679e-01 (4.0057e-01)\tAcc@1  85.94 ( 86.97)\n",
      "Epoch: [29][400/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.002)\tLoss 4.9412e-01 (4.0547e-01)\tAcc@1  82.81 ( 86.73)\n",
      "Epoch: [29][500/562]\tTime  0.185 ( 0.189)\tData  0.000 ( 0.002)\tLoss 3.4906e-01 (4.0818e-01)\tAcc@1  89.06 ( 86.63)\n",
      "Test: [  0/141]\tTime  0.990 ( 0.990)\tLoss 5.3895e-03 (5.3895e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.193)\tLoss 3.1433e-01 (2.9627e-01)\tAcc@1  89.06 ( 90.66)\n",
      "Monitored (fake) accuracy * Acc@1 88.989\n",
      "correct best accuracy:87.74\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, num_train_samples, train_sampler = get_data_loaders(args)\n",
    "max_iter = args.epochs * (num_train_samples // (args.batch_size * misc.get_world_size()))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_iter, eta_min=0)\n",
    "\n",
    "args.output_dir += '_bn' if args.use_bn else ''\n",
    "if misc.is_main_process() and args.output_dir:\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "args.log_dir += '_bn' if args.use_bn else ''\n",
    "if misc.is_main_process() and args.log_dir:\n",
    "    os.makedirs(args.log_dir, exist_ok=True)\n",
    "    log_writer = SummaryWriter(args.log_dir)\n",
    "else:\n",
    "    log_writer = None\n",
    "\n",
    "max_acc = -1\n",
    "name = None\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    train_stats, train_all_top1, train_all_losses = train(\n",
    "        train_loader, model, linear_classifiers, optimizer, scheduler, epoch, args)\n",
    "    if (epoch + 1) % args.eval_freq != 0:\n",
    "        continue\n",
    "\n",
    "    val_stats, val_all_top1, val_all_losses = \\\n",
    "        validate(val_loader, model, linear_classifiers, args)\n",
    "\n",
    "    all_acc1 = [meter.avg for k, meter in val_all_top1.items()]\n",
    "    acc1 = max(all_acc1)\n",
    "    is_best = acc1 > max_acc\n",
    "\n",
    "    for k, meter in val_all_top1.items():\n",
    "        if meter.avg > max_acc:\n",
    "            max_acc = meter.avg\n",
    "            name = k\n",
    "\n",
    "    if log_writer is not None:\n",
    "        for k, v in train_stats.items():\n",
    "            log_writer.add_scalar('train/{}'.format(k), v, epoch)\n",
    "        for k, v in val_stats.items():\n",
    "            log_writer.add_scalar('val/{}'.format(k), v, epoch)\n",
    "        log_writer.flush()\n",
    "\n",
    "    if misc.is_main_process():  # only the first GPU saves checkpoint\n",
    "        save_checkpoint({\n",
    "            'args': args,\n",
    "            'epoch': epoch + 1,\n",
    "            'model': model.state_dict(),\n",
    "            'linear_classifiers': linear_classifiers.state_dict(),\n",
    "            'acc1': acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, args.output_dir)\n",
    "\n",
    "    for k in train_all_top1.keys():\n",
    "        log_stats = {'train_acc1': train_all_top1[k].avg,\n",
    "                     # 'train_acc5': train_all_top5[k].avg,\n",
    "                     'train_loss': train_all_losses[k].avg,\n",
    "                     'test_acc1': val_all_top1[k].avg,\n",
    "                     # 'test_acc5': val_all_top5[k].avg,\n",
    "                     'test_loss': val_all_losses[k].avg,\n",
    "                     'epoch': epoch}\n",
    "\n",
    "        if misc.is_main_process():\n",
    "            with open(os.path.join(args.output_dir, 'linear_{}.txt'.format(k)), 'a') as f:\n",
    "                f.write(json.dumps(log_stats) + '\\n')\n",
    "\n",
    "if max_acc > 0.0:\n",
    "    print(f\"correct best accuracy:{max_acc:.2f}\")\n",
    "    if misc.is_main_process():\n",
    "        shutil.copyfile(\n",
    "            os.path.join(args.output_dir, 'linear_{}.txt'.format(name)),\n",
    "            os.path.join(args.output_dir, 'linear.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd2b5743-0bfd-46e6-bd3a-b907bac6bfbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T09:29:13.411558Z",
     "iopub.status.busy": "2024-05-12T09:29:13.411305Z",
     "iopub.status.idle": "2024-05-12T09:29:14.995447Z",
     "shell.execute_reply": "2024-05-12T09:29:14.994489Z",
     "shell.execute_reply.started": "2024-05-12T09:29:13.411539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifies: classifier_lr_0_0010\n",
      "Target: [2, 1, 0, 4, 0, 8, 5, 8, 6, 7, 6, 5, 6, 6, 2, 7, 2, 1, 2, 1, 6, 3, 2, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 3, 4, 2, 8, 3, 8, 4, 3, 4, 3, 5, 3, 0, 2, 2]\n",
      "Pred:   [2, 1, 0, 4, 0, 8, 7, 8, 6, 5, 4, 5, 6, 6, 8, 6, 5, 1, 2, 2, 6, 3, 5, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 6, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 7, 0, 4, 8, 8, 4, 2, 8, 3, 8, 4, 3, 4, 3, 1, 3, 0, 2, 2]\n",
      "[tensor([81.2500], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0020\n",
      "Target: [2, 1, 0, 4, 0, 8, 5, 8, 6, 7, 6, 5, 6, 6, 2, 7, 2, 1, 2, 1, 6, 3, 2, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 3, 4, 2, 8, 3, 8, 4, 3, 4, 3, 5, 3, 0, 2, 2]\n",
      "Pred:   [2, 1, 0, 4, 0, 8, 7, 8, 6, 5, 4, 5, 6, 6, 8, 6, 5, 1, 2, 2, 6, 3, 5, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 6, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 7, 0, 4, 8, 8, 4, 2, 8, 3, 8, 4, 3, 4, 3, 1, 3, 0, 2, 2]\n",
      "[tensor([81.2500], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0050\n",
      "Target: [2, 1, 0, 4, 0, 8, 5, 8, 6, 7, 6, 5, 6, 6, 2, 7, 2, 1, 2, 1, 6, 3, 2, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 3, 4, 2, 8, 3, 8, 4, 3, 4, 3, 5, 3, 0, 2, 2]\n",
      "Pred:   [2, 1, 0, 4, 0, 8, 7, 8, 6, 7, 6, 5, 6, 6, 8, 6, 5, 1, 2, 1, 6, 3, 5, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 6, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 7, 0, 4, 8, 8, 4, 2, 8, 3, 8, 4, 3, 4, 3, 1, 3, 0, 2, 2]\n",
      "[tensor([85.9375], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0100\n",
      "Target: [2, 1, 0, 4, 0, 8, 5, 8, 6, 7, 6, 5, 6, 6, 2, 7, 2, 1, 2, 1, 6, 3, 2, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 3, 4, 2, 8, 3, 8, 4, 3, 4, 3, 5, 3, 0, 2, 2]\n",
      "Pred:   [2, 1, 0, 4, 0, 8, 7, 8, 6, 7, 6, 5, 6, 6, 8, 6, 5, 1, 2, 1, 6, 3, 5, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 7, 0, 4, 8, 8, 4, 2, 8, 3, 8, 4, 3, 4, 3, 1, 3, 0, 2, 2]\n",
      "[tensor([87.5000], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0200\n",
      "Target: [2, 1, 0, 4, 0, 8, 5, 8, 6, 7, 6, 5, 6, 6, 2, 7, 2, 1, 2, 1, 6, 3, 2, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 3, 4, 2, 8, 3, 8, 4, 3, 4, 3, 5, 3, 0, 2, 2]\n",
      "Pred:   [2, 1, 0, 4, 0, 8, 7, 8, 6, 7, 6, 5, 6, 6, 2, 6, 5, 1, 2, 1, 6, 3, 5, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 7, 0, 4, 8, 8, 4, 2, 8, 3, 8, 4, 3, 4, 3, 1, 3, 0, 2, 2]\n",
      "[tensor([89.0625], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0500\n",
      "Target: [2, 1, 0, 4, 0, 8, 5, 8, 6, 7, 6, 5, 6, 6, 2, 7, 2, 1, 2, 1, 6, 3, 2, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 3, 4, 2, 8, 3, 8, 4, 3, 4, 3, 5, 3, 0, 2, 2]\n",
      "Pred:   [2, 1, 0, 4, 0, 8, 7, 8, 6, 7, 6, 5, 6, 6, 2, 6, 5, 1, 2, 1, 6, 3, 5, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 7, 0, 4, 8, 8, 4, 2, 8, 3, 8, 6, 3, 4, 3, 1, 3, 0, 2, 2]\n",
      "[tensor([87.5000], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_1000\n",
      "Target: [2, 1, 0, 4, 0, 8, 5, 8, 6, 7, 6, 5, 6, 6, 2, 7, 2, 1, 2, 1, 6, 3, 2, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 3, 4, 2, 8, 3, 8, 4, 3, 4, 3, 5, 3, 0, 2, 2]\n",
      "Pred:   [2, 1, 0, 4, 0, 8, 7, 8, 6, 7, 6, 5, 6, 6, 2, 6, 5, 1, 2, 1, 6, 3, 5, 1, 8, 5, 8, 6, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 7, 0, 4, 8, 8, 4, 2, 8, 3, 8, 6, 3, 4, 3, 5, 3, 0, 2, 2]\n",
      "[tensor([87.5000], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_2000\n",
      "Target: [2, 1, 0, 4, 0, 8, 5, 8, 6, 7, 6, 5, 6, 6, 2, 7, 2, 1, 2, 1, 6, 3, 2, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 3, 4, 2, 8, 3, 8, 4, 3, 4, 3, 5, 3, 0, 2, 2]\n",
      "Pred:   [2, 1, 0, 4, 0, 8, 7, 8, 6, 7, 6, 5, 6, 6, 2, 6, 5, 1, 2, 1, 6, 3, 5, 1, 8, 5, 8, 6, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 8, 4, 2, 8, 3, 8, 6, 3, 4, 2, 5, 3, 0, 2, 2]\n",
      "[tensor([87.5000], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_3000\n",
      "Target: [2, 1, 0, 4, 0, 8, 5, 8, 6, 7, 6, 5, 6, 6, 2, 7, 2, 1, 2, 1, 6, 3, 2, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 3, 4, 2, 8, 3, 8, 4, 3, 4, 3, 5, 3, 0, 2, 2]\n",
      "Pred:   [2, 1, 0, 4, 0, 8, 7, 8, 6, 7, 6, 5, 6, 6, 2, 6, 5, 1, 2, 1, 6, 3, 5, 1, 8, 5, 8, 6, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 8, 4, 2, 8, 3, 8, 6, 3, 4, 2, 5, 3, 0, 2, 2]\n",
      "[tensor([87.5000], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_5000\n",
      "Target: [2, 1, 0, 4, 0, 8, 5, 8, 6, 7, 6, 5, 6, 6, 2, 7, 2, 1, 2, 1, 6, 3, 2, 1, 8, 5, 8, 4, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 7, 5, 8, 8, 5, 0, 4, 8, 3, 4, 2, 8, 3, 8, 4, 3, 4, 3, 5, 3, 0, 2, 2]\n",
      "Pred:   [2, 1, 0, 4, 0, 8, 7, 8, 6, 7, 6, 5, 6, 6, 2, 6, 7, 1, 2, 1, 6, 3, 5, 1, 8, 5, 8, 6, 4, 1, 2, 3, 1, 4, 3, 8, 5, 3, 0, 2, 0, 5, 5, 8, 8, 5, 0, 4, 8, 8, 4, 2, 8, 3, 8, 6, 3, 4, 2, 5, 3, 0, 2, 2]\n",
      "[tensor([85.9375], device='cuda:0')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "visulize_val_dataset = datasets.ImageFolder(\n",
    "    os.path.join(args.data, 'val'), val_transform)\n",
    "visulize_val_loader = torch.utils.data.DataLoader(\n",
    "        visulize_val_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "with torch.no_grad():\n",
    "    for i, (images, target) in enumerate(visulize_val_loader):\n",
    "        if i > 0:\n",
    "            break\n",
    "        images = images.cuda(args.gpu, non_blocking=True)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "        # compute output\n",
    "        features = model.forward_features(images)\n",
    "        outputs = linear_classifiers(features)\n",
    "        # print(outputs)\n",
    "        for key in outputs:       \n",
    "            _, pred = outputs[key].topk(1, 1, True, True)\n",
    "            print(\"classifies:\", key)\n",
    "            print(\"Target:\", target.tolist())\n",
    "            print(\"Pred:  \", pred.t()[0].tolist())\n",
    "            print(accuracy(outputs[key], target, topk=(1,)))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef31141-284b-4dbc-8c2a-6fd93ea50e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
