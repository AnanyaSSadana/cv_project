{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb70403-2740-4e1d-ac77-f1fae4079b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:45.338361Z",
     "iopub.status.busy": "2024-05-15T02:09:45.338049Z",
     "iopub.status.idle": "2024-05-15T02:09:46.176333Z",
     "shell.execute_reply": "2024-05-15T02:09:46.175295Z",
     "shell.execute_reply.started": "2024-05-15T02:09:45.338347Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from util import misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5775166-b433-45d7-9b29-2e043d56f3ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.178448Z",
     "iopub.status.busy": "2024-05-15T02:09:46.178154Z",
     "iopub.status.idle": "2024-05-15T02:09:46.184934Z",
     "shell.execute_reply": "2024-05-15T02:09:46.184171Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.178428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.12.0\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current CUDA device index: 0\n",
      "Current CUDA device name: NVIDIA GeForce RTX 3080\n",
      "CUDA device properties:\n",
      "   Name: NVIDIA GeForce RTX 3080\n",
      "   CUDA capability: 8 . 6\n",
      "   Total memory: 10.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch version\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda:0\")\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available:\", cuda_available)\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the CUDA device count\n",
    "    cuda_device_count = torch.cuda.device_count()\n",
    "    print(\"CUDA device count:\", cuda_device_count)\n",
    "\n",
    "    # Get the current CUDA device index\n",
    "    current_cuda_device = torch.cuda.current_device()\n",
    "    print(\"Current CUDA device index:\", current_cuda_device)\n",
    "\n",
    "    # Get the name of the current CUDA device\n",
    "    current_cuda_device_name = torch.cuda.get_device_name(current_cuda_device)\n",
    "    print(\"Current CUDA device name:\", current_cuda_device_name)\n",
    "\n",
    "    # Get the CUDA device properties\n",
    "    cuda_device_properties = torch.cuda.get_device_properties(current_cuda_device)\n",
    "    print(\"CUDA device properties:\")\n",
    "    print(\"   Name:\", cuda_device_properties.name)\n",
    "    print(\"   CUDA capability:\", cuda_device_properties.major, \".\", cuda_device_properties.minor)\n",
    "    print(\"   Total memory:\", round(cuda_device_properties.total_memory / (1024 ** 3), 1), \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2163f0-9e7a-4b2e-98ca-7a573929b574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.186189Z",
     "iopub.status.busy": "2024-05-15T02:09:46.185890Z",
     "iopub.status.idle": "2024-05-15T02:09:46.205601Z",
     "shell.execute_reply": "2024-05-15T02:09:46.204694Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.186169Z"
    }
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data': './SSL_embeddings/Real/',\n",
    "    'output_dir': './SSL_CRC_outputs_simCLR/',\n",
    "    'log_dir': './logs/',\n",
    "    'model': 'base',\n",
    "    'workers': 12,\n",
    "    'epochs': 30,\n",
    "    'start_epoch': 0,\n",
    "    'batch_size': 64,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 0.,\n",
    "    'print_freq': 100,\n",
    "    'eval_freq': 1,\n",
    "    # 'world_size': 1,\n",
    "    # 'rank': 0,\n",
    "    # 'local_rank': 0,\n",
    "    # 'dist_url': 'env://',\n",
    "    # 'dist_backend': 'nccl',\n",
    "    'seed': None,\n",
    "    'gpu': 0,\n",
    "    'pretrained': './output_dir_simCLR/out/epoch_last.pth',\n",
    "    'use_bn': False,\n",
    "    'num_classes': 9,\n",
    "    'base_lrs': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "    # 'base_lrs': [0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af09efb-222f-4290-99bf-6353e66284b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.206865Z",
     "iopub.status.busy": "2024-05-15T02:09:46.206655Z",
     "iopub.status.idle": "2024-05-15T02:09:46.214982Z",
     "shell.execute_reply": "2024-05-15T02:09:46.214265Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.206850Z"
    }
   },
   "outputs": [],
   "source": [
    "class DictToObject:\n",
    "    def __init__(self, d):\n",
    "        for key, value in d.items():\n",
    "            setattr(self, key, value)\n",
    "args = DictToObject(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af81f65f-8edd-4a38-a541-e7431c51c657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.216088Z",
     "iopub.status.busy": "2024-05-15T02:09:46.215839Z",
     "iopub.status.idle": "2024-05-15T02:09:46.226146Z",
     "shell.execute_reply": "2024-05-15T02:09:46.225312Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.216075Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_and_optimizer(args):\n",
    "    # load pre-trained model\n",
    "    if os.path.isfile(args.pretrained):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.pretrained))\n",
    "        checkpoint = torch.load(args.pretrained, map_location=f\"cuda:{args.gpu}\")\n",
    "        state_dict = checkpoint['model']\n",
    "\n",
    "        prefix = 'visual.'\n",
    "        for k in list(state_dict.keys()):\n",
    "            if k.startswith(prefix) and not k.startswith(prefix + 'head'):\n",
    "                state_dict[k[len('visual.'):]] = state_dict[k]\n",
    "            del state_dict[k]\n",
    "    else:\n",
    "        raise Exception(f\"No pre-trained model specified: {args.pretrained}\")\n",
    "\n",
    "    # create model\n",
    "    model = timm.create_model(f\"vit_{args.model}_patch16_224\", num_classes=args.num_classes)\n",
    "    msg = model.load_state_dict(state_dict, strict=False)\n",
    "    assert set(msg.missing_keys) == {\"head.weight\", \"head.bias\"}\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if name not in ['head.weight', 'head.bias']:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # delete the last fc layer, and instead add a bunch of classifiers\n",
    "    del model.head\n",
    "    feat_dim = model.cls_token.shape[-1]\n",
    "    linear_classifiers, optim_param_groups = add_linear_classifier(\n",
    "        feat_dim, args.num_classes, args.base_lrs, args.batch_size, args.use_bn)\n",
    "\n",
    "    model.cuda(args.gpu)\n",
    "    # if args.distributed:\n",
    "    #     linear_classifiers = torch.nn.parallel.DistributedDataParallel(\n",
    "    #         linear_classifiers, device_ids=[args.gpu])\n",
    "\n",
    "    optimizer = torch.optim.SGD(optim_param_groups,\n",
    "                                lr=0.0,  # fake lr\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    return model, linear_classifiers, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "907b8c23-6783-4176-b146-bf865f442e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.227465Z",
     "iopub.status.busy": "2024-05-15T02:09:46.227007Z",
     "iopub.status.idle": "2024-05-15T02:09:46.239605Z",
     "shell.execute_reply": "2024-05-15T02:09:46.239027Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.227444Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(args):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        os.path.join(args.data, 'train'), train_transform)\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        os.path.join(args.data, 'val'), val_transform)\n",
    "\n",
    "    # if args.distributed:\n",
    "    #     train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    # else:\n",
    "    train_sampler = None\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler, drop_last=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, len(train_dataset), train_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23201f3b-f010-4e00-ae32-88b675040aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.241590Z",
     "iopub.status.busy": "2024-05-15T02:09:46.241192Z",
     "iopub.status.idle": "2024-05-15T02:09:46.252886Z",
     "shell.execute_reply": "2024-05-15T02:09:46.252034Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.241570Z"
    }
   },
   "outputs": [],
   "source": [
    "class AllClassifiers(nn.Module):\n",
    "    def __init__(self, classifiers_dict):\n",
    "        super().__init__()\n",
    "        self.classifiers_dict = nn.ModuleDict()\n",
    "        self.classifiers_dict.update(classifiers_dict)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return {k: v.forward(inputs) for k, v in self.classifiers_dict.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.classifiers_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6530fae1-c16a-4a7d-ad9a-a0226c6aca31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.254269Z",
     "iopub.status.busy": "2024-05-15T02:09:46.254007Z",
     "iopub.status.idle": "2024-05-15T02:09:46.263516Z",
     "shell.execute_reply": "2024-05-15T02:09:46.262842Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.254252Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_linear_classifier(feat_dim, num_classes, learning_rates, batch_size, use_bn=False):\n",
    "    linear_classifier_dict = nn.ModuleDict()\n",
    "    optim_param_groups = []\n",
    "    for blr in learning_rates:\n",
    "        lr = blr * batch_size * misc.get_world_size() / 256\n",
    "\n",
    "        linear_classifier = nn.Linear(feat_dim, num_classes)\n",
    "        linear_classifier.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        linear_classifier.bias.data.zero_()\n",
    "        if use_bn:\n",
    "            linear_classifier = nn.Sequential(\n",
    "                torch.nn.SyncBatchNorm(feat_dim, affine=False, eps=1e-6),\n",
    "                linear_classifier\n",
    "            )\n",
    "        linear_classifier.cuda()\n",
    "\n",
    "        name = f\"{blr:.4f}\".replace('.', '_')\n",
    "        linear_classifier_dict[f\"classifier_lr_{name}\"] = linear_classifier\n",
    "        optim_param_groups.append({\"params\": linear_classifier.parameters(), \"lr\": lr})\n",
    "\n",
    "    # add to ddp mode\n",
    "    linear_classifiers = AllClassifiers(linear_classifier_dict)\n",
    "    print('number of classifiers in totall (with different lr): ', len(linear_classifiers))\n",
    "    return linear_classifiers, optim_param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fd5f7a-4daa-4c86-b715-59070374baa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.264695Z",
     "iopub.status.busy": "2024-05-15T02:09:46.264432Z",
     "iopub.status.idle": "2024-05-15T02:09:46.276440Z",
     "shell.execute_reply": "2024-05-15T02:09:46.275811Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.264678Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "        # print(output)\n",
    "        # print(maxk)\n",
    "        # print(target)\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be0fb25a-d3f9-48ac-a698-0a1a55d6ca5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.277586Z",
     "iopub.status.busy": "2024-05-15T02:09:46.277270Z",
     "iopub.status.idle": "2024-05-15T02:09:46.288973Z",
     "shell.execute_reply": "2024-05-15T02:09:46.288105Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.277558Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, linear_classifiers, optimizer, scheduler, epoch, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        # [batch_time, data_time, losses, top1, top5],\n",
    "        [batch_time, data_time, losses, top1],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    model.eval()\n",
    "    linear_classifiers.train(True)\n",
    "\n",
    "    all_top1 = {k: AverageMeter('Acc@1', ':6.2f') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "    # all_top5 = {k: AverageMeter('Acc@5', ':6.2f') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "    all_losses = {k: AverageMeter('Loss', ':.4e') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        images = images.cuda(args.gpu, non_blocking=True)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            features = model.forward_features(images)\n",
    "        outputs = linear_classifiers(features)\n",
    "\n",
    "        cls_losses = {f\"loss_{k}\": nn.CrossEntropyLoss()(v, target) for k, v in outputs.items()}\n",
    "        loss = sum(cls_losses.values())\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        min_loss = 1e5\n",
    "        max_acc1 = -1\n",
    "        # max_acc5 = -1\n",
    "        for k, v in outputs.items():\n",
    "            # acc1, acc5 = accuracy(v, target, topk=(1, 5))\n",
    "            acc1, _ = accuracy(v, target, topk=(1, 2))\n",
    "            # print(acc1)\n",
    "            all_top1[k].update(acc1.item(), images.size(0))\n",
    "            # all_top5[k].update(acc5.item(), images.size(0))\n",
    "            all_losses[k].update(cls_losses[f\"loss_{k}\"].item(), images.size(0))\n",
    "            min_loss = min(min_loss, cls_losses[f\"loss_{k}\"].item())\n",
    "            max_acc1 = max(max_acc1, acc1.item())\n",
    "            # max_acc5 = max(max_acc5, acc5.item())\n",
    "\n",
    "        # logging the best loss/accuracy across all classifiers\n",
    "        losses.update(min_loss, images.size(0))\n",
    "        top1.update(max_acc1, images.size(0))\n",
    "        # top5.update(max_acc5, images.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "    # return {'acc1': top1.avg, 'acc5': top5.avg, 'loss': losses.avg}, all_top1, all_top5, all_losses\n",
    "    return {'acc1': top1.avg, 'loss': losses.avg}, all_top1, all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba13d88-50e5-4089-9ada-bf6c7e1d7eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.290262Z",
     "iopub.status.busy": "2024-05-15T02:09:46.289747Z",
     "iopub.status.idle": "2024-05-15T02:09:46.302775Z",
     "shell.execute_reply": "2024-05-15T02:09:46.301866Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.290242Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, linear_classifiers, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        # [batch_time, losses, top1, top5],\n",
    "        [batch_time, losses, top1],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    linear_classifiers.eval()\n",
    "\n",
    "    all_top1 = {k: AverageMeter('Acc@1', ':6.2f') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "    # all_top5 = {k: AverageMeter('Acc@5', ':6.2f') for k in linear_classifiers.module.classifiers_dict.keys()}\n",
    "    all_losses = {k: AverageMeter('Loss', ':.4e') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            images = images.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            features = model.forward_features(images)\n",
    "            outputs = linear_classifiers(features)\n",
    "\n",
    "            my_losses = {f\"loss_{k}\": nn.CrossEntropyLoss()(v, target) for k, v in outputs.items()}\n",
    "            min_loss = 1e6\n",
    "            max_acc1 = -1\n",
    "            # max_acc5 = -1\n",
    "            for k, v in outputs.items():\n",
    "                # acc1, acc5 = accuracy(v, target, topk=(1, 5))\n",
    "                acc1, _ = accuracy(v, target, topk=(1, 2))\n",
    "                all_top1[k].update(acc1.item(), images.size(0))\n",
    "                # all_top5[k].update(acc5.item(), images.size(0))\n",
    "                all_losses[k].update(my_losses[f\"loss_{k}\"].item(), images.size(0))\n",
    "                min_loss = min(min_loss, my_losses[f\"loss_{k}\"].item())\n",
    "                max_acc1 = max(max_acc1, acc1.item())\n",
    "                # max_acc5 = max(max_acc5, acc5.item())\n",
    "\n",
    "            # logging the best loss/accuracy across all classifiers\n",
    "            losses.update(min_loss, images.size(0))\n",
    "            top1.update(max_acc1, images.size(0))\n",
    "            # top5.update(max_acc5, images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # print('Monitored (fake) accuracy * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "        #       .format(top1=top1, top5=top5))\n",
    "        print('Monitored (fake) accuracy * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "    # print('acc1', top1.avg)\n",
    "    # print('loss', losses.avg)\n",
    "    # return {'acc1': top1.avg, 'acc5': top5.avg, 'loss': losses.avg}, all_top1, all_top5, all_losses\n",
    "    return {'acc1': top1.avg, 'loss': losses.avg}, all_top1, all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a7ec2fc-b64f-442f-ac2d-32cb8914f0a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.304675Z",
     "iopub.status.busy": "2024-05-15T02:09:46.304075Z",
     "iopub.status.idle": "2024-05-15T02:09:46.315485Z",
     "shell.execute_reply": "2024-05-15T02:09:46.314843Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.304644Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, output_dir):\n",
    "    ckpt_path = f'{output_dir}/linear_checkpoint.pt'\n",
    "    best_path = f'{output_dir}/linear_best.pt'\n",
    "    torch.save(state, ckpt_path)\n",
    "    if is_best:\n",
    "        shutil.copyfile(ckpt_path, best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91954208-4ccf-417e-8687-91027bf0fce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.317272Z",
     "iopub.status.busy": "2024-05-15T02:09:46.316567Z",
     "iopub.status.idle": "2024-05-15T02:09:46.325945Z",
     "shell.execute_reply": "2024-05-15T02:09:46.325310Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.317250Z"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbed858d-c64d-4445-9888-ae032913b862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.327446Z",
     "iopub.status.busy": "2024-05-15T02:09:46.326754Z",
     "iopub.status.idle": "2024-05-15T02:09:46.339267Z",
     "shell.execute_reply": "2024-05-15T02:09:46.338563Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.327414Z"
    }
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a8f644d-c044-47c5-b581-2f874a455ef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:46.340259Z",
     "iopub.status.busy": "2024-05-15T02:09:46.340047Z",
     "iopub.status.idle": "2024-05-15T02:09:53.224651Z",
     "shell.execute_reply": "2024-05-15T02:09:53.224051Z",
     "shell.execute_reply.started": "2024-05-15T02:09:46.340243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './output_dir_simCLR/out/epoch_last.pth'\n",
      "number of classifiers in totall (with different lr):  10\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "model, linear_classifiers, optimizer = get_model_and_optimizer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d44d2257-04c4-4385-8193-3c50304d0070",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T02:09:53.225727Z",
     "iopub.status.busy": "2024-05-15T02:09:53.225522Z",
     "iopub.status.idle": "2024-05-15T03:18:12.695801Z",
     "shell.execute_reply": "2024-05-15T03:18:12.685953Z",
     "shell.execute_reply.started": "2024-05-15T02:09:53.225702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/562]\tTime 28.353 (28.353)\tData  5.694 ( 5.694)\tLoss 2.1876e+00 (2.1876e+00)\tAcc@1  17.19 ( 17.19)\n",
      "Epoch: [0][100/562]\tTime  0.180 ( 0.462)\tData  0.001 ( 0.057)\tLoss 7.1814e-01 (9.6665e-01)\tAcc@1  73.44 ( 68.05)\n",
      "Epoch: [0][200/562]\tTime  0.181 ( 0.321)\tData  0.000 ( 0.029)\tLoss 8.0190e-01 (8.4825e-01)\tAcc@1  73.44 ( 72.06)\n",
      "Epoch: [0][300/562]\tTime  0.181 ( 0.275)\tData  0.000 ( 0.019)\tLoss 4.9681e-01 (8.0178e-01)\tAcc@1  87.50 ( 73.73)\n",
      "Epoch: [0][400/562]\tTime  0.185 ( 0.252)\tData  0.000 ( 0.015)\tLoss 7.4149e-01 (7.7185e-01)\tAcc@1  68.75 ( 74.72)\n",
      "Epoch: [0][500/562]\tTime  0.187 ( 0.239)\tData  0.000 ( 0.012)\tLoss 6.2927e-01 (7.5595e-01)\tAcc@1  81.25 ( 75.25)\n",
      "Test: [  0/141]\tTime  1.096 ( 1.096)\tLoss 1.7843e-06 (1.7843e-06)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.183 ( 0.197)\tLoss 3.5193e-01 (4.2302e-01)\tAcc@1  89.06 ( 88.34)\n",
      "Monitored (fake) accuracy * Acc@1 88.911\n",
      "Epoch: [1][  0/562]\tTime  1.088 ( 1.088)\tData  0.757 ( 0.757)\tLoss 7.7781e-01 (7.7781e-01)\tAcc@1  76.56 ( 76.56)\n",
      "Epoch: [1][100/562]\tTime  0.191 ( 0.198)\tData  0.000 ( 0.009)\tLoss 6.2956e-01 (6.8776e-01)\tAcc@1  79.69 ( 77.18)\n",
      "Epoch: [1][200/562]\tTime  0.188 ( 0.193)\tData  0.000 ( 0.004)\tLoss 6.1150e-01 (6.8072e-01)\tAcc@1  79.69 ( 77.55)\n",
      "Epoch: [1][300/562]\tTime  0.189 ( 0.192)\tData  0.000 ( 0.003)\tLoss 5.4929e-01 (6.7005e-01)\tAcc@1  84.38 ( 77.95)\n",
      "Epoch: [1][400/562]\tTime  0.188 ( 0.191)\tData  0.000 ( 0.002)\tLoss 6.0393e-01 (6.5917e-01)\tAcc@1  82.81 ( 78.31)\n",
      "Epoch: [1][500/562]\tTime  0.190 ( 0.191)\tData  0.000 ( 0.002)\tLoss 6.7834e-01 (6.5775e-01)\tAcc@1  73.44 ( 78.32)\n",
      "Test: [  0/141]\tTime  1.216 ( 1.216)\tLoss 4.2993e-02 (4.2993e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.190 ( 0.196)\tLoss 4.8062e-01 (4.1712e-01)\tAcc@1  85.94 ( 86.40)\n",
      "Monitored (fake) accuracy * Acc@1 87.889\n",
      "Epoch: [2][  0/562]\tTime  1.503 ( 1.503)\tData  1.099 ( 1.099)\tLoss 6.5252e-01 (6.5252e-01)\tAcc@1  78.12 ( 78.12)\n",
      "Epoch: [2][100/562]\tTime  0.188 ( 0.201)\tData  0.000 ( 0.011)\tLoss 5.7197e-01 (6.3114e-01)\tAcc@1  78.12 ( 79.29)\n",
      "Epoch: [2][200/562]\tTime  0.186 ( 0.194)\tData  0.000 ( 0.006)\tLoss 7.3745e-01 (6.3788e-01)\tAcc@1  76.56 ( 78.84)\n",
      "Epoch: [2][300/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.004)\tLoss 6.7373e-01 (6.4377e-01)\tAcc@1  78.12 ( 78.68)\n",
      "Epoch: [2][400/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.003)\tLoss 6.3282e-01 (6.3913e-01)\tAcc@1  76.56 ( 78.88)\n",
      "Epoch: [2][500/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.002)\tLoss 6.1089e-01 (6.3926e-01)\tAcc@1  79.69 ( 78.83)\n",
      "Test: [  0/141]\tTime  0.898 ( 0.898)\tLoss 5.5691e-02 (5.5691e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.188 ( 0.194)\tLoss 5.7785e-01 (3.1449e-01)\tAcc@1  76.56 ( 90.73)\n",
      "Monitored (fake) accuracy * Acc@1 90.044\n",
      "Epoch: [3][  0/562]\tTime  0.912 ( 0.912)\tData  0.651 ( 0.651)\tLoss 5.3522e-01 (5.3522e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [3][100/562]\tTime  0.189 ( 0.196)\tData  0.000 ( 0.008)\tLoss 6.3616e-01 (6.3402e-01)\tAcc@1  78.12 ( 79.25)\n",
      "Epoch: [3][200/562]\tTime  0.188 ( 0.192)\tData  0.000 ( 0.004)\tLoss 7.6150e-01 (6.2620e-01)\tAcc@1  73.44 ( 79.63)\n",
      "Epoch: [3][300/562]\tTime  0.185 ( 0.191)\tData  0.000 ( 0.003)\tLoss 7.4503e-01 (6.2951e-01)\tAcc@1  75.00 ( 79.33)\n",
      "Epoch: [3][400/562]\tTime  0.190 ( 0.190)\tData  0.000 ( 0.002)\tLoss 5.9566e-01 (6.2748e-01)\tAcc@1  76.56 ( 79.25)\n",
      "Epoch: [3][500/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.002)\tLoss 5.1039e-01 (6.2600e-01)\tAcc@1  82.81 ( 79.23)\n",
      "Test: [  0/141]\tTime  1.561 ( 1.561)\tLoss 2.7763e-05 (2.7763e-05)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.206)\tLoss 6.2902e-01 (2.7223e-01)\tAcc@1  76.56 ( 93.72)\n",
      "Monitored (fake) accuracy * Acc@1 90.089\n",
      "Epoch: [4][  0/562]\tTime  1.421 ( 1.421)\tData  1.083 ( 1.083)\tLoss 6.3968e-01 (6.3968e-01)\tAcc@1  75.00 ( 75.00)\n",
      "Epoch: [4][100/562]\tTime  0.191 ( 0.204)\tData  0.000 ( 0.011)\tLoss 5.2909e-01 (6.1767e-01)\tAcc@1  84.38 ( 79.55)\n",
      "Epoch: [4][200/562]\tTime  0.189 ( 0.196)\tData  0.000 ( 0.006)\tLoss 7.3611e-01 (6.1452e-01)\tAcc@1  76.56 ( 79.96)\n",
      "Epoch: [4][300/562]\tTime  0.190 ( 0.194)\tData  0.000 ( 0.004)\tLoss 7.6464e-01 (6.1342e-01)\tAcc@1  78.12 ( 79.95)\n",
      "Epoch: [4][400/562]\tTime  0.200 ( 0.196)\tData  0.000 ( 0.003)\tLoss 5.9350e-01 (6.1565e-01)\tAcc@1  82.81 ( 79.74)\n",
      "Epoch: [4][500/562]\tTime  0.188 ( 0.195)\tData  0.000 ( 0.002)\tLoss 6.6312e-01 (6.1769e-01)\tAcc@1  75.00 ( 79.68)\n",
      "Test: [  0/141]\tTime  0.975 ( 0.975)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.198)\tLoss 4.4934e-01 (3.6549e-01)\tAcc@1  84.38 ( 90.53)\n",
      "Monitored (fake) accuracy * Acc@1 89.833\n",
      "Epoch: [5][  0/562]\tTime  1.546 ( 1.546)\tData  1.156 ( 1.156)\tLoss 5.2747e-01 (5.2747e-01)\tAcc@1  84.38 ( 84.38)\n",
      "Epoch: [5][100/562]\tTime  0.192 ( 0.201)\tData  0.000 ( 0.012)\tLoss 5.2808e-01 (6.0699e-01)\tAcc@1  84.38 ( 80.35)\n",
      "Epoch: [5][200/562]\tTime  0.188 ( 0.196)\tData  0.000 ( 0.006)\tLoss 8.9187e-01 (6.1900e-01)\tAcc@1  70.31 ( 79.91)\n",
      "Epoch: [5][300/562]\tTime  0.199 ( 0.193)\tData  0.000 ( 0.004)\tLoss 6.2129e-01 (6.1461e-01)\tAcc@1  76.56 ( 79.93)\n",
      "Epoch: [5][400/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.003)\tLoss 4.2411e-01 (6.1778e-01)\tAcc@1  87.50 ( 79.91)\n",
      "Epoch: [5][500/562]\tTime  0.200 ( 0.193)\tData  0.000 ( 0.003)\tLoss 6.5596e-01 (6.1676e-01)\tAcc@1  76.56 ( 79.94)\n",
      "Test: [  0/141]\tTime  1.168 ( 1.168)\tLoss 2.8777e-02 (2.8777e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.189 ( 0.198)\tLoss 4.9800e-01 (3.2986e-01)\tAcc@1  79.69 ( 90.47)\n",
      "Monitored (fake) accuracy * Acc@1 89.022\n",
      "Epoch: [6][  0/562]\tTime  1.107 ( 1.107)\tData  0.902 ( 0.902)\tLoss 5.3581e-01 (5.3581e-01)\tAcc@1  82.81 ( 82.81)\n",
      "Epoch: [6][100/562]\tTime  0.194 ( 0.201)\tData  0.000 ( 0.009)\tLoss 6.6261e-01 (6.2259e-01)\tAcc@1  75.00 ( 79.75)\n",
      "Epoch: [6][200/562]\tTime  0.189 ( 0.195)\tData  0.000 ( 0.005)\tLoss 8.1393e-01 (6.1859e-01)\tAcc@1  78.12 ( 79.64)\n",
      "Epoch: [6][300/562]\tTime  0.187 ( 0.193)\tData  0.000 ( 0.003)\tLoss 6.1749e-01 (6.1356e-01)\tAcc@1  79.69 ( 79.84)\n",
      "Epoch: [6][400/562]\tTime  0.187 ( 0.194)\tData  0.000 ( 0.002)\tLoss 5.8206e-01 (6.0978e-01)\tAcc@1  76.56 ( 80.03)\n",
      "Epoch: [6][500/562]\tTime  0.188 ( 0.193)\tData  0.000 ( 0.002)\tLoss 5.8267e-01 (6.1175e-01)\tAcc@1  79.69 ( 79.87)\n",
      "Test: [  0/141]\tTime  1.091 ( 1.091)\tLoss 2.9802e-08 (2.9802e-08)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.196)\tLoss 5.9559e-01 (3.3834e-01)\tAcc@1  84.38 ( 89.99)\n",
      "Monitored (fake) accuracy * Acc@1 88.644\n",
      "Epoch: [7][  0/562]\tTime  1.113 ( 1.113)\tData  0.928 ( 0.928)\tLoss 4.1085e-01 (4.1085e-01)\tAcc@1  89.06 ( 89.06)\n",
      "Epoch: [7][100/562]\tTime  0.192 ( 0.198)\tData  0.000 ( 0.009)\tLoss 6.6054e-01 (5.9052e-01)\tAcc@1  81.25 ( 80.66)\n",
      "Epoch: [7][200/562]\tTime  0.189 ( 0.193)\tData  0.000 ( 0.005)\tLoss 6.9720e-01 (6.0176e-01)\tAcc@1  79.69 ( 80.35)\n",
      "Epoch: [7][300/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.003)\tLoss 4.5228e-01 (5.9676e-01)\tAcc@1  85.94 ( 80.46)\n",
      "Epoch: [7][400/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.003)\tLoss 7.4361e-01 (5.9885e-01)\tAcc@1  75.00 ( 80.44)\n",
      "Epoch: [7][500/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.002)\tLoss 5.5798e-01 (6.0396e-01)\tAcc@1  78.12 ( 80.22)\n",
      "Test: [  0/141]\tTime  1.016 ( 1.016)\tLoss 5.3488e-04 (5.3488e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.195)\tLoss 5.5133e-01 (2.7140e-01)\tAcc@1  78.12 ( 92.33)\n",
      "Monitored (fake) accuracy * Acc@1 91.000\n",
      "Epoch: [8][  0/562]\tTime  1.458 ( 1.458)\tData  1.070 ( 1.070)\tLoss 5.8069e-01 (5.8069e-01)\tAcc@1  82.81 ( 82.81)\n",
      "Epoch: [8][100/562]\tTime  0.187 ( 0.201)\tData  0.000 ( 0.011)\tLoss 5.6570e-01 (6.2365e-01)\tAcc@1  82.81 ( 79.10)\n",
      "Epoch: [8][200/562]\tTime  0.188 ( 0.194)\tData  0.000 ( 0.006)\tLoss 4.0857e-01 (6.0853e-01)\tAcc@1  89.06 ( 79.72)\n",
      "Epoch: [8][300/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.004)\tLoss 7.4653e-01 (6.0413e-01)\tAcc@1  85.94 ( 79.98)\n",
      "Epoch: [8][400/562]\tTime  0.185 ( 0.191)\tData  0.000 ( 0.003)\tLoss 4.7795e-01 (6.0060e-01)\tAcc@1  84.38 ( 80.15)\n",
      "Epoch: [8][500/562]\tTime  0.188 ( 0.191)\tData  0.000 ( 0.002)\tLoss 6.9576e-01 (5.9994e-01)\tAcc@1  78.12 ( 80.15)\n",
      "Test: [  0/141]\tTime  0.976 ( 0.976)\tLoss 2.5846e-03 (2.5846e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.190 ( 0.195)\tLoss 5.7361e-01 (3.5642e-01)\tAcc@1  76.56 ( 90.30)\n",
      "Monitored (fake) accuracy * Acc@1 89.011\n",
      "Epoch: [9][  0/562]\tTime  1.399 ( 1.399)\tData  1.064 ( 1.064)\tLoss 7.6658e-01 (7.6658e-01)\tAcc@1  81.25 ( 81.25)\n",
      "Epoch: [9][100/562]\tTime  0.190 ( 0.200)\tData  0.000 ( 0.011)\tLoss 6.0734e-01 (6.1770e-01)\tAcc@1  78.12 ( 79.94)\n",
      "Epoch: [9][200/562]\tTime  0.191 ( 0.194)\tData  0.000 ( 0.005)\tLoss 5.7723e-01 (6.0826e-01)\tAcc@1  76.56 ( 80.05)\n",
      "Epoch: [9][300/562]\tTime  0.186 ( 0.192)\tData  0.000 ( 0.004)\tLoss 3.8773e-01 (6.0116e-01)\tAcc@1  87.50 ( 80.26)\n",
      "Epoch: [9][400/562]\tTime  0.194 ( 0.191)\tData  0.000 ( 0.003)\tLoss 6.7479e-01 (5.9772e-01)\tAcc@1  79.69 ( 80.46)\n",
      "Epoch: [9][500/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.002)\tLoss 6.1972e-01 (5.9424e-01)\tAcc@1  79.69 ( 80.61)\n",
      "Test: [  0/141]\tTime  1.070 ( 1.070)\tLoss 1.6267e-02 (1.6267e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.196)\tLoss 6.9528e-01 (2.8500e-01)\tAcc@1  78.12 ( 91.99)\n",
      "Monitored (fake) accuracy * Acc@1 90.011\n",
      "Epoch: [10][  0/562]\tTime  1.481 ( 1.481)\tData  1.093 ( 1.093)\tLoss 7.4130e-01 (7.4130e-01)\tAcc@1  76.56 ( 76.56)\n",
      "Epoch: [10][100/562]\tTime  0.193 ( 0.201)\tData  0.000 ( 0.011)\tLoss 5.2658e-01 (6.0995e-01)\tAcc@1  82.81 ( 80.77)\n",
      "Epoch: [10][200/562]\tTime  0.189 ( 0.195)\tData  0.000 ( 0.006)\tLoss 5.5707e-01 (5.9920e-01)\tAcc@1  84.38 ( 80.69)\n",
      "Epoch: [10][300/562]\tTime  0.187 ( 0.193)\tData  0.000 ( 0.004)\tLoss 5.5186e-01 (6.0240e-01)\tAcc@1  82.81 ( 80.48)\n",
      "Epoch: [10][400/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.003)\tLoss 6.0575e-01 (6.0222e-01)\tAcc@1  81.25 ( 80.33)\n",
      "Epoch: [10][500/562]\tTime  0.189 ( 0.191)\tData  0.000 ( 0.002)\tLoss 5.1650e-01 (5.9740e-01)\tAcc@1  81.25 ( 80.38)\n",
      "Test: [  0/141]\tTime  0.918 ( 0.918)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.195)\tLoss 3.4888e-01 (3.4560e-01)\tAcc@1  87.50 ( 91.15)\n",
      "Monitored (fake) accuracy * Acc@1 91.489\n",
      "Epoch: [11][  0/562]\tTime  1.242 ( 1.242)\tData  0.860 ( 0.860)\tLoss 6.1629e-01 (6.1629e-01)\tAcc@1  76.56 ( 76.56)\n",
      "Epoch: [11][100/562]\tTime  0.187 ( 0.198)\tData  0.000 ( 0.009)\tLoss 4.7247e-01 (6.1195e-01)\tAcc@1  84.38 ( 79.38)\n",
      "Epoch: [11][200/562]\tTime  0.188 ( 0.193)\tData  0.000 ( 0.004)\tLoss 5.5305e-01 (6.0867e-01)\tAcc@1  79.69 ( 79.99)\n",
      "Epoch: [11][300/562]\tTime  0.191 ( 0.191)\tData  0.000 ( 0.003)\tLoss 6.2794e-01 (5.9315e-01)\tAcc@1  82.81 ( 80.63)\n",
      "Epoch: [11][400/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.002)\tLoss 8.0317e-01 (5.9016e-01)\tAcc@1  82.81 ( 80.80)\n",
      "Epoch: [11][500/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.002)\tLoss 6.3996e-01 (5.8985e-01)\tAcc@1  76.56 ( 80.78)\n",
      "Test: [  0/141]\tTime  1.104 ( 1.104)\tLoss 5.2911e-03 (5.2911e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.196)\tLoss 3.0659e-01 (3.6197e-01)\tAcc@1  89.06 ( 89.62)\n",
      "Monitored (fake) accuracy * Acc@1 89.611\n",
      "Epoch: [12][  0/562]\tTime  1.386 ( 1.386)\tData  1.026 ( 1.026)\tLoss 4.8285e-01 (4.8285e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [12][100/562]\tTime  0.186 ( 0.201)\tData  0.000 ( 0.010)\tLoss 5.2041e-01 (5.8977e-01)\tAcc@1  84.38 ( 80.82)\n",
      "Epoch: [12][200/562]\tTime  0.187 ( 0.196)\tData  0.000 ( 0.005)\tLoss 5.0514e-01 (5.8381e-01)\tAcc@1  85.94 ( 80.91)\n",
      "Epoch: [12][300/562]\tTime  0.188 ( 0.193)\tData  0.000 ( 0.004)\tLoss 5.5699e-01 (5.9291e-01)\tAcc@1  85.94 ( 80.73)\n",
      "Epoch: [12][400/562]\tTime  0.191 ( 0.192)\tData  0.000 ( 0.003)\tLoss 5.2766e-01 (5.9001e-01)\tAcc@1  82.81 ( 80.83)\n",
      "Epoch: [12][500/562]\tTime  0.188 ( 0.192)\tData  0.000 ( 0.002)\tLoss 4.2025e-01 (5.8917e-01)\tAcc@1  87.50 ( 80.80)\n",
      "Test: [  0/141]\tTime  1.080 ( 1.080)\tLoss 2.1966e-02 (2.1966e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.197)\tLoss 6.4356e-01 (2.9080e-01)\tAcc@1  76.56 ( 91.55)\n",
      "Monitored (fake) accuracy * Acc@1 90.767\n",
      "Epoch: [13][  0/562]\tTime  1.204 ( 1.204)\tData  1.021 ( 1.021)\tLoss 6.8152e-01 (6.8152e-01)\tAcc@1  78.12 ( 78.12)\n",
      "Epoch: [13][100/562]\tTime  0.185 ( 0.198)\tData  0.000 ( 0.010)\tLoss 5.5415e-01 (5.6630e-01)\tAcc@1  82.81 ( 81.10)\n",
      "Epoch: [13][200/562]\tTime  0.185 ( 0.194)\tData  0.000 ( 0.005)\tLoss 4.7589e-01 (5.7687e-01)\tAcc@1  79.69 ( 81.20)\n",
      "Epoch: [13][300/562]\tTime  0.188 ( 0.192)\tData  0.000 ( 0.004)\tLoss 4.6040e-01 (5.7928e-01)\tAcc@1  81.25 ( 81.18)\n",
      "Epoch: [13][400/562]\tTime  0.185 ( 0.191)\tData  0.000 ( 0.003)\tLoss 7.0556e-01 (5.7489e-01)\tAcc@1  81.25 ( 81.38)\n",
      "Epoch: [13][500/562]\tTime  0.191 ( 0.191)\tData  0.000 ( 0.002)\tLoss 3.2462e-01 (5.7489e-01)\tAcc@1  89.06 ( 81.37)\n",
      "Test: [  0/141]\tTime  0.968 ( 0.968)\tLoss 9.2758e-07 (9.2758e-07)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.191 ( 0.195)\tLoss 7.8720e-01 (3.1943e-01)\tAcc@1  75.00 ( 90.07)\n",
      "Monitored (fake) accuracy * Acc@1 89.378\n",
      "Epoch: [14][  0/562]\tTime  1.298 ( 1.298)\tData  0.928 ( 0.928)\tLoss 6.6244e-01 (6.6244e-01)\tAcc@1  78.12 ( 78.12)\n",
      "Epoch: [14][100/562]\tTime  0.190 ( 0.200)\tData  0.000 ( 0.009)\tLoss 5.5724e-01 (5.6589e-01)\tAcc@1  87.50 ( 81.78)\n",
      "Epoch: [14][200/562]\tTime  0.190 ( 0.197)\tData  0.000 ( 0.005)\tLoss 4.4659e-01 (5.7522e-01)\tAcc@1  82.81 ( 81.31)\n",
      "Epoch: [14][300/562]\tTime  0.200 ( 0.197)\tData  0.000 ( 0.003)\tLoss 4.9292e-01 (5.7502e-01)\tAcc@1  82.81 ( 81.43)\n",
      "Epoch: [14][400/562]\tTime  0.186 ( 0.195)\tData  0.000 ( 0.003)\tLoss 5.4863e-01 (5.7572e-01)\tAcc@1  82.81 ( 81.41)\n",
      "Epoch: [14][500/562]\tTime  0.186 ( 0.194)\tData  0.000 ( 0.002)\tLoss 5.3238e-01 (5.7278e-01)\tAcc@1  84.38 ( 81.44)\n",
      "Test: [  0/141]\tTime  1.245 ( 1.245)\tLoss 3.2887e-02 (3.2887e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.197)\tLoss 6.1860e-01 (3.1595e-01)\tAcc@1  76.56 ( 89.93)\n",
      "Monitored (fake) accuracy * Acc@1 89.567\n",
      "Epoch: [15][  0/562]\tTime  1.204 ( 1.204)\tData  0.831 ( 0.831)\tLoss 5.7767e-01 (5.7767e-01)\tAcc@1  76.56 ( 76.56)\n",
      "Epoch: [15][100/562]\tTime  0.187 ( 0.197)\tData  0.000 ( 0.008)\tLoss 6.5463e-01 (5.6021e-01)\tAcc@1  76.56 ( 81.53)\n",
      "Epoch: [15][200/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.004)\tLoss 4.6248e-01 (5.6428e-01)\tAcc@1  84.38 ( 81.66)\n",
      "Epoch: [15][300/562]\tTime  0.185 ( 0.191)\tData  0.000 ( 0.003)\tLoss 4.1630e-01 (5.6251e-01)\tAcc@1  85.94 ( 81.72)\n",
      "Epoch: [15][400/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.002)\tLoss 5.4156e-01 (5.6303e-01)\tAcc@1  81.25 ( 81.75)\n",
      "Epoch: [15][500/562]\tTime  0.189 ( 0.190)\tData  0.000 ( 0.002)\tLoss 4.0242e-01 (5.6233e-01)\tAcc@1  85.94 ( 81.79)\n",
      "Test: [  0/141]\tTime  1.112 ( 1.112)\tLoss 1.1368e-02 (1.1368e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.190 ( 0.196)\tLoss 2.6321e-01 (3.6046e-01)\tAcc@1  90.62 ( 88.86)\n",
      "Monitored (fake) accuracy * Acc@1 89.600\n",
      "Epoch: [16][  0/562]\tTime  1.500 ( 1.500)\tData  1.158 ( 1.158)\tLoss 5.9178e-01 (5.9178e-01)\tAcc@1  79.69 ( 79.69)\n",
      "Epoch: [16][100/562]\tTime  0.185 ( 0.202)\tData  0.000 ( 0.012)\tLoss 7.5684e-01 (5.6443e-01)\tAcc@1  79.69 ( 81.82)\n",
      "Epoch: [16][200/562]\tTime  0.187 ( 0.195)\tData  0.000 ( 0.006)\tLoss 5.6425e-01 (5.6802e-01)\tAcc@1  81.25 ( 81.58)\n",
      "Epoch: [16][300/562]\tTime  0.193 ( 0.192)\tData  0.000 ( 0.004)\tLoss 5.8469e-01 (5.6492e-01)\tAcc@1  79.69 ( 81.78)\n",
      "Epoch: [16][400/562]\tTime  0.188 ( 0.191)\tData  0.000 ( 0.003)\tLoss 6.1425e-01 (5.6157e-01)\tAcc@1  78.12 ( 81.85)\n",
      "Epoch: [16][500/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.003)\tLoss 6.8195e-01 (5.6409e-01)\tAcc@1  76.56 ( 81.75)\n",
      "Test: [  0/141]\tTime  0.802 ( 0.802)\tLoss 2.5511e-04 (2.5511e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.188 ( 0.193)\tLoss 1.7334e-01 (2.9805e-01)\tAcc@1  93.75 ( 90.19)\n",
      "Monitored (fake) accuracy * Acc@1 88.644\n",
      "Epoch: [17][  0/562]\tTime  1.430 ( 1.430)\tData  1.049 ( 1.049)\tLoss 7.1746e-01 (7.1746e-01)\tAcc@1  71.88 ( 71.88)\n",
      "Epoch: [17][100/562]\tTime  0.185 ( 0.200)\tData  0.000 ( 0.011)\tLoss 7.0779e-01 (5.4844e-01)\tAcc@1  75.00 ( 82.47)\n",
      "Epoch: [17][200/562]\tTime  0.188 ( 0.194)\tData  0.000 ( 0.005)\tLoss 6.3118e-01 (5.6209e-01)\tAcc@1  81.25 ( 82.21)\n",
      "Epoch: [17][300/562]\tTime  0.193 ( 0.193)\tData  0.000 ( 0.004)\tLoss 7.3481e-01 (5.6086e-01)\tAcc@1  73.44 ( 82.25)\n",
      "Epoch: [17][400/562]\tTime  0.191 ( 0.192)\tData  0.000 ( 0.003)\tLoss 6.9176e-01 (5.6453e-01)\tAcc@1  78.12 ( 81.99)\n",
      "Epoch: [17][500/562]\tTime  0.188 ( 0.192)\tData  0.000 ( 0.002)\tLoss 6.2486e-01 (5.6383e-01)\tAcc@1  79.69 ( 82.01)\n",
      "Test: [  0/141]\tTime  0.939 ( 0.939)\tLoss 2.6379e-05 (2.6379e-05)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.194)\tLoss 4.1232e-01 (3.4831e-01)\tAcc@1  87.50 ( 90.15)\n",
      "Monitored (fake) accuracy * Acc@1 89.844\n",
      "Epoch: [18][  0/562]\tTime  1.528 ( 1.528)\tData  1.219 ( 1.219)\tLoss 5.4035e-01 (5.4035e-01)\tAcc@1  79.69 ( 79.69)\n",
      "Epoch: [18][100/562]\tTime  0.186 ( 0.201)\tData  0.000 ( 0.012)\tLoss 4.7384e-01 (5.5835e-01)\tAcc@1  84.38 ( 82.02)\n",
      "Epoch: [18][200/562]\tTime  0.197 ( 0.197)\tData  0.000 ( 0.006)\tLoss 5.0919e-01 (5.5097e-01)\tAcc@1  81.25 ( 82.42)\n",
      "Epoch: [18][300/562]\tTime  0.188 ( 0.195)\tData  0.000 ( 0.004)\tLoss 6.6096e-01 (5.4951e-01)\tAcc@1  75.00 ( 82.43)\n",
      "Epoch: [18][400/562]\tTime  0.197 ( 0.194)\tData  0.000 ( 0.003)\tLoss 7.5464e-01 (5.5516e-01)\tAcc@1  71.88 ( 82.31)\n",
      "Epoch: [18][500/562]\tTime  0.188 ( 0.193)\tData  0.000 ( 0.003)\tLoss 4.7669e-01 (5.5386e-01)\tAcc@1  85.94 ( 82.41)\n",
      "Test: [  0/141]\tTime  1.292 ( 1.292)\tLoss 3.1596e-02 (3.1596e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.198 ( 0.201)\tLoss 2.9513e-01 (3.1446e-01)\tAcc@1  85.94 ( 90.83)\n",
      "Monitored (fake) accuracy * Acc@1 89.467\n",
      "Epoch: [19][  0/562]\tTime  1.278 ( 1.278)\tData  0.961 ( 0.961)\tLoss 5.8196e-01 (5.8196e-01)\tAcc@1  84.38 ( 84.38)\n",
      "Epoch: [19][100/562]\tTime  0.184 ( 0.200)\tData  0.000 ( 0.010)\tLoss 6.4308e-01 (5.5080e-01)\tAcc@1  79.69 ( 82.55)\n",
      "Epoch: [19][200/562]\tTime  0.186 ( 0.194)\tData  0.000 ( 0.005)\tLoss 4.8096e-01 (5.4820e-01)\tAcc@1  81.25 ( 82.54)\n",
      "Epoch: [19][300/562]\tTime  0.186 ( 0.193)\tData  0.000 ( 0.003)\tLoss 4.7458e-01 (5.5305e-01)\tAcc@1  82.81 ( 82.41)\n",
      "Epoch: [19][400/562]\tTime  0.190 ( 0.192)\tData  0.000 ( 0.003)\tLoss 5.7561e-01 (5.4139e-01)\tAcc@1  82.81 ( 82.64)\n",
      "Epoch: [19][500/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.002)\tLoss 4.4693e-01 (5.4621e-01)\tAcc@1  87.50 ( 82.48)\n",
      "Test: [  0/141]\tTime  1.018 ( 1.018)\tLoss 8.1244e-06 (8.1244e-06)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.194)\tLoss 6.3343e-01 (3.3240e-01)\tAcc@1  76.56 ( 89.56)\n",
      "Monitored (fake) accuracy * Acc@1 88.289\n",
      "Epoch: [20][  0/562]\tTime  1.402 ( 1.402)\tData  1.071 ( 1.071)\tLoss 5.4326e-01 (5.4326e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [20][100/562]\tTime  0.186 ( 0.200)\tData  0.000 ( 0.011)\tLoss 5.0615e-01 (5.4622e-01)\tAcc@1  81.25 ( 82.60)\n",
      "Epoch: [20][200/562]\tTime  0.186 ( 0.194)\tData  0.000 ( 0.006)\tLoss 4.1661e-01 (5.4144e-01)\tAcc@1  84.38 ( 82.74)\n",
      "Epoch: [20][300/562]\tTime  0.192 ( 0.192)\tData  0.000 ( 0.004)\tLoss 6.7297e-01 (5.4907e-01)\tAcc@1  78.12 ( 82.32)\n",
      "Epoch: [20][400/562]\tTime  0.192 ( 0.191)\tData  0.000 ( 0.003)\tLoss 6.1036e-01 (5.4657e-01)\tAcc@1  78.12 ( 82.59)\n",
      "Epoch: [20][500/562]\tTime  0.190 ( 0.191)\tData  0.000 ( 0.002)\tLoss 4.3399e-01 (5.4693e-01)\tAcc@1  82.81 ( 82.55)\n",
      "Test: [  0/141]\tTime  1.509 ( 1.509)\tLoss 2.4673e-03 (2.4673e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.205)\tLoss 5.5135e-01 (3.5624e-01)\tAcc@1  79.69 ( 88.38)\n",
      "Monitored (fake) accuracy * Acc@1 87.478\n",
      "Epoch: [21][  0/562]\tTime  1.053 ( 1.053)\tData  0.858 ( 0.858)\tLoss 5.1823e-01 (5.1823e-01)\tAcc@1  84.38 ( 84.38)\n",
      "Epoch: [21][100/562]\tTime  0.189 ( 0.198)\tData  0.000 ( 0.009)\tLoss 4.8473e-01 (5.4883e-01)\tAcc@1  85.94 ( 82.18)\n",
      "Epoch: [21][200/562]\tTime  0.187 ( 0.195)\tData  0.000 ( 0.005)\tLoss 6.3708e-01 (5.3761e-01)\tAcc@1  81.25 ( 82.48)\n",
      "Epoch: [21][300/562]\tTime  0.190 ( 0.193)\tData  0.000 ( 0.003)\tLoss 7.3497e-01 (5.3907e-01)\tAcc@1  78.12 ( 82.64)\n",
      "Epoch: [21][400/562]\tTime  0.185 ( 0.192)\tData  0.000 ( 0.002)\tLoss 6.1429e-01 (5.3848e-01)\tAcc@1  81.25 ( 82.79)\n",
      "Epoch: [21][500/562]\tTime  0.191 ( 0.191)\tData  0.000 ( 0.002)\tLoss 4.7611e-01 (5.3513e-01)\tAcc@1  89.06 ( 82.95)\n",
      "Test: [  0/141]\tTime  1.044 ( 1.044)\tLoss 4.6677e-03 (4.6677e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.197)\tLoss 3.2675e-01 (2.7707e-01)\tAcc@1  89.06 ( 91.65)\n",
      "Monitored (fake) accuracy * Acc@1 89.356\n",
      "Epoch: [22][  0/562]\tTime  0.868 ( 0.868)\tData  0.655 ( 0.655)\tLoss 5.7790e-01 (5.7790e-01)\tAcc@1  82.81 ( 82.81)\n",
      "Epoch: [22][100/562]\tTime  0.186 ( 0.196)\tData  0.000 ( 0.007)\tLoss 3.7218e-01 (5.3996e-01)\tAcc@1  89.06 ( 82.91)\n",
      "Epoch: [22][200/562]\tTime  0.189 ( 0.192)\tData  0.000 ( 0.003)\tLoss 5.2905e-01 (5.3388e-01)\tAcc@1  82.81 ( 83.37)\n",
      "Epoch: [22][300/562]\tTime  0.188 ( 0.191)\tData  0.000 ( 0.002)\tLoss 5.6352e-01 (5.2663e-01)\tAcc@1  85.94 ( 83.58)\n",
      "Epoch: [22][400/562]\tTime  0.189 ( 0.190)\tData  0.000 ( 0.002)\tLoss 6.4226e-01 (5.2459e-01)\tAcc@1  78.12 ( 83.53)\n",
      "Epoch: [22][500/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.002)\tLoss 4.6371e-01 (5.2478e-01)\tAcc@1  81.25 ( 83.40)\n",
      "Test: [  0/141]\tTime  1.112 ( 1.112)\tLoss 2.8978e-02 (2.8978e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.197)\tLoss 5.0267e-01 (3.6833e-01)\tAcc@1  82.81 ( 88.15)\n",
      "Monitored (fake) accuracy * Acc@1 88.556\n",
      "Epoch: [23][  0/562]\tTime  0.831 ( 0.831)\tData  0.639 ( 0.639)\tLoss 3.2557e-01 (3.2557e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [23][100/562]\tTime  0.185 ( 0.194)\tData  0.000 ( 0.007)\tLoss 4.5168e-01 (5.1106e-01)\tAcc@1  85.94 ( 83.74)\n",
      "Epoch: [23][200/562]\tTime  0.192 ( 0.191)\tData  0.000 ( 0.003)\tLoss 6.1785e-01 (5.0305e-01)\tAcc@1  79.69 ( 83.98)\n",
      "Epoch: [23][300/562]\tTime  0.189 ( 0.190)\tData  0.000 ( 0.002)\tLoss 6.0275e-01 (5.1317e-01)\tAcc@1  82.81 ( 83.61)\n",
      "Epoch: [23][400/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.002)\tLoss 4.4243e-01 (5.1156e-01)\tAcc@1  84.38 ( 83.67)\n",
      "Epoch: [23][500/562]\tTime  0.192 ( 0.189)\tData  0.000 ( 0.001)\tLoss 4.2069e-01 (5.1237e-01)\tAcc@1  85.94 ( 83.65)\n",
      "Test: [  0/141]\tTime  0.919 ( 0.919)\tLoss 2.9950e-03 (2.9950e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.195)\tLoss 5.0401e-01 (3.5752e-01)\tAcc@1  84.38 ( 88.51)\n",
      "Monitored (fake) accuracy * Acc@1 86.978\n",
      "Epoch: [24][  0/562]\tTime  1.058 ( 1.058)\tData  0.865 ( 0.865)\tLoss 5.4016e-01 (5.4016e-01)\tAcc@1  78.12 ( 78.12)\n",
      "Epoch: [24][100/562]\tTime  0.186 ( 0.198)\tData  0.000 ( 0.009)\tLoss 4.1993e-01 (5.1092e-01)\tAcc@1  89.06 ( 83.91)\n",
      "Epoch: [24][200/562]\tTime  0.192 ( 0.193)\tData  0.000 ( 0.005)\tLoss 5.8830e-01 (5.1469e-01)\tAcc@1  81.25 ( 83.71)\n",
      "Epoch: [24][300/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.003)\tLoss 5.0292e-01 (5.1509e-01)\tAcc@1  87.50 ( 83.59)\n",
      "Epoch: [24][400/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.002)\tLoss 6.7275e-01 (5.1937e-01)\tAcc@1  82.81 ( 83.38)\n",
      "Epoch: [24][500/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.002)\tLoss 3.3782e-01 (5.1425e-01)\tAcc@1  89.06 ( 83.53)\n",
      "Test: [  0/141]\tTime  1.366 ( 1.366)\tLoss 5.1937e-04 (5.1937e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.198)\tLoss 3.1758e-01 (3.5020e-01)\tAcc@1  90.62 ( 89.20)\n",
      "Monitored (fake) accuracy * Acc@1 87.133\n",
      "Epoch: [25][  0/562]\tTime  1.005 ( 1.005)\tData  0.821 ( 0.821)\tLoss 4.7208e-01 (4.7208e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Epoch: [25][100/562]\tTime  0.185 ( 0.195)\tData  0.000 ( 0.008)\tLoss 6.1000e-01 (4.9679e-01)\tAcc@1  79.69 ( 84.30)\n",
      "Epoch: [25][200/562]\tTime  0.185 ( 0.191)\tData  0.000 ( 0.004)\tLoss 5.1983e-01 (5.0187e-01)\tAcc@1  79.69 ( 84.27)\n",
      "Epoch: [25][300/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.003)\tLoss 5.0355e-01 (5.0007e-01)\tAcc@1  79.69 ( 84.34)\n",
      "Epoch: [25][400/562]\tTime  0.189 ( 0.189)\tData  0.000 ( 0.002)\tLoss 3.0347e-01 (4.9836e-01)\tAcc@1  89.06 ( 84.36)\n",
      "Epoch: [25][500/562]\tTime  0.191 ( 0.188)\tData  0.000 ( 0.002)\tLoss 4.7942e-01 (5.0008e-01)\tAcc@1  87.50 ( 84.28)\n",
      "Test: [  0/141]\tTime  1.016 ( 1.016)\tLoss 4.6633e-03 (4.6633e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.195)\tLoss 5.4123e-01 (3.6110e-01)\tAcc@1  79.69 ( 89.28)\n",
      "Monitored (fake) accuracy * Acc@1 86.733\n",
      "Epoch: [26][  0/562]\tTime  1.205 ( 1.205)\tData  0.925 ( 0.925)\tLoss 4.7064e-01 (4.7064e-01)\tAcc@1  89.06 ( 89.06)\n",
      "Epoch: [26][100/562]\tTime  0.186 ( 0.198)\tData  0.000 ( 0.009)\tLoss 4.8213e-01 (4.9804e-01)\tAcc@1  79.69 ( 84.17)\n",
      "Epoch: [26][200/562]\tTime  0.193 ( 0.192)\tData  0.001 ( 0.005)\tLoss 4.2849e-01 (4.9650e-01)\tAcc@1  84.38 ( 84.31)\n",
      "Epoch: [26][300/562]\tTime  0.191 ( 0.191)\tData  0.000 ( 0.003)\tLoss 4.6761e-01 (4.9540e-01)\tAcc@1  79.69 ( 84.26)\n",
      "Epoch: [26][400/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 4.9175e-01 (4.9432e-01)\tAcc@1  82.81 ( 84.32)\n",
      "Epoch: [26][500/562]\tTime  0.194 ( 0.190)\tData  0.000 ( 0.002)\tLoss 5.8526e-01 (4.9769e-01)\tAcc@1  78.12 ( 84.19)\n",
      "Test: [  0/141]\tTime  0.936 ( 0.936)\tLoss 5.6618e-03 (5.6618e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.196)\tLoss 5.6258e-01 (4.0031e-01)\tAcc@1  81.25 ( 87.35)\n",
      "Monitored (fake) accuracy * Acc@1 86.122\n",
      "Epoch: [27][  0/562]\tTime  0.900 ( 0.900)\tData  0.700 ( 0.700)\tLoss 4.1518e-01 (4.1518e-01)\tAcc@1  89.06 ( 89.06)\n",
      "Epoch: [27][100/562]\tTime  0.187 ( 0.196)\tData  0.000 ( 0.007)\tLoss 5.3216e-01 (4.9747e-01)\tAcc@1  82.81 ( 84.05)\n",
      "Epoch: [27][200/562]\tTime  0.188 ( 0.192)\tData  0.000 ( 0.004)\tLoss 3.2751e-01 (5.1255e-01)\tAcc@1  87.50 ( 83.70)\n",
      "Epoch: [27][300/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.003)\tLoss 5.3293e-01 (5.0533e-01)\tAcc@1  81.25 ( 83.96)\n",
      "Epoch: [27][400/562]\tTime  0.192 ( 0.190)\tData  0.000 ( 0.002)\tLoss 6.1085e-01 (5.0549e-01)\tAcc@1  79.69 ( 83.90)\n",
      "Epoch: [27][500/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.002)\tLoss 4.7150e-01 (5.0067e-01)\tAcc@1  81.25 ( 84.02)\n",
      "Test: [  0/141]\tTime  1.062 ( 1.062)\tLoss 1.5154e-02 (1.5154e-02)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.189 ( 0.196)\tLoss 5.1233e-01 (4.0120e-01)\tAcc@1  82.81 ( 87.42)\n",
      "Monitored (fake) accuracy * Acc@1 85.800\n",
      "Epoch: [28][  0/562]\tTime  1.026 ( 1.026)\tData  0.842 ( 0.842)\tLoss 5.4322e-01 (5.4322e-01)\tAcc@1  84.38 ( 84.38)\n",
      "Epoch: [28][100/562]\tTime  0.188 ( 0.198)\tData  0.000 ( 0.009)\tLoss 4.2531e-01 (4.8426e-01)\tAcc@1  90.62 ( 84.85)\n",
      "Epoch: [28][200/562]\tTime  0.188 ( 0.193)\tData  0.000 ( 0.004)\tLoss 3.3761e-01 (4.8596e-01)\tAcc@1  90.62 ( 84.77)\n",
      "Epoch: [28][300/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.003)\tLoss 6.5037e-01 (4.8942e-01)\tAcc@1  81.25 ( 84.73)\n",
      "Epoch: [28][400/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.002)\tLoss 6.9794e-01 (4.9310e-01)\tAcc@1  81.25 ( 84.50)\n",
      "Epoch: [28][500/562]\tTime  0.190 ( 0.190)\tData  0.000 ( 0.002)\tLoss 4.1772e-01 (4.9326e-01)\tAcc@1  82.81 ( 84.43)\n",
      "Test: [  0/141]\tTime  1.108 ( 1.108)\tLoss 8.1989e-03 (8.1989e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.183 ( 0.197)\tLoss 5.2411e-01 (3.9193e-01)\tAcc@1  82.81 ( 87.81)\n",
      "Monitored (fake) accuracy * Acc@1 85.856\n",
      "Epoch: [29][  0/562]\tTime  0.795 ( 0.795)\tData  0.595 ( 0.595)\tLoss 5.7427e-01 (5.7427e-01)\tAcc@1  79.69 ( 79.69)\n",
      "Epoch: [29][100/562]\tTime  0.193 ( 0.194)\tData  0.000 ( 0.006)\tLoss 5.0389e-01 (5.0528e-01)\tAcc@1  85.94 ( 84.13)\n",
      "Epoch: [29][200/562]\tTime  0.185 ( 0.191)\tData  0.000 ( 0.003)\tLoss 4.4553e-01 (5.0752e-01)\tAcc@1  87.50 ( 83.96)\n",
      "Epoch: [29][300/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.002)\tLoss 5.2099e-01 (4.9712e-01)\tAcc@1  81.25 ( 84.25)\n",
      "Epoch: [29][400/562]\tTime  0.185 ( 0.189)\tData  0.000 ( 0.002)\tLoss 4.2673e-01 (4.9227e-01)\tAcc@1  89.06 ( 84.21)\n",
      "Epoch: [29][500/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.001)\tLoss 4.6440e-01 (4.9296e-01)\tAcc@1  87.50 ( 84.22)\n",
      "Test: [  0/141]\tTime  0.997 ( 0.997)\tLoss 8.0517e-03 (8.0517e-03)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.190 ( 0.195)\tLoss 5.1496e-01 (3.9336e-01)\tAcc@1  82.81 ( 87.59)\n",
      "Monitored (fake) accuracy * Acc@1 85.789\n",
      "correct best accuracy:84.57\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, num_train_samples, train_sampler = get_data_loaders(args)\n",
    "max_iter = args.epochs * (num_train_samples // (args.batch_size * misc.get_world_size()))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_iter, eta_min=0)\n",
    "\n",
    "args.output_dir += '_bn' if args.use_bn else ''\n",
    "if misc.is_main_process() and args.output_dir:\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "args.log_dir += '_bn' if args.use_bn else ''\n",
    "if misc.is_main_process() and args.log_dir:\n",
    "    os.makedirs(args.log_dir, exist_ok=True)\n",
    "    log_writer = SummaryWriter(args.log_dir)\n",
    "else:\n",
    "    log_writer = None\n",
    "\n",
    "max_acc = -1\n",
    "name = None\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    train_stats, train_all_top1, train_all_losses = train(\n",
    "        train_loader, model, linear_classifiers, optimizer, scheduler, epoch, args)\n",
    "    if (epoch + 1) % args.eval_freq != 0:\n",
    "        continue\n",
    "\n",
    "    val_stats, val_all_top1, val_all_losses = \\\n",
    "        validate(val_loader, model, linear_classifiers, args)\n",
    "\n",
    "    all_acc1 = [meter.avg for k, meter in val_all_top1.items()]\n",
    "    acc1 = max(all_acc1)\n",
    "    is_best = acc1 > max_acc\n",
    "\n",
    "    for k, meter in val_all_top1.items():\n",
    "        if meter.avg > max_acc:\n",
    "            max_acc = meter.avg\n",
    "            name = k\n",
    "\n",
    "    if log_writer is not None:\n",
    "        for k, v in train_stats.items():\n",
    "            log_writer.add_scalar('train/{}'.format(k), v, epoch)\n",
    "        for k, v in val_stats.items():\n",
    "            log_writer.add_scalar('val/{}'.format(k), v, epoch)\n",
    "        log_writer.flush()\n",
    "\n",
    "    if misc.is_main_process():  # only the first GPU saves checkpoint\n",
    "        save_checkpoint({\n",
    "            'args': args,\n",
    "            'epoch': epoch + 1,\n",
    "            'model': model.state_dict(),\n",
    "            'linear_classifiers': linear_classifiers.state_dict(),\n",
    "            'acc1': acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, args.output_dir)\n",
    "\n",
    "    for k in train_all_top1.keys():\n",
    "        log_stats = {'train_acc1': train_all_top1[k].avg,\n",
    "                     # 'train_acc5': train_all_top5[k].avg,\n",
    "                     'train_loss': train_all_losses[k].avg,\n",
    "                     'test_acc1': val_all_top1[k].avg,\n",
    "                     # 'test_acc5': val_all_top5[k].avg,\n",
    "                     'test_loss': val_all_losses[k].avg,\n",
    "                     'epoch': epoch}\n",
    "\n",
    "        if misc.is_main_process():\n",
    "            with open(os.path.join(args.output_dir, 'linear_{}.txt'.format(k)), 'a') as f:\n",
    "                f.write(json.dumps(log_stats) + '\\n')\n",
    "\n",
    "if max_acc > 0.0:\n",
    "    print(f\"correct best accuracy:{max_acc:.2f}\")\n",
    "    if misc.is_main_process():\n",
    "        shutil.copyfile(\n",
    "            os.path.join(args.output_dir, 'linear_{}.txt'.format(name)),\n",
    "            os.path.join(args.output_dir, 'linear.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2b5743-0bfd-46e6-bd3a-b907bac6bfbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T03:18:12.734569Z",
     "iopub.status.busy": "2024-05-15T03:18:12.733197Z",
     "iopub.status.idle": "2024-05-15T03:18:14.218962Z",
     "shell.execute_reply": "2024-05-15T03:18:14.218336Z",
     "shell.execute_reply.started": "2024-05-15T03:18:12.734342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifies: classifier_lr_0_0010\n",
      "Target: [3, 4, 5, 6, 4, 5, 7, 2, 3, 7, 2, 5, 3, 7, 4, 2, 3, 6, 0, 1, 3, 5, 6, 7, 5, 6, 8, 1, 2, 2, 8, 3, 1, 4, 7, 3, 2, 3, 0, 5, 0, 2, 2, 8, 0, 3, 6, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "Pred:   [3, 4, 2, 6, 4, 2, 7, 5, 3, 5, 2, 7, 3, 5, 4, 2, 3, 4, 7, 1, 3, 2, 6, 7, 5, 4, 8, 1, 2, 2, 8, 3, 1, 4, 2, 3, 8, 3, 0, 0, 0, 2, 5, 8, 0, 3, 8, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 5, 5, 4, 5, 6, 6, 1]\n",
      "[tensor([75.], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0020\n",
      "Target: [3, 4, 5, 6, 4, 5, 7, 2, 3, 7, 2, 5, 3, 7, 4, 2, 3, 6, 0, 1, 3, 5, 6, 7, 5, 6, 8, 1, 2, 2, 8, 3, 1, 4, 7, 3, 2, 3, 0, 5, 0, 2, 2, 8, 0, 3, 6, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "Pred:   [3, 4, 2, 6, 4, 2, 7, 5, 3, 5, 2, 7, 3, 5, 4, 2, 3, 4, 7, 1, 3, 2, 6, 7, 5, 4, 8, 1, 2, 2, 8, 3, 1, 4, 2, 3, 8, 3, 0, 0, 0, 2, 5, 8, 0, 3, 8, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "[tensor([76.5625], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0050\n",
      "Target: [3, 4, 5, 6, 4, 5, 7, 2, 3, 7, 2, 5, 3, 7, 4, 2, 3, 6, 0, 1, 3, 5, 6, 7, 5, 6, 8, 1, 2, 2, 8, 3, 1, 4, 7, 3, 2, 3, 0, 5, 0, 2, 2, 8, 0, 3, 6, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "Pred:   [3, 4, 2, 6, 4, 2, 7, 5, 3, 5, 2, 7, 3, 5, 6, 2, 3, 4, 7, 1, 3, 2, 6, 7, 5, 4, 8, 1, 2, 2, 8, 3, 1, 4, 2, 3, 2, 3, 0, 0, 0, 2, 5, 8, 0, 3, 8, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "[tensor([76.5625], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0100\n",
      "Target: [3, 4, 5, 6, 4, 5, 7, 2, 3, 7, 2, 5, 3, 7, 4, 2, 3, 6, 0, 1, 3, 5, 6, 7, 5, 6, 8, 1, 2, 2, 8, 3, 1, 4, 7, 3, 2, 3, 0, 5, 0, 2, 2, 8, 0, 3, 6, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "Pred:   [3, 4, 2, 6, 4, 2, 7, 5, 3, 5, 2, 2, 3, 7, 6, 2, 3, 6, 7, 1, 3, 2, 6, 7, 5, 4, 8, 1, 2, 2, 8, 3, 1, 4, 2, 3, 2, 3, 0, 0, 0, 2, 5, 8, 0, 3, 8, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "[tensor([79.6875], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0200\n",
      "Target: [3, 4, 5, 6, 4, 5, 7, 2, 3, 7, 2, 5, 3, 7, 4, 2, 3, 6, 0, 1, 3, 5, 6, 7, 5, 6, 8, 1, 2, 2, 8, 3, 1, 4, 7, 3, 2, 3, 0, 5, 0, 2, 2, 8, 0, 3, 6, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "Pred:   [3, 4, 2, 6, 4, 2, 7, 5, 3, 5, 2, 2, 3, 7, 6, 2, 3, 6, 7, 1, 3, 2, 6, 7, 5, 4, 8, 1, 2, 2, 8, 3, 1, 4, 2, 3, 2, 3, 0, 0, 0, 2, 2, 8, 0, 3, 8, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "[tensor([81.2500], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0500\n",
      "Target: [3, 4, 5, 6, 4, 5, 7, 2, 3, 7, 2, 5, 3, 7, 4, 2, 3, 6, 0, 1, 3, 5, 6, 7, 5, 6, 8, 1, 2, 2, 8, 3, 1, 4, 7, 3, 2, 3, 0, 5, 0, 2, 2, 8, 0, 3, 6, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "Pred:   [3, 4, 5, 6, 4, 2, 7, 5, 3, 5, 2, 2, 3, 7, 4, 2, 3, 6, 7, 1, 3, 2, 6, 7, 5, 4, 8, 1, 2, 2, 8, 3, 1, 4, 2, 3, 2, 3, 0, 0, 0, 2, 2, 8, 0, 3, 8, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 8, 1]\n",
      "[tensor([82.8125], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_1000\n",
      "Target: [3, 4, 5, 6, 4, 5, 7, 2, 3, 7, 2, 5, 3, 7, 4, 2, 3, 6, 0, 1, 3, 5, 6, 7, 5, 6, 8, 1, 2, 2, 8, 3, 1, 4, 7, 3, 2, 3, 0, 5, 0, 2, 2, 8, 0, 3, 6, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "Pred:   [3, 4, 5, 6, 4, 2, 7, 2, 3, 5, 2, 2, 3, 7, 4, 2, 3, 6, 7, 1, 3, 2, 6, 7, 5, 4, 8, 1, 2, 2, 8, 3, 1, 4, 2, 3, 2, 3, 0, 0, 0, 2, 2, 8, 0, 3, 8, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 8, 1]\n",
      "[tensor([84.3750], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_2000\n",
      "Target: [3, 4, 5, 6, 4, 5, 7, 2, 3, 7, 2, 5, 3, 7, 4, 2, 3, 6, 0, 1, 3, 5, 6, 7, 5, 6, 8, 1, 2, 2, 8, 3, 1, 4, 7, 3, 2, 3, 0, 5, 0, 2, 2, 8, 0, 3, 6, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "Pred:   [3, 4, 5, 6, 4, 2, 7, 2, 3, 5, 2, 2, 3, 7, 4, 2, 3, 6, 7, 1, 3, 2, 6, 7, 5, 4, 8, 1, 2, 2, 8, 3, 1, 4, 2, 3, 2, 3, 0, 0, 0, 2, 2, 8, 0, 3, 8, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 8, 4, 5, 6, 8, 1]\n",
      "[tensor([82.8125], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_3000\n",
      "Target: [3, 4, 5, 6, 4, 5, 7, 2, 3, 7, 2, 5, 3, 7, 4, 2, 3, 6, 0, 1, 3, 5, 6, 7, 5, 6, 8, 1, 2, 2, 8, 3, 1, 4, 7, 3, 2, 3, 0, 5, 0, 2, 2, 8, 0, 3, 6, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "Pred:   [3, 4, 5, 6, 4, 2, 7, 2, 3, 5, 2, 2, 3, 7, 4, 2, 3, 6, 7, 1, 3, 2, 6, 7, 5, 4, 8, 1, 2, 2, 8, 3, 1, 4, 2, 3, 2, 3, 0, 0, 0, 2, 2, 8, 0, 3, 8, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 8, 4, 5, 6, 8, 1]\n",
      "[tensor([82.8125], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_5000\n",
      "Target: [3, 4, 5, 6, 4, 5, 7, 2, 3, 7, 2, 5, 3, 7, 4, 2, 3, 6, 0, 1, 3, 5, 6, 7, 5, 6, 8, 1, 2, 2, 8, 3, 1, 4, 7, 3, 2, 3, 0, 5, 0, 2, 2, 8, 0, 3, 6, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 5, 4, 5, 6, 6, 1]\n",
      "Pred:   [3, 4, 5, 6, 4, 2, 7, 2, 3, 5, 2, 2, 3, 7, 4, 2, 3, 6, 4, 1, 3, 5, 6, 7, 5, 4, 8, 1, 2, 2, 8, 3, 1, 4, 2, 3, 2, 3, 0, 0, 0, 2, 2, 8, 0, 3, 8, 2, 6, 0, 5, 4, 5, 0, 5, 5, 1, 0, 8, 4, 5, 6, 8, 1]\n",
      "[tensor([84.3750], device='cuda:0')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "visulize_val_dataset = datasets.ImageFolder(\n",
    "    os.path.join(args.data, 'val'), val_transform)\n",
    "visulize_val_loader = torch.utils.data.DataLoader(\n",
    "        visulize_val_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "with torch.no_grad():\n",
    "    for i, (images, target) in enumerate(visulize_val_loader):\n",
    "        if i > 0:\n",
    "            break\n",
    "        images = images.cuda(args.gpu, non_blocking=True)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "        # compute output\n",
    "        features = model.forward_features(images)\n",
    "        outputs = linear_classifiers(features)\n",
    "        # print(outputs)\n",
    "        for key in outputs:       \n",
    "            _, pred = outputs[key].topk(1, 1, True, True)\n",
    "            print(\"classifies:\", key)\n",
    "            print(\"Target:\", target.tolist())\n",
    "            print(\"Pred:  \", pred.t()[0].tolist())\n",
    "            print(accuracy(outputs[key], target, topk=(1,)))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef31141-284b-4dbc-8c2a-6fd93ea50e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
