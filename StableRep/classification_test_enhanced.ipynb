{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb70403-2740-4e1d-ac77-f1fae4079b8f",
   "metadata": {
    "execution": {
     "iopub.status.idle": "2024-05-13T18:29:17.439886Z",
     "shell.execute_reply": "2024-05-13T18:29:17.439318Z",
     "shell.execute_reply.started": "2024-05-13T18:29:15.911263Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from util import misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5775166-b433-45d7-9b29-2e043d56f3ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.441160Z",
     "iopub.status.busy": "2024-05-13T18:29:17.440927Z",
     "iopub.status.idle": "2024-05-13T18:29:17.446629Z",
     "shell.execute_reply": "2024-05-13T18:29:17.445982Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.441146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.12.0\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current CUDA device index: 0\n",
      "Current CUDA device name: NVIDIA GeForce RTX 3080\n",
      "CUDA device properties:\n",
      "   Name: NVIDIA GeForce RTX 3080\n",
      "   CUDA capability: 8 . 6\n",
      "   Total memory: 10.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch version\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda:0\")\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available:\", cuda_available)\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the CUDA device count\n",
    "    cuda_device_count = torch.cuda.device_count()\n",
    "    print(\"CUDA device count:\", cuda_device_count)\n",
    "\n",
    "    # Get the current CUDA device index\n",
    "    current_cuda_device = torch.cuda.current_device()\n",
    "    print(\"Current CUDA device index:\", current_cuda_device)\n",
    "\n",
    "    # Get the name of the current CUDA device\n",
    "    current_cuda_device_name = torch.cuda.get_device_name(current_cuda_device)\n",
    "    print(\"Current CUDA device name:\", current_cuda_device_name)\n",
    "\n",
    "    # Get the CUDA device properties\n",
    "    cuda_device_properties = torch.cuda.get_device_properties(current_cuda_device)\n",
    "    print(\"CUDA device properties:\")\n",
    "    print(\"   Name:\", cuda_device_properties.name)\n",
    "    print(\"   CUDA capability:\", cuda_device_properties.major, \".\", cuda_device_properties.minor)\n",
    "    print(\"   Total memory:\", round(cuda_device_properties.total_memory / (1024 ** 3), 1), \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2163f0-9e7a-4b2e-98ca-7a573929b574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.450741Z",
     "iopub.status.busy": "2024-05-13T18:29:17.450051Z",
     "iopub.status.idle": "2024-05-13T18:29:17.455811Z",
     "shell.execute_reply": "2024-05-13T18:29:17.454156Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.450722Z"
    }
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data': './SSL_embeddings/Real/',\n",
    "    'output_dir': './SSL_CRC_outputs_enhanced/',\n",
    "    'log_dir': './logs/',\n",
    "    'model': 'base',\n",
    "    'workers': 12,\n",
    "    'epochs': 30,\n",
    "    'start_epoch': 0,\n",
    "    'batch_size': 64,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 0.,\n",
    "    'print_freq': 100,\n",
    "    'eval_freq': 1,\n",
    "    # 'world_size': 1,\n",
    "    # 'rank': 0,\n",
    "    # 'local_rank': 0,\n",
    "    # 'dist_url': 'env://',\n",
    "    # 'dist_backend': 'nccl',\n",
    "    'seed': None,\n",
    "    'gpu': 0,\n",
    "    'pretrained': './output_dir_enhance/out/epoch_last.pth',\n",
    "    'use_bn': False,\n",
    "    'num_classes': 9,\n",
    "    'base_lrs': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "    # 'base_lrs': [0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af09efb-222f-4290-99bf-6353e66284b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.457126Z",
     "iopub.status.busy": "2024-05-13T18:29:17.456938Z",
     "iopub.status.idle": "2024-05-13T18:29:17.461085Z",
     "shell.execute_reply": "2024-05-13T18:29:17.460099Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.457111Z"
    }
   },
   "outputs": [],
   "source": [
    "class DictToObject:\n",
    "    def __init__(self, d):\n",
    "        for key, value in d.items():\n",
    "            setattr(self, key, value)\n",
    "args = DictToObject(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af81f65f-8edd-4a38-a541-e7431c51c657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.462334Z",
     "iopub.status.busy": "2024-05-13T18:29:17.461876Z",
     "iopub.status.idle": "2024-05-13T18:29:17.468834Z",
     "shell.execute_reply": "2024-05-13T18:29:17.468069Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.462317Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_and_optimizer(args):\n",
    "    # load pre-trained model\n",
    "    if os.path.isfile(args.pretrained):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.pretrained))\n",
    "        checkpoint = torch.load(args.pretrained, map_location=f\"cuda:{args.gpu}\")\n",
    "        state_dict = checkpoint['model']\n",
    "\n",
    "        prefix = 'visual.'\n",
    "        for k in list(state_dict.keys()):\n",
    "            if k.startswith(prefix) and not k.startswith(prefix + 'head'):\n",
    "                state_dict[k[len('visual.'):]] = state_dict[k]\n",
    "            del state_dict[k]\n",
    "    else:\n",
    "        raise Exception(f\"No pre-trained model specified: {args.pretrained}\")\n",
    "\n",
    "    # create model\n",
    "    model = timm.create_model(f\"vit_{args.model}_patch16_224\", num_classes=args.num_classes)\n",
    "    msg = model.load_state_dict(state_dict, strict=False)\n",
    "    assert set(msg.missing_keys) == {\"head.weight\", \"head.bias\"}\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if name not in ['head.weight', 'head.bias']:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # delete the last fc layer, and instead add a bunch of classifiers\n",
    "    del model.head\n",
    "    feat_dim = model.cls_token.shape[-1]\n",
    "    linear_classifiers, optim_param_groups = add_linear_classifier(\n",
    "        feat_dim, args.num_classes, args.base_lrs, args.batch_size, args.use_bn)\n",
    "\n",
    "    model.cuda(args.gpu)\n",
    "    # if args.distributed:\n",
    "    #     linear_classifiers = torch.nn.parallel.DistributedDataParallel(\n",
    "    #         linear_classifiers, device_ids=[args.gpu])\n",
    "\n",
    "    optimizer = torch.optim.SGD(optim_param_groups,\n",
    "                                lr=0.0,  # fake lr\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    return model, linear_classifiers, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "907b8c23-6783-4176-b146-bf865f442e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.470838Z",
     "iopub.status.busy": "2024-05-13T18:29:17.470431Z",
     "iopub.status.idle": "2024-05-13T18:29:17.476851Z",
     "shell.execute_reply": "2024-05-13T18:29:17.476024Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.470818Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(args):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        os.path.join(args.data, 'train'), train_transform)\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        os.path.join(args.data, 'val'), val_transform)\n",
    "\n",
    "    # if args.distributed:\n",
    "    #     train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    # else:\n",
    "    train_sampler = None\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler, drop_last=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, len(train_dataset), train_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23201f3b-f010-4e00-ae32-88b675040aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.478077Z",
     "iopub.status.busy": "2024-05-13T18:29:17.477758Z",
     "iopub.status.idle": "2024-05-13T18:29:17.482850Z",
     "shell.execute_reply": "2024-05-13T18:29:17.482245Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.478061Z"
    }
   },
   "outputs": [],
   "source": [
    "class AllClassifiers(nn.Module):\n",
    "    def __init__(self, classifiers_dict):\n",
    "        super().__init__()\n",
    "        self.classifiers_dict = nn.ModuleDict()\n",
    "        self.classifiers_dict.update(classifiers_dict)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return {k: v.forward(inputs) for k, v in self.classifiers_dict.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.classifiers_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6530fae1-c16a-4a7d-ad9a-a0226c6aca31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.484265Z",
     "iopub.status.busy": "2024-05-13T18:29:17.483608Z",
     "iopub.status.idle": "2024-05-13T18:29:17.488885Z",
     "shell.execute_reply": "2024-05-13T18:29:17.487940Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.484248Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_linear_classifier(feat_dim, num_classes, learning_rates, batch_size, use_bn=False):\n",
    "    linear_classifier_dict = nn.ModuleDict()\n",
    "    optim_param_groups = []\n",
    "    for blr in learning_rates:\n",
    "        lr = blr * batch_size * misc.get_world_size() / 256\n",
    "\n",
    "        linear_classifier = nn.Linear(feat_dim, num_classes)\n",
    "        linear_classifier.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        linear_classifier.bias.data.zero_()\n",
    "        if use_bn:\n",
    "            linear_classifier = nn.Sequential(\n",
    "                torch.nn.SyncBatchNorm(feat_dim, affine=False, eps=1e-6),\n",
    "                linear_classifier\n",
    "            )\n",
    "        linear_classifier.cuda()\n",
    "\n",
    "        name = f\"{blr:.4f}\".replace('.', '_')\n",
    "        linear_classifier_dict[f\"classifier_lr_{name}\"] = linear_classifier\n",
    "        optim_param_groups.append({\"params\": linear_classifier.parameters(), \"lr\": lr})\n",
    "\n",
    "    # add to ddp mode\n",
    "    linear_classifiers = AllClassifiers(linear_classifier_dict)\n",
    "    print('number of classifiers in totall (with different lr): ', len(linear_classifiers))\n",
    "    return linear_classifiers, optim_param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fd5f7a-4daa-4c86-b715-59070374baa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.489841Z",
     "iopub.status.busy": "2024-05-13T18:29:17.489648Z",
     "iopub.status.idle": "2024-05-13T18:29:17.494645Z",
     "shell.execute_reply": "2024-05-13T18:29:17.494036Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.489824Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "        # print(output)\n",
    "        # print(maxk)\n",
    "        # print(target)\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be0fb25a-d3f9-48ac-a698-0a1a55d6ca5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.496357Z",
     "iopub.status.busy": "2024-05-13T18:29:17.495729Z",
     "iopub.status.idle": "2024-05-13T18:29:17.504068Z",
     "shell.execute_reply": "2024-05-13T18:29:17.503338Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.496333Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, linear_classifiers, optimizer, scheduler, epoch, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        # [batch_time, data_time, losses, top1, top5],\n",
    "        [batch_time, data_time, losses, top1],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    model.eval()\n",
    "    linear_classifiers.train(True)\n",
    "\n",
    "    all_top1 = {k: AverageMeter('Acc@1', ':6.2f') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "    # all_top5 = {k: AverageMeter('Acc@5', ':6.2f') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "    all_losses = {k: AverageMeter('Loss', ':.4e') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        images = images.cuda(args.gpu, non_blocking=True)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            features = model.forward_features(images)\n",
    "        outputs = linear_classifiers(features)\n",
    "\n",
    "        cls_losses = {f\"loss_{k}\": nn.CrossEntropyLoss()(v, target) for k, v in outputs.items()}\n",
    "        loss = sum(cls_losses.values())\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        min_loss = 1e5\n",
    "        max_acc1 = -1\n",
    "        # max_acc5 = -1\n",
    "        for k, v in outputs.items():\n",
    "            # acc1, acc5 = accuracy(v, target, topk=(1, 5))\n",
    "            acc1, _ = accuracy(v, target, topk=(1, 2))\n",
    "            # print(acc1)\n",
    "            all_top1[k].update(acc1.item(), images.size(0))\n",
    "            # all_top5[k].update(acc5.item(), images.size(0))\n",
    "            all_losses[k].update(cls_losses[f\"loss_{k}\"].item(), images.size(0))\n",
    "            min_loss = min(min_loss, cls_losses[f\"loss_{k}\"].item())\n",
    "            max_acc1 = max(max_acc1, acc1.item())\n",
    "            # max_acc5 = max(max_acc5, acc5.item())\n",
    "\n",
    "        # logging the best loss/accuracy across all classifiers\n",
    "        losses.update(min_loss, images.size(0))\n",
    "        top1.update(max_acc1, images.size(0))\n",
    "        # top5.update(max_acc5, images.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "    # return {'acc1': top1.avg, 'acc5': top5.avg, 'loss': losses.avg}, all_top1, all_top5, all_losses\n",
    "    return {'acc1': top1.avg, 'loss': losses.avg}, all_top1, all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba13d88-50e5-4089-9ada-bf6c7e1d7eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.505741Z",
     "iopub.status.busy": "2024-05-13T18:29:17.505025Z",
     "iopub.status.idle": "2024-05-13T18:29:17.512777Z",
     "shell.execute_reply": "2024-05-13T18:29:17.511963Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.505704Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, linear_classifiers, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        # [batch_time, losses, top1, top5],\n",
    "        [batch_time, losses, top1],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    linear_classifiers.eval()\n",
    "\n",
    "    all_top1 = {k: AverageMeter('Acc@1', ':6.2f') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "    # all_top5 = {k: AverageMeter('Acc@5', ':6.2f') for k in linear_classifiers.module.classifiers_dict.keys()}\n",
    "    all_losses = {k: AverageMeter('Loss', ':.4e') for k in linear_classifiers.classifiers_dict.keys()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            images = images.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            features = model.forward_features(images)\n",
    "            outputs = linear_classifiers(features)\n",
    "\n",
    "            my_losses = {f\"loss_{k}\": nn.CrossEntropyLoss()(v, target) for k, v in outputs.items()}\n",
    "            min_loss = 1e6\n",
    "            max_acc1 = -1\n",
    "            # max_acc5 = -1\n",
    "            for k, v in outputs.items():\n",
    "                # acc1, acc5 = accuracy(v, target, topk=(1, 5))\n",
    "                acc1, _ = accuracy(v, target, topk=(1, 2))\n",
    "                all_top1[k].update(acc1.item(), images.size(0))\n",
    "                # all_top5[k].update(acc5.item(), images.size(0))\n",
    "                all_losses[k].update(my_losses[f\"loss_{k}\"].item(), images.size(0))\n",
    "                min_loss = min(min_loss, my_losses[f\"loss_{k}\"].item())\n",
    "                max_acc1 = max(max_acc1, acc1.item())\n",
    "                # max_acc5 = max(max_acc5, acc5.item())\n",
    "\n",
    "            # logging the best loss/accuracy across all classifiers\n",
    "            losses.update(min_loss, images.size(0))\n",
    "            top1.update(max_acc1, images.size(0))\n",
    "            # top5.update(max_acc5, images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # print('Monitored (fake) accuracy * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "        #       .format(top1=top1, top5=top5))\n",
    "        print('Monitored (fake) accuracy * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "    # print('acc1', top1.avg)\n",
    "    # print('loss', losses.avg)\n",
    "    # return {'acc1': top1.avg, 'acc5': top5.avg, 'loss': losses.avg}, all_top1, all_top5, all_losses\n",
    "    return {'acc1': top1.avg, 'loss': losses.avg}, all_top1, all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a7ec2fc-b64f-442f-ac2d-32cb8914f0a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.513827Z",
     "iopub.status.busy": "2024-05-13T18:29:17.513637Z",
     "iopub.status.idle": "2024-05-13T18:29:17.517541Z",
     "shell.execute_reply": "2024-05-13T18:29:17.516903Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.513812Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, output_dir):\n",
    "    ckpt_path = f'{output_dir}/linear_checkpoint.pt'\n",
    "    best_path = f'{output_dir}/linear_best.pt'\n",
    "    torch.save(state, ckpt_path)\n",
    "    if is_best:\n",
    "        shutil.copyfile(ckpt_path, best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91954208-4ccf-417e-8687-91027bf0fce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.518627Z",
     "iopub.status.busy": "2024-05-13T18:29:17.518288Z",
     "iopub.status.idle": "2024-05-13T18:29:17.523070Z",
     "shell.execute_reply": "2024-05-13T18:29:17.522354Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.518610Z"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbed858d-c64d-4445-9888-ae032913b862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.524082Z",
     "iopub.status.busy": "2024-05-13T18:29:17.523894Z",
     "iopub.status.idle": "2024-05-13T18:29:17.530091Z",
     "shell.execute_reply": "2024-05-13T18:29:17.529057Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.524068Z"
    }
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a8f644d-c044-47c5-b581-2f874a455ef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:17.531986Z",
     "iopub.status.busy": "2024-05-13T18:29:17.530981Z",
     "iopub.status.idle": "2024-05-13T18:29:22.086844Z",
     "shell.execute_reply": "2024-05-13T18:29:22.085860Z",
     "shell.execute_reply.started": "2024-05-13T18:29:17.531950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './output_dir_enhance/out/epoch_last.pth'\n",
      "number of classifiers in totall (with different lr):  10\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "model, linear_classifiers, optimizer = get_model_and_optimizer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d44d2257-04c4-4385-8193-3c50304d0070",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T18:29:22.088543Z",
     "iopub.status.busy": "2024-05-13T18:29:22.088285Z",
     "iopub.status.idle": "2024-05-13T19:37:08.531981Z",
     "shell.execute_reply": "2024-05-13T19:37:08.529123Z",
     "shell.execute_reply.started": "2024-05-13T18:29:22.088522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/562]\tTime 10.917 (10.917)\tData  1.518 ( 1.518)\tLoss 2.1464e+00 (2.1464e+00)\tAcc@1  34.38 ( 34.38)\n",
      "Epoch: [0][100/562]\tTime  0.180 ( 0.290)\tData  0.000 ( 0.016)\tLoss 5.0924e-01 (4.2614e-01)\tAcc@1  89.06 ( 87.48)\n",
      "Epoch: [0][200/562]\tTime  0.182 ( 0.292)\tData  0.000 ( 0.009)\tLoss 3.7125e-01 (3.6732e-01)\tAcc@1  92.19 ( 89.24)\n",
      "Epoch: [0][300/562]\tTime  0.184 ( 0.255)\tData  0.000 ( 0.006)\tLoss 4.4089e-01 (3.4692e-01)\tAcc@1  89.06 ( 89.84)\n",
      "Epoch: [0][400/562]\tTime  0.277 ( 0.246)\tData  0.011 ( 0.006)\tLoss 1.5427e-01 (3.3119e-01)\tAcc@1  96.88 ( 90.38)\n",
      "Epoch: [0][500/562]\tTime  0.310 ( 0.252)\tData  0.013 ( 0.006)\tLoss 1.9979e-01 (3.1883e-01)\tAcc@1  95.31 ( 90.80)\n",
      "Test: [  0/141]\tTime  0.848 ( 0.848)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.192)\tLoss 5.6540e-03 (9.1626e-02)\tAcc@1 100.00 ( 97.49)\n",
      "Monitored (fake) accuracy * Acc@1 96.278\n",
      "Epoch: [1][  0/562]\tTime  1.749 ( 1.749)\tData  1.425 ( 1.425)\tLoss 2.4896e-01 (2.4896e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Epoch: [1][100/562]\tTime  0.186 ( 0.203)\tData  0.000 ( 0.014)\tLoss 3.0231e-01 (2.6655e-01)\tAcc@1  87.50 ( 92.25)\n",
      "Epoch: [1][200/562]\tTime  0.187 ( 0.196)\tData  0.000 ( 0.007)\tLoss 4.0802e-01 (2.6844e-01)\tAcc@1  89.06 ( 92.30)\n",
      "Epoch: [1][300/562]\tTime  0.189 ( 0.193)\tData  0.000 ( 0.005)\tLoss 3.1120e-01 (2.6695e-01)\tAcc@1  90.62 ( 92.25)\n",
      "Epoch: [1][400/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.004)\tLoss 1.5067e-01 (2.6129e-01)\tAcc@1  95.31 ( 92.40)\n",
      "Epoch: [1][500/562]\tTime  0.188 ( 0.191)\tData  0.000 ( 0.003)\tLoss 2.6330e-01 (2.5774e-01)\tAcc@1  93.75 ( 92.53)\n",
      "Test: [  0/141]\tTime  1.076 ( 1.076)\tLoss 4.2658e-04 (4.2658e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.198)\tLoss 1.4125e-01 (8.6333e-02)\tAcc@1  96.88 ( 97.93)\n",
      "Monitored (fake) accuracy * Acc@1 96.211\n",
      "Epoch: [2][  0/562]\tTime  1.225 ( 1.225)\tData  0.898 ( 0.898)\tLoss 1.7852e-01 (1.7852e-01)\tAcc@1  96.88 ( 96.88)\n",
      "Epoch: [2][100/562]\tTime  0.186 ( 0.200)\tData  0.000 ( 0.009)\tLoss 2.2744e-01 (2.5009e-01)\tAcc@1  93.75 ( 92.71)\n",
      "Epoch: [2][200/562]\tTime  0.189 ( 0.195)\tData  0.000 ( 0.005)\tLoss 1.0666e-01 (2.4357e-01)\tAcc@1  98.44 ( 92.90)\n",
      "Epoch: [2][300/562]\tTime  0.188 ( 0.193)\tData  0.000 ( 0.003)\tLoss 2.5812e-01 (2.4441e-01)\tAcc@1  90.62 ( 92.95)\n",
      "Epoch: [2][400/562]\tTime  0.189 ( 0.192)\tData  0.000 ( 0.002)\tLoss 3.9634e-01 (2.4878e-01)\tAcc@1  89.06 ( 92.81)\n",
      "Epoch: [2][500/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.002)\tLoss 2.4712e-01 (2.4527e-01)\tAcc@1  93.75 ( 92.96)\n",
      "Test: [  0/141]\tTime  0.932 ( 0.932)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.194)\tLoss 6.1086e-02 (1.3685e-01)\tAcc@1  96.88 ( 96.32)\n",
      "Monitored (fake) accuracy * Acc@1 96.589\n",
      "Epoch: [3][  0/562]\tTime  1.146 ( 1.146)\tData  0.963 ( 0.963)\tLoss 2.0554e-01 (2.0554e-01)\tAcc@1  96.88 ( 96.88)\n",
      "Epoch: [3][100/562]\tTime  0.186 ( 0.198)\tData  0.000 ( 0.010)\tLoss 1.6053e-01 (2.3660e-01)\tAcc@1  95.31 ( 93.44)\n",
      "Epoch: [3][200/562]\tTime  0.189 ( 0.193)\tData  0.000 ( 0.005)\tLoss 2.1351e-01 (2.4026e-01)\tAcc@1  92.19 ( 93.13)\n",
      "Epoch: [3][300/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.003)\tLoss 2.8289e-01 (2.3908e-01)\tAcc@1  92.19 ( 93.21)\n",
      "Epoch: [3][400/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 2.1601e-01 (2.3912e-01)\tAcc@1  92.19 ( 93.23)\n",
      "Epoch: [3][500/562]\tTime  0.185 ( 0.190)\tData  0.000 ( 0.002)\tLoss 2.3707e-01 (2.3923e-01)\tAcc@1  89.06 ( 93.13)\n",
      "Test: [  0/141]\tTime  1.115 ( 1.115)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.189 ( 0.196)\tLoss 1.9781e-01 (9.7654e-02)\tAcc@1  93.75 ( 97.25)\n",
      "Monitored (fake) accuracy * Acc@1 96.411\n",
      "Epoch: [4][  0/562]\tTime  1.024 ( 1.024)\tData  0.837 ( 0.837)\tLoss 2.2041e-01 (2.2041e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Epoch: [4][100/562]\tTime  0.199 ( 0.197)\tData  0.000 ( 0.008)\tLoss 2.3606e-01 (2.4349e-01)\tAcc@1  92.19 ( 93.21)\n",
      "Epoch: [4][200/562]\tTime  0.192 ( 0.192)\tData  0.000 ( 0.004)\tLoss 4.2593e-01 (2.3862e-01)\tAcc@1  89.06 ( 93.29)\n",
      "Epoch: [4][300/562]\tTime  0.190 ( 0.191)\tData  0.000 ( 0.003)\tLoss 1.6301e-01 (2.3886e-01)\tAcc@1  95.31 ( 93.32)\n",
      "Epoch: [4][400/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.002)\tLoss 2.9572e-01 (2.3903e-01)\tAcc@1  90.62 ( 93.33)\n",
      "Epoch: [4][500/562]\tTime  0.185 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.0072e-01 (2.3876e-01)\tAcc@1  92.19 ( 93.30)\n",
      "Test: [  0/141]\tTime  0.777 ( 0.777)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.184 ( 0.192)\tLoss 9.2409e-02 (9.8541e-02)\tAcc@1  98.44 ( 97.23)\n",
      "Monitored (fake) accuracy * Acc@1 96.678\n",
      "Epoch: [5][  0/562]\tTime  1.211 ( 1.211)\tData  1.025 ( 1.025)\tLoss 4.0467e-01 (4.0467e-01)\tAcc@1  84.38 ( 84.38)\n",
      "Epoch: [5][100/562]\tTime  0.187 ( 0.197)\tData  0.000 ( 0.010)\tLoss 1.9691e-01 (2.2921e-01)\tAcc@1  93.75 ( 93.66)\n",
      "Epoch: [5][200/562]\tTime  0.190 ( 0.193)\tData  0.000 ( 0.005)\tLoss 1.1092e-01 (2.2909e-01)\tAcc@1  96.88 ( 93.45)\n",
      "Epoch: [5][300/562]\tTime  0.185 ( 0.191)\tData  0.000 ( 0.004)\tLoss 1.4669e-01 (2.3032e-01)\tAcc@1  95.31 ( 93.41)\n",
      "Epoch: [5][400/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.003)\tLoss 1.4561e-01 (2.2884e-01)\tAcc@1  98.44 ( 93.41)\n",
      "Epoch: [5][500/562]\tTime  0.189 ( 0.190)\tData  0.000 ( 0.002)\tLoss 1.2096e-01 (2.3211e-01)\tAcc@1  95.31 ( 93.33)\n",
      "Test: [  0/141]\tTime  1.019 ( 1.019)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.195)\tLoss 1.4602e-01 (7.9781e-02)\tAcc@1  96.88 ( 97.97)\n",
      "Monitored (fake) accuracy * Acc@1 96.211\n",
      "Epoch: [6][  0/562]\tTime  0.902 ( 0.902)\tData  0.711 ( 0.711)\tLoss 1.9351e-01 (1.9351e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Epoch: [6][100/562]\tTime  0.189 ( 0.195)\tData  0.000 ( 0.007)\tLoss 4.1502e-01 (2.3314e-01)\tAcc@1  89.06 ( 93.64)\n",
      "Epoch: [6][200/562]\tTime  0.190 ( 0.192)\tData  0.000 ( 0.004)\tLoss 2.2408e-01 (2.2732e-01)\tAcc@1  92.19 ( 93.58)\n",
      "Epoch: [6][300/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.003)\tLoss 1.2127e-01 (2.2919e-01)\tAcc@1  98.44 ( 93.50)\n",
      "Epoch: [6][400/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.002)\tLoss 2.5046e-01 (2.2934e-01)\tAcc@1  92.19 ( 93.45)\n",
      "Epoch: [6][500/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.002)\tLoss 1.1821e-01 (2.2799e-01)\tAcc@1  96.88 ( 93.46)\n",
      "Test: [  0/141]\tTime  1.023 ( 1.023)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.195)\tLoss 1.7192e-01 (1.0247e-01)\tAcc@1  93.75 ( 96.98)\n",
      "Monitored (fake) accuracy * Acc@1 95.856\n",
      "Epoch: [7][  0/562]\tTime  1.177 ( 1.177)\tData  0.992 ( 0.992)\tLoss 1.8298e-01 (1.8298e-01)\tAcc@1  92.19 ( 92.19)\n",
      "Epoch: [7][100/562]\tTime  0.189 ( 0.197)\tData  0.000 ( 0.010)\tLoss 1.7271e-01 (2.2729e-01)\tAcc@1  95.31 ( 93.60)\n",
      "Epoch: [7][200/562]\tTime  0.186 ( 0.192)\tData  0.000 ( 0.005)\tLoss 4.0924e-01 (2.2811e-01)\tAcc@1  87.50 ( 93.59)\n",
      "Epoch: [7][300/562]\tTime  0.191 ( 0.190)\tData  0.000 ( 0.003)\tLoss 3.3163e-01 (2.2479e-01)\tAcc@1  89.06 ( 93.76)\n",
      "Epoch: [7][400/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.003)\tLoss 4.2622e-01 (2.2848e-01)\tAcc@1  89.06 ( 93.59)\n",
      "Epoch: [7][500/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.002)\tLoss 3.2021e-01 (2.2704e-01)\tAcc@1  92.19 ( 93.63)\n",
      "Test: [  0/141]\tTime  0.784 ( 0.784)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.192)\tLoss 8.3836e-03 (9.7277e-02)\tAcc@1 100.00 ( 97.03)\n",
      "Monitored (fake) accuracy * Acc@1 96.122\n",
      "Epoch: [8][  0/562]\tTime  0.848 ( 0.848)\tData  0.644 ( 0.644)\tLoss 1.9105e-01 (1.9105e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Epoch: [8][100/562]\tTime  0.186 ( 0.197)\tData  0.000 ( 0.008)\tLoss 2.2137e-01 (2.1023e-01)\tAcc@1  95.31 ( 93.84)\n",
      "Epoch: [8][200/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.004)\tLoss 1.8623e-01 (2.2207e-01)\tAcc@1  95.31 ( 93.66)\n",
      "Epoch: [8][300/562]\tTime  0.189 ( 0.191)\tData  0.000 ( 0.003)\tLoss 3.2396e-01 (2.2574e-01)\tAcc@1  92.19 ( 93.60)\n",
      "Epoch: [8][400/562]\tTime  0.189 ( 0.190)\tData  0.000 ( 0.002)\tLoss 1.9405e-01 (2.2237e-01)\tAcc@1  95.31 ( 93.71)\n",
      "Epoch: [8][500/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.002)\tLoss 8.4165e-02 (2.2635e-01)\tAcc@1  95.31 ( 93.63)\n",
      "Test: [  0/141]\tTime  0.882 ( 0.882)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.194)\tLoss 1.2584e-01 (7.4215e-02)\tAcc@1  95.31 ( 98.11)\n",
      "Monitored (fake) accuracy * Acc@1 96.389\n",
      "Epoch: [9][  0/562]\tTime  0.879 ( 0.879)\tData  0.687 ( 0.687)\tLoss 2.1290e-01 (2.1290e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Epoch: [9][100/562]\tTime  0.186 ( 0.195)\tData  0.000 ( 0.007)\tLoss 4.6593e-02 (2.2940e-01)\tAcc@1 100.00 ( 93.61)\n",
      "Epoch: [9][200/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.004)\tLoss 1.6320e-01 (2.2190e-01)\tAcc@1  95.31 ( 93.77)\n",
      "Epoch: [9][300/562]\tTime  0.189 ( 0.190)\tData  0.000 ( 0.002)\tLoss 5.6437e-02 (2.2147e-01)\tAcc@1  98.44 ( 93.73)\n",
      "Epoch: [9][400/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.002)\tLoss 3.3869e-01 (2.2310e-01)\tAcc@1  90.62 ( 93.70)\n",
      "Epoch: [9][500/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.4068e-01 (2.2283e-01)\tAcc@1  93.75 ( 93.73)\n",
      "Test: [  0/141]\tTime  0.784 ( 0.784)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.192)\tLoss 1.1364e-01 (8.3312e-02)\tAcc@1  96.88 ( 97.74)\n",
      "Monitored (fake) accuracy * Acc@1 96.811\n",
      "Epoch: [10][  0/562]\tTime  0.918 ( 0.918)\tData  0.725 ( 0.725)\tLoss 3.1251e-01 (3.1251e-01)\tAcc@1  89.06 ( 89.06)\n",
      "Epoch: [10][100/562]\tTime  0.187 ( 0.195)\tData  0.000 ( 0.007)\tLoss 2.5017e-01 (2.2076e-01)\tAcc@1  90.62 ( 93.72)\n",
      "Epoch: [10][200/562]\tTime  0.195 ( 0.191)\tData  0.000 ( 0.004)\tLoss 1.5065e-01 (2.2467e-01)\tAcc@1  96.88 ( 93.60)\n",
      "Epoch: [10][300/562]\tTime  0.190 ( 0.190)\tData  0.000 ( 0.003)\tLoss 1.4209e-01 (2.2357e-01)\tAcc@1  93.75 ( 93.57)\n",
      "Epoch: [10][400/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.002)\tLoss 3.1472e-01 (2.2050e-01)\tAcc@1  92.19 ( 93.67)\n",
      "Epoch: [10][500/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.2400e-01 (2.1954e-01)\tAcc@1  93.75 ( 93.72)\n",
      "Test: [  0/141]\tTime  0.782 ( 0.782)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.192)\tLoss 3.0102e-02 (9.4019e-02)\tAcc@1  98.44 ( 97.39)\n",
      "Monitored (fake) accuracy * Acc@1 96.500\n",
      "Epoch: [11][  0/562]\tTime  1.036 ( 1.036)\tData  0.850 ( 0.850)\tLoss 1.6832e-01 (1.6832e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Epoch: [11][100/562]\tTime  0.187 ( 0.196)\tData  0.000 ( 0.009)\tLoss 3.3307e-01 (2.3481e-01)\tAcc@1  90.62 ( 93.46)\n",
      "Epoch: [11][200/562]\tTime  0.188 ( 0.192)\tData  0.000 ( 0.004)\tLoss 4.6439e-01 (2.2692e-01)\tAcc@1  89.06 ( 93.50)\n",
      "Epoch: [11][300/562]\tTime  0.194 ( 0.191)\tData  0.000 ( 0.003)\tLoss 1.6215e-01 (2.2581e-01)\tAcc@1  96.88 ( 93.56)\n",
      "Epoch: [11][400/562]\tTime  0.192 ( 0.190)\tData  0.000 ( 0.002)\tLoss 2.4736e-01 (2.2248e-01)\tAcc@1  93.75 ( 93.64)\n",
      "Epoch: [11][500/562]\tTime  0.192 ( 0.190)\tData  0.000 ( 0.002)\tLoss 1.4193e-01 (2.1947e-01)\tAcc@1  96.88 ( 93.75)\n",
      "Test: [  0/141]\tTime  1.011 ( 1.011)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.195)\tLoss 6.4425e-02 (1.2795e-01)\tAcc@1  98.44 ( 95.99)\n",
      "Monitored (fake) accuracy * Acc@1 96.533\n",
      "Epoch: [12][  0/562]\tTime  1.152 ( 1.152)\tData  0.961 ( 0.961)\tLoss 1.6219e-01 (1.6219e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Epoch: [12][100/562]\tTime  0.186 ( 0.197)\tData  0.000 ( 0.010)\tLoss 2.5539e-01 (2.2477e-01)\tAcc@1  92.19 ( 93.66)\n",
      "Epoch: [12][200/562]\tTime  0.186 ( 0.192)\tData  0.000 ( 0.005)\tLoss 4.7856e-02 (2.1318e-01)\tAcc@1 100.00 ( 94.01)\n",
      "Epoch: [12][300/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.003)\tLoss 2.8407e-01 (2.1303e-01)\tAcc@1  90.62 ( 93.93)\n",
      "Epoch: [12][400/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 2.6419e-01 (2.1190e-01)\tAcc@1  93.75 ( 93.99)\n",
      "Epoch: [12][500/562]\tTime  0.189 ( 0.190)\tData  0.000 ( 0.002)\tLoss 1.4683e-01 (2.1444e-01)\tAcc@1  95.31 ( 93.94)\n",
      "Test: [  0/141]\tTime  0.911 ( 0.911)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.193)\tLoss 8.4656e-02 (1.0423e-01)\tAcc@1  96.88 ( 96.97)\n",
      "Monitored (fake) accuracy * Acc@1 96.167\n",
      "Epoch: [13][  0/562]\tTime  0.855 ( 0.855)\tData  0.646 ( 0.646)\tLoss 2.0368e-01 (2.0368e-01)\tAcc@1  92.19 ( 92.19)\n",
      "Epoch: [13][100/562]\tTime  0.188 ( 0.194)\tData  0.000 ( 0.007)\tLoss 4.5881e-01 (2.1935e-01)\tAcc@1  84.38 ( 93.84)\n",
      "Epoch: [13][200/562]\tTime  0.188 ( 0.191)\tData  0.000 ( 0.003)\tLoss 1.4578e-01 (2.1346e-01)\tAcc@1  96.88 ( 93.98)\n",
      "Epoch: [13][300/562]\tTime  0.195 ( 0.190)\tData  0.000 ( 0.002)\tLoss 2.0740e-01 (2.1366e-01)\tAcc@1  93.75 ( 93.90)\n",
      "Epoch: [13][400/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.0371e-01 (2.1070e-01)\tAcc@1  93.75 ( 93.99)\n",
      "Epoch: [13][500/562]\tTime  0.189 ( 0.189)\tData  0.000 ( 0.002)\tLoss 4.4434e-01 (2.1161e-01)\tAcc@1  89.06 ( 94.00)\n",
      "Test: [  0/141]\tTime  1.127 ( 1.127)\tLoss 3.7253e-09 (3.7253e-09)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.197)\tLoss 1.0623e-01 (1.2627e-01)\tAcc@1  96.88 ( 96.38)\n",
      "Monitored (fake) accuracy * Acc@1 96.233\n",
      "Epoch: [14][  0/562]\tTime  1.068 ( 1.068)\tData  0.883 ( 0.883)\tLoss 2.7458e-01 (2.7458e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Epoch: [14][100/562]\tTime  0.187 ( 0.196)\tData  0.000 ( 0.009)\tLoss 2.2552e-01 (2.0834e-01)\tAcc@1  92.19 ( 94.07)\n",
      "Epoch: [14][200/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.005)\tLoss 2.7439e-01 (2.0783e-01)\tAcc@1  93.75 ( 94.09)\n",
      "Epoch: [14][300/562]\tTime  0.188 ( 0.191)\tData  0.000 ( 0.003)\tLoss 1.5636e-01 (2.0727e-01)\tAcc@1  95.31 ( 94.09)\n",
      "Epoch: [14][400/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.002)\tLoss 3.2689e-01 (2.0879e-01)\tAcc@1  90.62 ( 94.07)\n",
      "Epoch: [14][500/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.002)\tLoss 9.7717e-02 (2.0516e-01)\tAcc@1  96.88 ( 94.15)\n",
      "Test: [  0/141]\tTime  0.807 ( 0.807)\tLoss 0.0000e+00 (0.0000e+00)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.192)\tLoss 7.4456e-02 (8.2634e-02)\tAcc@1  98.44 ( 97.74)\n",
      "Monitored (fake) accuracy * Acc@1 96.656\n",
      "Epoch: [15][  0/562]\tTime  0.885 ( 0.885)\tData  0.693 ( 0.693)\tLoss 2.1509e-01 (2.1509e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Epoch: [15][100/562]\tTime  0.187 ( 0.194)\tData  0.000 ( 0.007)\tLoss 9.3508e-02 (2.0901e-01)\tAcc@1  96.88 ( 93.84)\n",
      "Epoch: [15][200/562]\tTime  0.188 ( 0.191)\tData  0.000 ( 0.004)\tLoss 8.2944e-02 (2.0822e-01)\tAcc@1  98.44 ( 94.12)\n",
      "Epoch: [15][300/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.002)\tLoss 1.3605e-01 (2.0706e-01)\tAcc@1  98.44 ( 94.04)\n",
      "Epoch: [15][400/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.1867e-01 (2.1254e-01)\tAcc@1  93.75 ( 93.88)\n",
      "Epoch: [15][500/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.5554e-01 (2.1215e-01)\tAcc@1  93.75 ( 93.91)\n",
      "Test: [  0/141]\tTime  1.098 ( 1.098)\tLoss 3.7253e-09 (3.7253e-09)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.195)\tLoss 1.6049e-01 (9.5083e-02)\tAcc@1  93.75 ( 97.42)\n",
      "Monitored (fake) accuracy * Acc@1 96.144\n",
      "Epoch: [16][  0/562]\tTime  1.043 ( 1.043)\tData  0.841 ( 0.841)\tLoss 2.9976e-01 (2.9976e-01)\tAcc@1  89.06 ( 89.06)\n",
      "Epoch: [16][100/562]\tTime  0.186 ( 0.196)\tData  0.000 ( 0.009)\tLoss 7.8105e-02 (2.1172e-01)\tAcc@1  96.88 ( 93.64)\n",
      "Epoch: [16][200/562]\tTime  0.188 ( 0.192)\tData  0.000 ( 0.004)\tLoss 1.7331e-01 (2.0499e-01)\tAcc@1  96.88 ( 94.03)\n",
      "Epoch: [16][300/562]\tTime  0.191 ( 0.190)\tData  0.000 ( 0.003)\tLoss 1.3681e-01 (2.0847e-01)\tAcc@1  95.31 ( 94.09)\n",
      "Epoch: [16][400/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.002)\tLoss 2.9849e-01 (2.0671e-01)\tAcc@1  90.62 ( 94.18)\n",
      "Epoch: [16][500/562]\tTime  0.189 ( 0.190)\tData  0.000 ( 0.002)\tLoss 1.6900e-01 (2.0555e-01)\tAcc@1  96.88 ( 94.24)\n",
      "Test: [  0/141]\tTime  0.897 ( 0.897)\tLoss 5.4981e-04 (5.4981e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.194)\tLoss 1.2335e-01 (5.6481e-02)\tAcc@1  96.88 ( 98.27)\n",
      "Monitored (fake) accuracy * Acc@1 96.556\n",
      "Epoch: [17][  0/562]\tTime  1.128 ( 1.128)\tData  0.934 ( 0.934)\tLoss 1.4550e-01 (1.4550e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Epoch: [17][100/562]\tTime  0.187 ( 0.197)\tData  0.000 ( 0.009)\tLoss 1.1115e-01 (2.0092e-01)\tAcc@1  95.31 ( 94.26)\n",
      "Epoch: [17][200/562]\tTime  0.188 ( 0.192)\tData  0.000 ( 0.005)\tLoss 3.6878e-01 (2.0061e-01)\tAcc@1  92.19 ( 94.34)\n",
      "Epoch: [17][300/562]\tTime  0.194 ( 0.191)\tData  0.000 ( 0.003)\tLoss 1.2933e-01 (2.0535e-01)\tAcc@1  95.31 ( 94.15)\n",
      "Epoch: [17][400/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.003)\tLoss 2.7890e-01 (2.0454e-01)\tAcc@1  93.75 ( 94.18)\n",
      "Epoch: [17][500/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.002)\tLoss 7.7521e-02 (2.0553e-01)\tAcc@1  98.44 ( 94.19)\n",
      "Test: [  0/141]\tTime  1.050 ( 1.050)\tLoss 5.5133e-07 (5.5133e-07)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.188 ( 0.195)\tLoss 2.0067e-01 (1.0004e-01)\tAcc@1  93.75 ( 97.17)\n",
      "Monitored (fake) accuracy * Acc@1 96.189\n",
      "Epoch: [18][  0/562]\tTime  0.974 ( 0.974)\tData  0.784 ( 0.784)\tLoss 1.8443e-01 (1.8443e-01)\tAcc@1  96.88 ( 96.88)\n",
      "Epoch: [18][100/562]\tTime  0.187 ( 0.195)\tData  0.000 ( 0.008)\tLoss 2.2430e-01 (1.9392e-01)\tAcc@1  95.31 ( 94.52)\n",
      "Epoch: [18][200/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.004)\tLoss 3.5237e-01 (1.9818e-01)\tAcc@1  89.06 ( 94.38)\n",
      "Epoch: [18][300/562]\tTime  0.189 ( 0.191)\tData  0.000 ( 0.003)\tLoss 3.7945e-01 (1.9332e-01)\tAcc@1  87.50 ( 94.54)\n",
      "Epoch: [18][400/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.002)\tLoss 1.6612e-01 (1.9695e-01)\tAcc@1  93.75 ( 94.42)\n",
      "Epoch: [18][500/562]\tTime  0.188 ( 0.191)\tData  0.000 ( 0.002)\tLoss 6.4326e-02 (1.9554e-01)\tAcc@1  98.44 ( 94.45)\n",
      "Test: [  0/141]\tTime  1.010 ( 1.010)\tLoss 3.0694e-06 (3.0694e-06)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.195)\tLoss 8.5471e-02 (9.4593e-02)\tAcc@1  98.44 ( 97.48)\n",
      "Monitored (fake) accuracy * Acc@1 96.700\n",
      "Epoch: [19][  0/562]\tTime  1.434 ( 1.434)\tData  1.054 ( 1.054)\tLoss 3.6064e-02 (3.6064e-02)\tAcc@1 100.00 (100.00)\n",
      "Epoch: [19][100/562]\tTime  0.188 ( 0.200)\tData  0.000 ( 0.011)\tLoss 9.6683e-03 (1.9454e-01)\tAcc@1 100.00 ( 94.57)\n",
      "Epoch: [19][200/562]\tTime  0.187 ( 0.194)\tData  0.000 ( 0.005)\tLoss 3.8744e-01 (1.9855e-01)\tAcc@1  90.62 ( 94.22)\n",
      "Epoch: [19][300/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.004)\tLoss 2.2098e-01 (1.9768e-01)\tAcc@1  92.19 ( 94.31)\n",
      "Epoch: [19][400/562]\tTime  0.190 ( 0.191)\tData  0.000 ( 0.003)\tLoss 1.0248e-01 (1.9602e-01)\tAcc@1  96.88 ( 94.35)\n",
      "Epoch: [19][500/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.002)\tLoss 2.1720e-01 (1.9665e-01)\tAcc@1  95.31 ( 94.39)\n",
      "Test: [  0/141]\tTime  0.990 ( 0.990)\tLoss 1.4134e-04 (1.4134e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.194)\tLoss 1.7761e-01 (1.1935e-01)\tAcc@1  93.75 ( 96.23)\n",
      "Monitored (fake) accuracy * Acc@1 96.311\n",
      "Epoch: [20][  0/562]\tTime  0.927 ( 0.927)\tData  0.720 ( 0.720)\tLoss 3.3456e-01 (3.3456e-01)\tAcc@1  87.50 ( 87.50)\n",
      "Epoch: [20][100/562]\tTime  0.186 ( 0.195)\tData  0.000 ( 0.007)\tLoss 2.9693e-01 (1.9275e-01)\tAcc@1  92.19 ( 94.57)\n",
      "Epoch: [20][200/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.004)\tLoss 1.7081e-01 (1.9143e-01)\tAcc@1  93.75 ( 94.49)\n",
      "Epoch: [20][300/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.003)\tLoss 1.6573e-01 (1.9342e-01)\tAcc@1  95.31 ( 94.46)\n",
      "Epoch: [20][400/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.6735e-01 (1.9608e-01)\tAcc@1  92.19 ( 94.42)\n",
      "Epoch: [20][500/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.002)\tLoss 5.9645e-02 (1.9473e-01)\tAcc@1  98.44 ( 94.53)\n",
      "Test: [  0/141]\tTime  1.024 ( 1.024)\tLoss 2.4576e-05 (2.4576e-05)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.194)\tLoss 1.8344e-01 (9.7324e-02)\tAcc@1  93.75 ( 97.23)\n",
      "Monitored (fake) accuracy * Acc@1 96.289\n",
      "Epoch: [21][  0/562]\tTime  0.883 ( 0.883)\tData  0.678 ( 0.678)\tLoss 1.1731e-01 (1.1731e-01)\tAcc@1  98.44 ( 98.44)\n",
      "Epoch: [21][100/562]\tTime  0.189 ( 0.194)\tData  0.000 ( 0.007)\tLoss 1.8732e-01 (2.0603e-01)\tAcc@1  92.19 ( 94.26)\n",
      "Epoch: [21][200/562]\tTime  0.186 ( 0.191)\tData  0.000 ( 0.004)\tLoss 2.4274e-01 (2.0055e-01)\tAcc@1  93.75 ( 94.27)\n",
      "Epoch: [21][300/562]\tTime  0.190 ( 0.190)\tData  0.000 ( 0.002)\tLoss 2.3522e-01 (1.9390e-01)\tAcc@1  92.19 ( 94.51)\n",
      "Epoch: [21][400/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.002)\tLoss 6.3472e-02 (1.9340e-01)\tAcc@1  96.88 ( 94.51)\n",
      "Epoch: [21][500/562]\tTime  0.187 ( 0.189)\tData  0.000 ( 0.002)\tLoss 1.3200e-01 (1.9524e-01)\tAcc@1  95.31 ( 94.48)\n",
      "Test: [  0/141]\tTime  0.832 ( 0.832)\tLoss 7.7049e-04 (7.7049e-04)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.193)\tLoss 1.1944e-01 (1.0644e-01)\tAcc@1  96.88 ( 96.88)\n",
      "Monitored (fake) accuracy * Acc@1 96.156\n",
      "Epoch: [22][  0/562]\tTime  1.255 ( 1.255)\tData  0.940 ( 0.940)\tLoss 1.2624e-01 (1.2624e-01)\tAcc@1  96.88 ( 96.88)\n",
      "Epoch: [22][100/562]\tTime  0.185 ( 0.199)\tData  0.000 ( 0.009)\tLoss 1.1425e-01 (2.0513e-01)\tAcc@1  95.31 ( 94.00)\n",
      "Epoch: [22][200/562]\tTime  0.187 ( 0.193)\tData  0.000 ( 0.005)\tLoss 1.7821e-01 (2.0057e-01)\tAcc@1  93.75 ( 94.07)\n",
      "Epoch: [22][300/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.003)\tLoss 1.6826e-01 (1.9618e-01)\tAcc@1  93.75 ( 94.31)\n",
      "Epoch: [22][400/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.003)\tLoss 2.2386e-01 (1.9494e-01)\tAcc@1  92.19 ( 94.35)\n",
      "Epoch: [22][500/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.002)\tLoss 2.5147e-01 (1.9343e-01)\tAcc@1  93.75 ( 94.40)\n",
      "Test: [  0/141]\tTime  0.970 ( 0.970)\tLoss 3.6938e-05 (3.6938e-05)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.187 ( 0.194)\tLoss 1.6235e-01 (9.9752e-02)\tAcc@1  93.75 ( 96.98)\n",
      "Monitored (fake) accuracy * Acc@1 96.033\n",
      "Epoch: [23][  0/562]\tTime  0.991 ( 0.991)\tData  0.787 ( 0.787)\tLoss 2.1329e-01 (2.1329e-01)\tAcc@1  92.19 ( 92.19)\n",
      "Epoch: [23][100/562]\tTime  0.187 ( 0.196)\tData  0.000 ( 0.008)\tLoss 1.8266e-01 (1.8845e-01)\tAcc@1  95.31 ( 94.83)\n",
      "Epoch: [23][200/562]\tTime  0.186 ( 0.192)\tData  0.000 ( 0.004)\tLoss 3.0029e-01 (1.8373e-01)\tAcc@1  93.75 ( 94.78)\n",
      "Epoch: [23][300/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.003)\tLoss 7.8728e-02 (1.8496e-01)\tAcc@1  96.88 ( 94.76)\n",
      "Epoch: [23][400/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.002)\tLoss 2.1856e-01 (1.8480e-01)\tAcc@1  93.75 ( 94.74)\n",
      "Epoch: [23][500/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.002)\tLoss 3.0521e-01 (1.8809e-01)\tAcc@1  92.19 ( 94.63)\n",
      "Test: [  0/141]\tTime  0.806 ( 0.806)\tLoss 4.7809e-06 (4.7809e-06)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.193)\tLoss 1.8136e-01 (1.0803e-01)\tAcc@1  95.31 ( 96.86)\n",
      "Monitored (fake) accuracy * Acc@1 96.233\n",
      "Epoch: [24][  0/562]\tTime  1.111 ( 1.111)\tData  0.921 ( 0.921)\tLoss 1.7114e-01 (1.7114e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Epoch: [24][100/562]\tTime  0.186 ( 0.197)\tData  0.000 ( 0.009)\tLoss 1.6603e-01 (1.8346e-01)\tAcc@1  93.75 ( 94.85)\n",
      "Epoch: [24][200/562]\tTime  0.194 ( 0.192)\tData  0.000 ( 0.005)\tLoss 1.4665e-01 (1.8295e-01)\tAcc@1  96.88 ( 94.88)\n",
      "Epoch: [24][300/562]\tTime  0.189 ( 0.191)\tData  0.000 ( 0.003)\tLoss 7.8048e-02 (1.8724e-01)\tAcc@1  98.44 ( 94.76)\n",
      "Epoch: [24][400/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.002)\tLoss 1.5457e-01 (1.8620e-01)\tAcc@1  96.88 ( 94.81)\n",
      "Epoch: [24][500/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.002)\tLoss 1.7390e-01 (1.8638e-01)\tAcc@1  93.75 ( 94.76)\n",
      "Test: [  0/141]\tTime  1.098 ( 1.098)\tLoss 3.0386e-05 (3.0386e-05)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.190 ( 0.196)\tLoss 1.6429e-01 (9.1487e-02)\tAcc@1  95.31 ( 97.39)\n",
      "Monitored (fake) accuracy * Acc@1 96.078\n",
      "Epoch: [25][  0/562]\tTime  1.037 ( 1.037)\tData  0.845 ( 0.845)\tLoss 1.6464e-01 (1.6464e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Epoch: [25][100/562]\tTime  0.189 ( 0.196)\tData  0.000 ( 0.009)\tLoss 2.6562e-01 (2.0108e-01)\tAcc@1  90.62 ( 94.06)\n",
      "Epoch: [25][200/562]\tTime  0.186 ( 0.192)\tData  0.000 ( 0.004)\tLoss 1.0173e-01 (1.8725e-01)\tAcc@1  98.44 ( 94.48)\n",
      "Epoch: [25][300/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.003)\tLoss 1.7547e-01 (1.8238e-01)\tAcc@1  95.31 ( 94.66)\n",
      "Epoch: [25][400/562]\tTime  0.190 ( 0.190)\tData  0.000 ( 0.002)\tLoss 6.5969e-02 (1.8054e-01)\tAcc@1  98.44 ( 94.80)\n",
      "Epoch: [25][500/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.002)\tLoss 1.2723e-01 (1.8299e-01)\tAcc@1  96.88 ( 94.75)\n",
      "Test: [  0/141]\tTime  0.921 ( 0.921)\tLoss 1.1265e-05 (1.1265e-05)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.194)\tLoss 1.7813e-01 (1.1763e-01)\tAcc@1  93.75 ( 96.44)\n",
      "Monitored (fake) accuracy * Acc@1 95.922\n",
      "Epoch: [26][  0/562]\tTime  0.915 ( 0.915)\tData  0.718 ( 0.718)\tLoss 1.6393e-01 (1.6393e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Epoch: [26][100/562]\tTime  0.187 ( 0.195)\tData  0.000 ( 0.007)\tLoss 1.0566e-01 (1.8159e-01)\tAcc@1  98.44 ( 94.94)\n",
      "Epoch: [26][200/562]\tTime  0.187 ( 0.191)\tData  0.000 ( 0.004)\tLoss 1.3322e-01 (1.8386e-01)\tAcc@1  95.31 ( 94.82)\n",
      "Epoch: [26][300/562]\tTime  0.190 ( 0.190)\tData  0.000 ( 0.003)\tLoss 2.8809e-01 (1.8444e-01)\tAcc@1  90.62 ( 94.79)\n",
      "Epoch: [26][400/562]\tTime  0.189 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.0650e-01 (1.8540e-01)\tAcc@1  93.75 ( 94.74)\n",
      "Epoch: [26][500/562]\tTime  0.186 ( 0.189)\tData  0.000 ( 0.002)\tLoss 8.6409e-02 (1.8348e-01)\tAcc@1 100.00 ( 94.78)\n",
      "Test: [  0/141]\tTime  0.864 ( 0.864)\tLoss 4.5893e-05 (4.5893e-05)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.188 ( 0.194)\tLoss 1.4544e-01 (1.0503e-01)\tAcc@1  93.75 ( 96.91)\n",
      "Monitored (fake) accuracy * Acc@1 96.033\n",
      "Epoch: [27][  0/562]\tTime  1.448 ( 1.448)\tData  0.892 ( 0.892)\tLoss 1.5487e-01 (1.5487e-01)\tAcc@1  96.88 ( 96.88)\n",
      "Epoch: [27][100/562]\tTime  0.186 ( 0.200)\tData  0.000 ( 0.009)\tLoss 2.2079e-01 (1.9473e-01)\tAcc@1  95.31 ( 94.60)\n",
      "Epoch: [27][200/562]\tTime  0.188 ( 0.194)\tData  0.000 ( 0.005)\tLoss 1.1626e-01 (1.8676e-01)\tAcc@1  98.44 ( 94.82)\n",
      "Epoch: [27][300/562]\tTime  0.189 ( 0.192)\tData  0.000 ( 0.003)\tLoss 1.0658e-01 (1.8223e-01)\tAcc@1  98.44 ( 94.94)\n",
      "Epoch: [27][400/562]\tTime  0.188 ( 0.191)\tData  0.000 ( 0.002)\tLoss 1.3869e-01 (1.8297e-01)\tAcc@1  95.31 ( 94.87)\n",
      "Epoch: [27][500/562]\tTime  0.189 ( 0.190)\tData  0.000 ( 0.002)\tLoss 2.9783e-01 (1.8333e-01)\tAcc@1  90.62 ( 94.83)\n",
      "Test: [  0/141]\tTime  0.852 ( 0.852)\tLoss 5.6685e-05 (5.6685e-05)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.188 ( 0.193)\tLoss 1.7310e-01 (1.0881e-01)\tAcc@1  93.75 ( 96.74)\n",
      "Monitored (fake) accuracy * Acc@1 95.844\n",
      "Epoch: [28][  0/562]\tTime  0.962 ( 0.962)\tData  0.773 ( 0.773)\tLoss 1.1024e-01 (1.1024e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Epoch: [28][100/562]\tTime  0.193 ( 0.195)\tData  0.000 ( 0.008)\tLoss 1.6441e-01 (1.8104e-01)\tAcc@1  95.31 ( 94.60)\n",
      "Epoch: [28][200/562]\tTime  0.187 ( 0.192)\tData  0.000 ( 0.004)\tLoss 1.7596e-01 (1.7255e-01)\tAcc@1  93.75 ( 94.88)\n",
      "Epoch: [28][300/562]\tTime  0.186 ( 0.190)\tData  0.000 ( 0.003)\tLoss 2.2809e-01 (1.7364e-01)\tAcc@1  92.19 ( 94.99)\n",
      "Epoch: [28][400/562]\tTime  0.190 ( 0.190)\tData  0.000 ( 0.002)\tLoss 1.9176e-01 (1.7503e-01)\tAcc@1  95.31 ( 94.84)\n",
      "Epoch: [28][500/562]\tTime  0.188 ( 0.189)\tData  0.000 ( 0.002)\tLoss 2.7620e-01 (1.7819e-01)\tAcc@1  89.06 ( 94.77)\n",
      "Test: [  0/141]\tTime  0.951 ( 0.951)\tLoss 4.1996e-05 (4.1996e-05)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.185 ( 0.194)\tLoss 1.7623e-01 (1.0050e-01)\tAcc@1  93.75 ( 97.03)\n",
      "Monitored (fake) accuracy * Acc@1 95.856\n",
      "Epoch: [29][  0/562]\tTime  1.007 ( 1.007)\tData  0.816 ( 0.816)\tLoss 1.7645e-01 (1.7645e-01)\tAcc@1  96.88 ( 96.88)\n",
      "Epoch: [29][100/562]\tTime  0.186 ( 0.196)\tData  0.000 ( 0.008)\tLoss 1.9823e-01 (1.7906e-01)\tAcc@1  93.75 ( 94.83)\n",
      "Epoch: [29][200/562]\tTime  0.186 ( 0.192)\tData  0.000 ( 0.004)\tLoss 7.2662e-02 (1.8162e-01)\tAcc@1  98.44 ( 94.84)\n",
      "Epoch: [29][300/562]\tTime  0.188 ( 0.190)\tData  0.000 ( 0.003)\tLoss 1.7658e-01 (1.7935e-01)\tAcc@1  93.75 ( 94.90)\n",
      "Epoch: [29][400/562]\tTime  0.187 ( 0.190)\tData  0.000 ( 0.002)\tLoss 5.8277e-02 (1.8092e-01)\tAcc@1  98.44 ( 94.86)\n",
      "Epoch: [29][500/562]\tTime  0.189 ( 0.189)\tData  0.000 ( 0.002)\tLoss 9.5476e-02 (1.8297e-01)\tAcc@1  95.31 ( 94.80)\n",
      "Test: [  0/141]\tTime  1.049 ( 1.049)\tLoss 4.1693e-05 (4.1693e-05)\tAcc@1 100.00 (100.00)\n",
      "Test: [100/141]\tTime  0.186 ( 0.195)\tLoss 1.7308e-01 (9.9590e-02)\tAcc@1  93.75 ( 97.03)\n",
      "Monitored (fake) accuracy * Acc@1 95.822\n",
      "correct best accuracy:95.07\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, num_train_samples, train_sampler = get_data_loaders(args)\n",
    "max_iter = args.epochs * (num_train_samples // (args.batch_size * misc.get_world_size()))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_iter, eta_min=0)\n",
    "\n",
    "args.output_dir += '_bn' if args.use_bn else ''\n",
    "if misc.is_main_process() and args.output_dir:\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "args.log_dir += '_bn' if args.use_bn else ''\n",
    "if misc.is_main_process() and args.log_dir:\n",
    "    os.makedirs(args.log_dir, exist_ok=True)\n",
    "    log_writer = SummaryWriter(args.log_dir)\n",
    "else:\n",
    "    log_writer = None\n",
    "\n",
    "max_acc = -1\n",
    "name = None\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    train_stats, train_all_top1, train_all_losses = train(\n",
    "        train_loader, model, linear_classifiers, optimizer, scheduler, epoch, args)\n",
    "    if (epoch + 1) % args.eval_freq != 0:\n",
    "        continue\n",
    "\n",
    "    val_stats, val_all_top1, val_all_losses = \\\n",
    "        validate(val_loader, model, linear_classifiers, args)\n",
    "\n",
    "    all_acc1 = [meter.avg for k, meter in val_all_top1.items()]\n",
    "    acc1 = max(all_acc1)\n",
    "    is_best = acc1 > max_acc\n",
    "\n",
    "    for k, meter in val_all_top1.items():\n",
    "        if meter.avg > max_acc:\n",
    "            max_acc = meter.avg\n",
    "            name = k\n",
    "\n",
    "    if log_writer is not None:\n",
    "        for k, v in train_stats.items():\n",
    "            log_writer.add_scalar('train/{}'.format(k), v, epoch)\n",
    "        for k, v in val_stats.items():\n",
    "            log_writer.add_scalar('val/{}'.format(k), v, epoch)\n",
    "        log_writer.flush()\n",
    "\n",
    "    if misc.is_main_process():  # only the first GPU saves checkpoint\n",
    "        save_checkpoint({\n",
    "            'args': args,\n",
    "            'epoch': epoch + 1,\n",
    "            'model': model.state_dict(),\n",
    "            'linear_classifiers': linear_classifiers.state_dict(),\n",
    "            'acc1': acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, args.output_dir)\n",
    "\n",
    "    for k in train_all_top1.keys():\n",
    "        log_stats = {'train_acc1': train_all_top1[k].avg,\n",
    "                     # 'train_acc5': train_all_top5[k].avg,\n",
    "                     'train_loss': train_all_losses[k].avg,\n",
    "                     'test_acc1': val_all_top1[k].avg,\n",
    "                     # 'test_acc5': val_all_top5[k].avg,\n",
    "                     'test_loss': val_all_losses[k].avg,\n",
    "                     'epoch': epoch}\n",
    "\n",
    "        if misc.is_main_process():\n",
    "            with open(os.path.join(args.output_dir, 'linear_{}.txt'.format(k)), 'a') as f:\n",
    "                f.write(json.dumps(log_stats) + '\\n')\n",
    "\n",
    "if max_acc > 0.0:\n",
    "    print(f\"correct best accuracy:{max_acc:.2f}\")\n",
    "    if misc.is_main_process():\n",
    "        shutil.copyfile(\n",
    "            os.path.join(args.output_dir, 'linear_{}.txt'.format(name)),\n",
    "            os.path.join(args.output_dir, 'linear.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2b5743-0bfd-46e6-bd3a-b907bac6bfbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:37:08.544321Z",
     "iopub.status.busy": "2024-05-13T19:37:08.542833Z",
     "iopub.status.idle": "2024-05-13T19:37:09.931828Z",
     "shell.execute_reply": "2024-05-13T19:37:09.930428Z",
     "shell.execute_reply.started": "2024-05-13T19:37:08.544153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifies: classifier_lr_0_0010\n",
      "Target: [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 7, 6, 4, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 7, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 5]\n",
      "Pred:   [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 8, 6, 7, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 2, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 7]\n",
      "[tensor([93.7500], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0020\n",
      "Target: [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 7, 6, 4, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 7, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 5]\n",
      "Pred:   [7, 1, 1, 3, 0, 8, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 8, 6, 7, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 2, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 7]\n",
      "[tensor([92.1875], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0050\n",
      "Target: [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 7, 6, 4, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 7, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 5]\n",
      "Pred:   [7, 1, 1, 3, 0, 8, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 2, 6, 7, 3, 8, 8, 0, 2, 2, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 2, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 7]\n",
      "[tensor([90.6250], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0100\n",
      "Target: [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 7, 6, 4, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 7, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 5]\n",
      "Pred:   [7, 1, 1, 3, 0, 8, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 2, 6, 7, 3, 8, 8, 0, 2, 2, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 2, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 7]\n",
      "[tensor([90.6250], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0200\n",
      "Target: [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 7, 6, 4, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 7, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 5]\n",
      "Pred:   [7, 1, 1, 3, 0, 8, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 2, 6, 7, 3, 8, 8, 0, 2, 2, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 2, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 7]\n",
      "[tensor([90.6250], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_0500\n",
      "Target: [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 7, 6, 4, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 7, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 5]\n",
      "Pred:   [7, 1, 1, 3, 0, 8, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 2, 6, 7, 3, 8, 8, 0, 2, 2, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 2, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 7]\n",
      "[tensor([90.6250], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_1000\n",
      "Target: [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 7, 6, 4, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 7, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 5]\n",
      "Pred:   [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 2, 6, 7, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 2, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 7]\n",
      "[tensor([93.7500], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_2000\n",
      "Target: [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 7, 6, 4, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 7, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 5]\n",
      "Pred:   [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 2, 6, 7, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 2, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 7]\n",
      "[tensor([93.7500], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_3000\n",
      "Target: [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 7, 6, 4, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 7, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 5]\n",
      "Pred:   [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 2, 6, 7, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 2, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 7]\n",
      "[tensor([93.7500], device='cuda:0')]\n",
      "\n",
      "classifies: classifier_lr_0_5000\n",
      "Target: [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 7, 6, 4, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 7, 6, 8, 7, 6, 2, 6, 1, 3, 1, 6, 6, 8, 4, 7, 2, 3, 5]\n",
      "Pred:   [7, 1, 1, 3, 0, 6, 7, 0, 2, 3, 2, 5, 0, 2, 1, 0, 1, 2, 6, 7, 3, 8, 8, 0, 2, 7, 2, 5, 1, 6, 4, 3, 2, 5, 6, 3, 0, 5, 5, 2, 8, 4, 8, 3, 1, 0, 2, 6, 8, 7, 6, 8, 6, 1, 3, 1, 6, 6, 8, 6, 7, 2, 3, 7]\n",
      "[tensor([90.6250], device='cuda:0')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "visulize_val_dataset = datasets.ImageFolder(\n",
    "    os.path.join(args.data, 'val'), val_transform)\n",
    "visulize_val_loader = torch.utils.data.DataLoader(\n",
    "        visulize_val_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "with torch.no_grad():\n",
    "    for i, (images, target) in enumerate(visulize_val_loader):\n",
    "        if i > 0:\n",
    "            break\n",
    "        images = images.cuda(args.gpu, non_blocking=True)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "        # compute output\n",
    "        features = model.forward_features(images)\n",
    "        outputs = linear_classifiers(features)\n",
    "        # print(outputs)\n",
    "        for key in outputs:       \n",
    "            _, pred = outputs[key].topk(1, 1, True, True)\n",
    "            print(\"classifies:\", key)\n",
    "            print(\"Target:\", target.tolist())\n",
    "            print(\"Pred:  \", pred.t()[0].tolist())\n",
    "            print(accuracy(outputs[key], target, topk=(1,)))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef31141-284b-4dbc-8c2a-6fd93ea50e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
